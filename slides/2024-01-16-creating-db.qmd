---
title: Creating Databases
author: "Jo Hardin"
date: "January 16, 2024"
format:
  revealjs:
    slide-number: true
    show-slide-number: all
execute:
  echo: true
  warning: false
  message: false
---


```{r}
#| include: false

source("../_common.R")
fontawesome::fa_html_dependency()
```



## **DuckDB**

**DuckDB** 

* in-process database management system that runs entirely on your own computer.

* the data live in your storage (instead of your memory).

* you don't have to transfer queries or results over the internet.

## **DuckDB** caveat

* the **SQL** dialect used in **DuckDB** is slightly different from **MySQL** 

* write `SELECT * FROM table 10;` instead of `SELECT * FROM table 0, 10;` 

* lots of different dialects, depending on the **SQL** server.  Always be aware of the dialect you are using.


## **DuckDB** via **R** {.scrollable}

```{r}
#| eval: false

install.packages("duckdb")  # only once, in the Console, not in the .qmd or .Rmd file
library(duckdb)             # at the top of the .qmd or .Rmd file

library(DBI)                # we also still need the DBI package
```


```{r}
con_duckdb <- DBI::dbConnect(duckdb::duckdb(),
                             dbdir = "duck_datab")
```


* the database has been stored to a database directory called `duck_datab` which lives in the current **R** project.  

* can't open it like a standard folder, but it is where **DuckDB** stores the database files.

## Preparing to load data 

Unlike **R**, when creating a new data table, **SQL** requires that you communicate each future variable (column) and that variable's type. Variable types are **not** automatically generated!   

# Today's example

## Saturday Night Live {.scrollable}


```{r}
#| label: fig-snl
#| out.width: 90%
#| fig-cap: "image credit: NBC"
#| fig-alt: "Image says 'Saturday Night Live'."
#| echo: false
knitr::include_graphics("../images/SNL.jpg")
```

Consider the Saturday Night Live datasets available on the <a href = "https://github.com/hhllcks/snldb/" target = "_blank">snldb GitHub repo</a>. 

## `casts` table {.scrollable}

Use **R** to understand the data from `casts.csv`.

```{r}
#| echo: false
casts <- readr::read_csv("https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv")
```

```{r}
#| echo: true
glimpse(casts)
```


## Data types


* **Numbers**: `INTEGER`, `SMALLINT`, `NUMERIC`, `DECIMAL`, `DOUBLE(precision, scale)` precision = \# sig digits, scale = \# digits the follow decimal.
* **String**: `CHAR`, `VARCHAR`, `BINARY`, `TEXT`
* **Date**: `DATE`, `TIME`, `DATETIME`, `TIMESTAMP`, `YEAR`
* **Boolean**: `SMALLINT(1)` in **MySQL**, `BOOLEAN` in **DuckDB**


## `CHECK` constraints

Violation will result in an error.

```{sql}
#| eval: false

CREATE TABLE CountryListCensus (
    Id INT,
    CountryName VARCHAR(255) NOT NULL,
    CountryPopulation INT CHECK(CountryPopulation > 0),
    LastCensus DATE,
    NextCensus DATE,
    CHECK(LastCensus<NextCensus),
    PRIMARY KEY (Id)
);
```


## Efficiencies {.scrollable}

> Each library (`database`) has books (`table`s). Each book (`table`) has pages (rows). Each page (row) has a unique page number to identify it (`key` value); to find a particular page, you sort through the page numbers (`key` values). But it isn't immediately obvious where the particular page of interest is, you might have to page through the book a little bit to find the page of interest.  It would be easier if you had several bookmarks throughout the book to anchor some of the page numbers.  For example, if you want page 1047 and you have a bookmark on page 1050, you only have to turn back three pages.  The bookmark is an `index`, it helps you find the desired rows much more quickly.^[Analogy taken from: https://www.quora.com/profile/Lara-Mazilu]


## Key

Keys are unique identifiers for each row, used primarily for connecting tables. Keys are generally not helpful for efficiency, but they are important for data integrity and relationships between tables.

* `PRIMARY KEY` is a column or set of columns that uniquely identify each row.  Primary keys cannot be `NULL`.
* `FOREIGN KEY` is a column or set of columns that reference a primary key in a different table.  A foreign key can be `NULL`.

## Creating `KEY`s


```{sql}
#| eval: false

CREATE TABLE table1 (
  col1 ...,
  col2 ...,
  col3 ...,
  PRIMARY KEY col1,
  FOREIGN KEY col2 REFERENCES table2(table2col1)
);
```

Either or both of the `KEY`s could be multiple columns.

```{sql}
#| eval: false

CREATE TABLE table1 (
  col1 ...,
  col2 ...,
  col3 ...,
  PRIMARY KEY (col1, col3),
  FOREIGN KEY (col1, col2) REFERENCES table2(table2col1, table2col4)
);
```


## Creating `INDEX`es

Indexes can be created on one or more variable.  A table does not need to have an `INDEX` (or a `KEY`).

```{sql}
#| eval: false

CREATE INDEX name_of_index ON table (col1);
```

```{sql}
#| eval: false

CREATE INDEX name_of_index ON table (col1, col2);
```


## Loading data {.scrollable}

Importing .csv files as tables, a series of steps:^[taken from <a href = "https://mdsr-book.github.io/mdsr3e/16-sqlII.html#load-into-mysql-database" target = "_blank">MDSR</a>.]

1. a `USE` statement that ensures we are in the right schema/database.
2. a series of `DROP TABLE` statements that drop any old tables with the same names as the ones we are going to create.
3. a series of `CREATE TABLE` statements that specify the table structures.
4. a series of `COPY` statements that read the data from the .csv files into the appropriate tables.

## Loading step 1, `USE`

Use the (local) database that we've called `duck_datab`.

```{sql}
#| connection: con_duckdb
#| echo: fenced

USE duck_datab;
```

## Loading step 2, refresh

Make sure to "refresh" the table, in case it already exists.  However, be very careful with the `DROP TABLE` statement, as it **removes** the `casts` table.

```{sql}
#| connection: con_duckdb

DROP TABLE IF EXISTS casts;
```


## Loading step 3, `CREATE TABLE`

Carefully define the variable types, whether or not they allow missing values, and what a default value is for that variable.  Additionally, identify the key for accessing information.

```{sql}
#| connection: con_duckdb

CREATE TABLE casts (
  aid VARCHAR(255) NOT NULL DEFAULT '',
  sid INTEGER NOT NULL DEFAULT 0,
  featured BOOLEAN NOT NULL DEFAULT 'false',
  first_epid INTEGER DEFAULT 0,
  last_epid INTEGER DEFAULT 0,
  update_anchor BOOLEAN NOT NULL DEFAULT 0,
  n_episodes INTEGER NOT NULL DEFAULT 0,
  season_fraction DECIMAL(21,20) NOT NULL DEFAULT 0,
  PRIMARY KEY (sid, aid)
);
```


## Loading step 4, `COPY`

The .csv file lives on my computer, so I load it in directly.  [n.b., the statement to load in data is different in **MySQL**.]

```{sql}
#| connection: con_duckdb

COPY casts FROM 'data/casts.csv' HEADER;
```

## Checking the loading, `SELECT` {.scrollable}

```{sql}
#| connection: con_duckdb
#| label: select-casts
#| output.var: "select_casts"

SELECT * FROM casts LIMIT 8;
```

```{r}
#| label: tbl-select-casts
#| echo: false
#| tbl-cap: "After `CREATE TABLE` where variable types are set, the `COPY` command pulls the data into the table.  `SELECT` shows us that the table is as expected."

select_casts |>
  kbl(linesep = "", booktabs = TRUE) |>
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = c("striped", "hold_position"),
                full_width = FALSE) 

```


## Check the database {.scrollable}

Let's make sure that the database exists and that the table in the database exists.


```{sql}
#| connection: con_duckdb

SHOW DATABASES;
```


```{sql}
#| connection: con_duckdb
#| echo: false
#| include: false

DROP TABLE IF EXISTS actors;
```

```{sql}
#| connection: con_duckdb
#| echo: false
#| include: false

DROP TABLE IF EXISTS seasons;
```

```{sql}
#| connection: con_duckdb
#| echo: false
#| include: false

DROP TABLE IF EXISTS titles;
```

```{sql}
#| connection: con_duckdb
#| echo: false
#| include: false

DROP TABLE IF EXISTS hosts;
```

```{sql}
#| connection: con_duckdb
#| echo: false
#| include: false

DROP TABLE IF EXISTS episodes;
```

```{sql}
#| connection: con_duckdb
#| echo: false
#| include: false

DROP TABLE IF EXISTS impressions;
```

## Check the database {.scrollable}

Let's make sure that the database exists and that the table in the database exists.

```{sql}
#| connection: con_duckdb

SHOW TABLES;
```
## Check the database {.scrollable}

Let's make sure that the database exists and that the table in the database exists.

```{sql}
#| connection: con_duckdb
#| label: casts-describe
#| output.var: "casts_describe"

DESCRIBE casts;
```

```{r}
#| label: tbl-casts-describe
#| echo: false
#| tbl-cap: "DESCRIBE variables in the casts table."

casts_describe |>
  kbl(linesep = "", booktabs = TRUE) |>
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = c("striped", "hold_position"),
                full_width = FALSE) 

```



## Best practice

It is always a good idea to terminate the **SQL** connection when you are done with it.

```{r}
dbDisconnect(con_duckdb, shutdown = TRUE)
```


