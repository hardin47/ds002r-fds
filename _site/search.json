[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Schedule",
    "section": "",
    "text": "Here’s your roadmap for the semester! Each day, follow the general process outlined below:\n\nEnjoy the notes / text \nAttend class, review the  worksheet and solutions if you have any questions after working on it during class.  Slides from class are linked below.\nComplete the Lab assignment ( html linked below),  submit the assignment to GitHub before 10am the following class period.\nDiscuss the reflection questions  and ethics considerations  (see the  class notes) with your classmates and professor.\nThe textbooks are  Modern Data Science with R (MDSR), 3rd edition by Baumer, Kaplan, and Horton and  R for Data Science (R4DS), 2nd edition by Wickham, Çetinkaya-Rundel, and Grolemund.\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\ntopic\nin class\nin lab\nresources\n\n\n\n\nDay 1\n1.08.24\nstarting +\nR + RStudio +\nSQL + MySQL\n Introduction\n  MDSR 15.1\n R4DS 21.2\n What is a DB?\n WS 1\n Lab 1\n dbplyr package\n\n\nDay 2\n1.09.24\nSQL clauses\n SQL clauses\n  MDSR 15.4\n R4DS 21.5\n SQL clauses\n WS 2\n Lab 2\n\n\n\nDay 3\n1.10.24\nCombining tables\n SQL joins\n  MDSR 15.4.7\n R4DS 21.5.7\n SQL joins\n WS 3\n Lab 3\n\n\n\nDay 4\n1.11.24\nRegular Expressions I\n regex I\n  MDSR 19\n R4DS 15\n regex I\n WS 4\n Lab 4\n\n\n\nDay 5\n1.12.24\nRegular Expressions II\n regex II\n  MDSR 19\n R4DS 15\n regex II\n WS 5\n(no lab)\n reg expr cheat sheet\n\n\nDay 6\n1.16.24\nCreating a DB\n creating databases\n  MDSR 16.1.1\n R4DS 21.4\n creating databases\n WS 6\nemail prof with dataset idea for project\n Lab 5\n\n\n\nDay 7\n1.17.24\nChanging a DB\n creating databases\n  MDSR 16.1.1\n R4DS 21.4\n changing databases\n WS 7\n Lab 6\n\n\n\nDay 8\n1.18.24\nSQL extras\n creating databases\n  MDSR 16.1.1\n R4DS 21.4\n SQL extras\n WS 8\n Project\n\n\n\nDay 9\n1.19.24\n Project\n\n(no lab)\n\n\n\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "clicker_study.html",
    "href": "clicker_study.html",
    "title": "Clicker Questions",
    "section": "",
    "text": "to go with Modern Data Science with R, 3rd edition by Baumer, Kaplan, and Horton.\nMany questions taken directly from * w3schools SQL quiz. * Java Guides * study.com\n\n\n\n\nWhat is a SQL server?.1\n\nA relational database management system.\nA software whose main purpose is to store and retrieve data.\nA highly secure server and does not allow any database file manipulation during execution.\nAll of the above.\n\n\n\n\nWhen was SQL created?2\n\n1960s\n1970s\n1980s\n1990s\n2000s\n\n\n\n\nWhat type of databases is SQL designed for?3\n\nhierarchical database management systems.\nnetwork database management systems.\nobject-oriented database management systems.\nrelational database management systems.\n\n\n\n\nWhich is bigger:4\n\ncomputer’s hard drive / storage\ncomputer’s memory / RAM\n\n\n\n\nWhere are each stored?5\n\nSQL tbl and R tibble both in storage\nSQL tbl and R tibble both in memory\nSQL tbl in storage and R tibble in memory\nSQL tbl in memory and R tibble in storage\n\n\n\n\nWhich SQL clause is used to extract data from a database?6\n\nOPEN\nEXTRACT\nSELECT\nGET\n\n\n\n\nWith SQL, how to you retrieve a column named “FirstName” from a table named “Persons”?7\n\nSELECT Persons.FirstName\nEXTRACT FIRSTNAME FROM Persons\nSELECT FirstName FROM Persons\nSELECT “FirstName” FROM “Persons”\n\n\n\n\nWith SQL, how do you select all the columns from a table named “Persons”?8\n\nSELECT Persons\nSELECT * FROM Persons\nSELECT [all] FROM Persons\nSELECT *.Persons\n\n\n\n\nWith SQL, how can you return the number of records in the “Persons” table?9\n\nSELECT COLUMNS(*) FROM Persons\nSELECT COUNT(*) FROM Persons\nSELECT NO(*) FROM Persons\nSELECT LEN(*) FROM Persons\n\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the value of the column “FirstName” is “Peter”?10\n\n\nSELECT * FROM Persons WHERE FirstName &lt;&gt; ‘Peter’\nSELECT * FROM Persons WHERE FirstName = ‘Peter’\nSELECT * FROM Persons WHERE FirstName == ‘Peter’\nSELECT [all] FROM Persons WHERE FirstName LIKE ‘Peter’\nSELECT [all] FROM Persons WHERE FirstName = ‘Peter’\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the “FirstName” is “Peter” and the “LastName” is “Jackson”?11\n\n\nSELECT FirstName = ‘Peter’, LastName = ‘Jackson’ FROM Persons\nSELECT * FROM Persons WHERE FirstName &lt;&gt; ‘Peter’ AND LastName &lt;&gt; ‘Jackson’\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ AND LastName = ‘Jackson’\nSELECT * FROM Persons WHERE FirstName == ‘Peter’ AND LastName == ‘Jackson’\n\n\n\nWhich operator selects values within a range?12\n\nBEWTEEN\nWITHIN\nRANGE\n\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the “LastName” is alphabetically between (and including) “Hansen” and “Pettersen”?13\n\nSELECT LastName &gt; ‘Hansen’ AND LastName &lt; ‘Pettersen’ FROM Persons\nSELECT * FROM Persons WHERE LastName BETWEEN ‘Hansen’ AND ‘Pettersen’\nSELECT * FROM Persons WHERE LastName &gt; ‘Hansen’ AND LastName &lt; ‘Pettersen’\n\n\n\n\nWhich SQL statement returns only different values?14\n\nSELECT UNIQUE\nSELECT DISTINCT\nSELECT DIFFERENT\n\n\n\n\nWhich SQL keyword is used to sort the result-set?15\n\nORDER BY\nORDER\nSORT\nSORT BY\n\n\n\n\nWith SQL, how can you return all the records from a table named “Persons” sorted descending by “FirstName”?16\n\nSELECT * FROM Persons ORDER FirstName DESC\nSELECT * FROM Persons SORT ‘FirstName’ DESC\nSELECT * FROM Persons ORDER BY FirstName DESC\nSELECT * FROM Persons SORT BY ‘FirstName’ DESC\n\n\n\n\nThe OR operator displays a record if ANY conditions listed are true. The AND operator displays a record if ALL of the conditions listed are true.17\n\nTRUE\nFALSE\n\n\n\n\nIn order to SELECT the records with foods that are either green or yellow fruit:18\n\n… WHERE type = ‘fruit’ AND color = ‘yellow’ OR color = ‘green’\n\n… WHERE (type = ‘fruit’ AND color = ‘yellow’) OR color = ‘green’\n\n… WHERE type = ‘fruit’ AND (color = ‘yellow’ OR color = ‘green’)\n\n… WHERE type = ‘fruit’ AND color = ‘yellow’ AND color = ‘green’\n\n… WHERE type = ‘fruit’ AND (color = ‘yellow’ AND color = ‘green’)\n\n\n\n\nWhat is the purpose of a JOIN?19\n\nit filters the rows returned by the SELECT statement.\nit specifies the columns to be retrieved.\nit combines rows from two or more tables based on a related column.\nit orders the results in ascending or descending order.\n\n\n\n\nWhat is the purpose of the UNION operator in SQL?20\n\nit combines the results of two or more SELECT statements.\nit performs a pattern match on a string.\nit retrieves the maximum value in a column.\nit filters the rows returned by the SELECT statement.\n\n\n\n\nWhat is the purpose of the INNER JOIN in SQL?21\n\nit retrieves the maximum value in a column.\nit combines rows from two or more tables based on a related column.\nit filters the rows returned by the SELECT statement.\nit performs a pattern match on a string.\n\n\n\n\nWhat is the purpose of the LEFT JOIN in SQL?22\n\nit combines rows from two or more tables based on a related column.\nit retrieves the maximum value in a column.\nit filters the rows returned by the SELECT statement.\nit performs a pattern match on a string.\n\n\n\n\nRIGHT JOIN keeps all the rows in …?23\n\nthe first table.\nthe second table.\nboth tables.\nneither table\n\n\n\n\nWho is removed in a RIGHT JOIN?24\n\nMick\nJohn\nPaul\nKeith\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich variable(s) are removed in a RIGHT JOIN?25\n\nname\nband\nplays\nnone of them\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn SQL, what happens to Mick’s “plays” variables in a FULL JOIN?26\n\nMick is removed\nguitar\nbass\nNA\nNULL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrep(\"q[^u]\", very.large.word.list) would not match which of the following?27\n\nIraqi\nIraqian\nIraq\nzaqqun (tree that “springs out of the bottom of Hell”, in the Quran)\nQantas (the Australian airline)\n\n\n\n\nWhich of the following regex would match to both “grey” and “gray”?28\n\n“gr[ae]y”\n“gr(a|e)y”\n“gray | grey”\n“gr[a|e]y”\nsome / all of the above – which ones?\n\n\n\n\nWhat will the result be for the following code?29\n\n10\n1\n0\nNA\n\n\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d\")\n\n\n\nWhat will the result be for the following code?30\n\n10\n1\n0\nNA\n\n\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d+\")\n\n\n\nWhat will the result be for the following code?31\n\n.\nEpisode 2: The pie whisperer. (4 August 2015)\nEpisode\nE\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".\")\n\n\n\nWhat will the result be for the following code?32\n\n.\nEpisode 2: The pie whisperer. (4 August 2015)\nEpisode\nE\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".+\")\n\n\n\nWhat will the result be for the following code?33\n\n.\nEpisode 2: The pie whisperer. (4 August 2015)\nEpisode\nE\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \"\\\\.\")\n\n\n\nHow can I pull out just the numerical information in $47?34\n\n“(?&lt;=\\$)\\d”\n“(?&lt;=\\$)\\d+”\n“\\d(?=\\$)”\n“\\d+(?=\\$)”\n\n\n\n\nYou want to know all the types of pies in the text strings. They are written as, for example “apple pie”.35\n\n“\\w+(?!pie)”\n“\\w+(?! pie)”\n“\\w+(?=pie)”\n“\\w+(?= pie)”\n\n\n\n\nstr_extract(c(\"apple pie\", \"chocolate pie\", \"peach pie\"), \"\\\\w+(?= pie)\")\n\n[1] \"apple\"     \"chocolate\" \"peach\"    \n\n\n\nstr_extract(c(\"apple pie\", \"chocolate pie\", \"peach pie\"), \"\\\\w+(?=pie)\")\n\n[1] NA NA NA\n\n\n\n\nWe say that lookarounds are “zero-lenghth assertions”. What does that mean?36\n\nwe return the string in the lookaround\nwe replace the string in the lookaround\nwe return the string at the lookaround\nwe replace the string at the lookaround\n\n\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the value of the column “FirstName” starts with an “a”?37\n\nSELECT * FROM Persons WHERE FirstName = ’a.*’\nSELECT * FROM Persons WHERE FirstName = ’a*’\nSELECT * FROM Persons WHERE FirstName REGEXP ’a.*’\nSELECT * FROM Persons WHERE FirstName REGEXP ’a*’\nSELECT * FROM Persons WHERE FirstName REGEXP ’(?i)a.*’\n\n\n\n\nWhat is the main way to absolutely recognize a record within a database?38\n\nForeign key\nPrimary key\nUnique key\nNatural key\nAlternate key\n\n\n\n\nWhat does a foreign key do?39\n\nDirectly identifies another table\nDirectly identifies another column\nGives access to another entire database\nTranslates the database into another language\n\n\n\n\nWhich of these would likely be used as a foreign key between a table on student enrollment and student grades?40\n\ngrades\ntuition\nstudent_name\nstudent_hometown\n\n\n\n\nFor the student records (for two tables: enrollment and grades), which is the most likely combination?41\n\nname as primary key to both\nname as foreign to both\nname as primary in enrollment and foreign in grades\nname as foreign in enrollment and primary in grades\n\n\n\n\nWhich SQL statement is used to create a database table called ‘Customers’?42\n\nCREATE DATABASE TAB Customers\nCREATE DATABASE Customers\nCREATE DATABASE TABLE Customers\nCREATE TABLE Customers\nCREATE DB Customers\n\n\n\n\nWhich SQL statement revises data in a database?43\n\nSAVE AS\nMODIFY\nSAVE\nUPDATE\n\n\n\n\nWhich SQL statement takes out data from a database?44\n\nREMOVE\nDELETE\nCOLLAPSE\n\n\n\n\nThe NOT NULL constraint enforces a column to not accept NULL values.45\n\nFALSE\nTRUE\n\n\n\n\nWhich SQL statement places new data in a database?46\n\nADD RECORD\nINSERT INTO\nADD NEW\nINSERT NEW\n\n\n\n\nWith SQL, how can you insert a new record into the “Persons” table?47\n\nINSERT INTO Persons VALUES (‘Jimmy’, ‘Jackson’)\nINSERT (‘Jimmy’, ‘Jacskon’) INTO Persons\nINSERT VALUES (‘Jimmy’, ‘Jackson’) INTO Persons\n\n\n\n\nWith SQL, how can you insert “Olsen” as the “LastName” in the “Persons” table?48\n\nINSERT INTO Persons (LastName) VALUES (‘Olsen’)\nINSERT INTO Persons (’Olsen) INTO LastName\nINSERT (‘Olsen’) INTO Persons (LastName)\n\n\n\n\nHow can you change “Hansen” into “Nilsen” in the “LastName” column in the Persons table?49\n\nMODIFY Persons SET LastName=‘Nilsen’ WHERE LastName=‘Hansen’\nUPDATE Persons SET LastName=‘Hansen’ INTO LastName=‘Nilsen’\nMODIFY Persons SET LastName=‘Hansen’ INTO LastName=‘Nilsen’\nUPDATE Persons SET LastName=‘Nilsen’ WHERE LastName=‘Hansen’\n\n\n\n\nWith SQL, how can you delete the records where the “FirstName” is “Peter” in the Persons Table?50\n\nDELETE FROM Persons WHERE FirstName=‘Peter’\nDELETE FirstName=‘Peter’ FROM Persons\nDELETE ROW FirstName=‘Peter’ FROM Persons\n\n\n\n\nIn the flights table, the following INDEXes exist: Tailnum, Year, and Date. How many rows would be looked through if the WHERE filter was on month only?51\n\nmore than 6.3 million\nless than 6.3 million\nmore than 700,000\nless than 700,000\n\n\n\n\nWhich has a larger cardinality, Tailnum or Year?52\n\nTailnum\nYear\nthey have the same cardinality\nneither has a cardinality\n\n\n\n\nWhich index takes up more storage space, the one on Tailnum or the one on Year?53\n\nTailnum\nYear\nthey take up the same space\nyou can’t index on either variable\n\n\n\n\nWhich index is more effective at reducing querying time, the one on Tailnum or the one on Year?54\n\nTailnum\nYear\nthe queries would be the same\nyou can’t query on either variable\n\n\n\n\nWhat does the R function ifelse(a, b, c) do?55\n\na = TRUE option, b = FALSE option, c = question\na = FALSE option, b = TRUE option, c = question\na = question, b = TRUE option, c = FALSE option\na = question, b = FALSE option, c = TRUE option\n\n\n\n\nWhat does the R function case_when() do?56\n\nrenames a variable\nchanges the data type of a variable\npartitions a numeric variable\ncreates a new variable by re-coding an original variable\n\n\n\n\nWhat does the R function cut() do?57\n\nrenames a variable\nchanges the data type of a variable\npartitions a numeric variable\ncreates a new variable by re-coding an original variable"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "syllabus",
    "section": "",
    "text": "Class: daily 10-11:30am\nLab: daily (not Fridays) 1:30-3pm\nOffice hours: daily 11:30-1:30pm\n\n\n\n\n\nArtwork by @allison_horst.\n\n\n\n\n\n\n\nData Science, the SQL is a continuation of ideas learned in Foundations of Data Science. The course develops abilities for using SQL databases within the data science pipeline. The core of the course will focus on the why and the how associated with writing SELECT queries in SQL. Additional topics will include subqueries, indexes, keys, and regular expressions. Students will learn how to run SQL queries from both the RStudio IDE as well as from a relational database management system client like MySQL Workbench or DuckDB.\n\n\n\n\n\n\nAnonymous Feedback\n\n\n\nAs someone who is, myself, constantly learning and growing in many ways, I welcome your feedback about the course, the classroom dynamics, or anything else you’d like me to know. I have emailed you a link to an anonymous feedback form. Please feel free to provide me with feedback at any time!\n\n\n\n\n\nBy the end of the term, students will:\n\nDatabase Concepts: be able to explain basic database concepts such as tables, records, fields, and relationships.\nIntroduction to SQL: gain a fundamental understanding of Structured Query Language (SQL), including its history, purpose, and key components.\nSQL Querying:\n\nWriting SQL Queries: learn how to write basic SQL queries to retrieve data from a single table.\nFiltering and Sorting Data: be able to use SQL to filter and sort data based on specific criteria.\nJoining Tables: understand how to perform inner and outer joins to combine data from multiple tables.\n\nCreating Tables: be able to create a SQL database with multiple tables that link to one another using DuckDB.\nInserting and Updating Data: be able to use SQL to insert new records into a table and update existing records. Use SQL to delete records from a table.\nBasics of Regular Expressions: understand the fundamental concepts of regular expressions. Identify and use basic metacharacters for pattern matching to write simple regular expressions for text search and matching.\n\n\n\n\nIn an ideal world, science would be objective. However, much of science is subjective and is historically built on a small subset of privileged voices. In this class, we will make an effort to recognize how science (and data science!) has played a role in both understanding diversity as well as in promoting systems of power and privilege. I acknowledge that there may be both overt and covert biases in the material due to the lens with which it was written, even though the material is primarily of a scientific nature. Integrating a diverse set of experiences is important for a more comprehensive understanding of science. I would like to discuss issues of diversity in statistics as part of the course from time to time.\nPlease contact me if you have any suggestions to improve the quality of the course materials.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this:\n\nIf you have a name and/or set of pronouns that differ from those that appear in your official records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. You can also relay information to me via your mentors. I want to be a resource for you.\n\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it. As a participant in course discussions, you should also strive to honor the diversity of your classmates.\n\n\n\n\n\n Modern Data Science with R, 3rd edition by Baumer, Kaplan, and Horton.\nR for Data Science, 2nd edition by Wickham, Çetinkaya-Rundel, and Grolemund.\n\n\n\n\n\n\nDates\n\n\n\nFinal Project due Tuesday, January 23rd\n\n\n\n\n\n\nEnough R\nR tutorial\nGreat tutorials through the Coding Club\nA true beginner’s introduction to the tidyverse, the introverse.\nfor a good start to R in general\nA fantastic ggplot2 tutorial\nGreat tutorials through the Coding Club\nGoogle for R\nsome R ideas that I wrote up\nIncredibly helpful cheatsheets from RStudio.\n\ndata wrangling\nggplot2\nR Markdown\nRStudio IDE\n\n\n\n\n\n\nW3 schools Introduction to SQL\nW3 schools SQL Exercises, Practice, Solution\nR packages for working with databases\nIntroduction to dbplyr\n\n\n\n\n\nstringr vignette\nstringr package\nJenny Bryan et al.’s STAT 545 notes\nHadley Wickham’s book R for Data Science\nregexpal\n\nRegExr\nRegexOne\n\n\n\n\nR will be used for many assignments. You can use R on the Smith server: https://rstudio.smith.edu/.\nAlternatively, feel free to download both R and RStudio onto your own computer. R is freely available at http://www.r-project.org/; RStudio is also free and allows you to turn in all R assignments using Quarto http://rstudio.org/.\n\n\n\nAssignments will be turned in using GitHub. See instructions for using GitHub on the course website.\n\n\n\n\n\n\nThe prerequisite for this class is SDS 192, Introduction to Data Science.\n\n\n\nLabs will take place on most days with the lab write-up due just before the following class period. See instructions for using GitHub on the course website for how to turn in assignments.\n\n\n\nThe class expectations are that you show up for class and labs and turn in a final project. A successful final project is required to pass the class. Additionally, you should not miss more than 1 or 2 classes nor should you miss turning in more than 1 or 2 labs."
  },
  {
    "objectID": "syllabus.html#math-150-spring-2023",
    "href": "syllabus.html#math-150-spring-2023",
    "title": "syllabus",
    "section": "",
    "text": "Class: Tuesdays & Thursdays, 1:15-2:30pm\nJo Hardin\n2351 Estella\njo.hardin@pomona.edu\n\n\nMondays 1:30-3pm\nTuesdays 2:30-3:30pm\nWednesday 9-11am\nThursday 3-4pm\nor by appointment\n\n\nMonday 6-8pm\nWednesday 8-10pm\nEstella 2131\n\n\n\n\n\nArtwork by @allison_horst."
  },
  {
    "objectID": "syllabus.html#the-course",
    "href": "syllabus.html#the-course",
    "title": "syllabus",
    "section": "",
    "text": "Data Science, the SQL is a continuation of ideas learned in Foundations of Data Science. The course develops abilities for using SQL databases within the data science pipeline. The core of the course will focus on the why and the how associated with writing SELECT queries in SQL. Additional topics will include subqueries, indexes, keys, and regular expressions. Students will learn how to run SQL queries from both the RStudio IDE as well as from a relational database management system client like MySQL Workbench or DuckDB.\n\n\n\n\n\n\nAnonymous Feedback\n\n\n\nAs someone who is, myself, constantly learning and growing in many ways, I welcome your feedback about the course, the classroom dynamics, or anything else you’d like me to know. I have emailed you a link to an anonymous feedback form. Please feel free to provide me with feedback at any time!"
  },
  {
    "objectID": "syllabus.html#student-learning-outcomes",
    "href": "syllabus.html#student-learning-outcomes",
    "title": "syllabus",
    "section": "",
    "text": "By the end of the semester, students will be able to do the following:\n\nevaluate quantitative information with regards to clinical and biological data. We’ll be sure to keep in mind:\n\nCareful presentation of data\nConsideration of variability\nMeaningful comparisons\n\ncritically evaluate the medical literature with respect to design, analysis, and interpretation of results.\nunderstand the role of inherent variability and keep it in perspective when inferring results to a population.\ncritically evaluate medical results given in the mainstream media.\nread published studies with skepticism. Some people (in all fields!) wrongly believe that all studies published in a peer review publication must be 100% accurate and/or well designed studies. In this course, you will learn the tools to recognize, interpret, and critique statistical results in medical literature."
  },
  {
    "objectID": "syllabus.html#inclusion-goals",
    "href": "syllabus.html#inclusion-goals",
    "title": "syllabus",
    "section": "",
    "text": "In an ideal world, science would be objective. However, much of science is subjective and is historically built on a small subset of privileged voices. In this class, we will make an effort to recognize how science (and data science!) has played a role in both understanding diversity as well as in promoting systems of power and privilege. I acknowledge that there may be both overt and covert biases in the material due to the lens with which it was written, even though the material is primarily of a scientific nature. Integrating a diverse set of experiences is important for a more comprehensive understanding of science. I would like to discuss issues of diversity in statistics as part of the course from time to time.\nPlease contact me if you have any suggestions to improve the quality of the course materials.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this:\n\nIf you have a name and/or set of pronouns that differ from those that appear in your official records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. You can also relay information to me via your mentors. I want to be a resource for you.\n\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it. As a participant in course discussions, you should also strive to honor the diversity of your classmates."
  },
  {
    "objectID": "syllabus.html#technical-details",
    "href": "syllabus.html#technical-details",
    "title": "syllabus",
    "section": "",
    "text": "Modern Data Science with R, 3rd edition by Baumer, Kaplan, and Horton.\nR for Data Science, 2nd edition by Wickham, Çetinkaya-Rundel, and Grolemund.\n\n\n\n\n\n\nDates\n\n\n\nFinal Project due Tuesday, January 23rd\n\n\n\n\n\n\nEnough R\nR tutorial\nGreat tutorials through the Coding Club\nA true beginner’s introduction to the tidyverse, the introverse.\nfor a good start to R in general\nA fantastic ggplot2 tutorial\nGreat tutorials through the Coding Club\nGoogle for R\nsome R ideas that I wrote up\nIncredibly helpful cheatsheets from RStudio.\n\ndata wrangling\nggplot2\nR Markdown\nRStudio IDE\n\n\n\n\n\n\nW3 schools Introduction to SQL\nW3 schools SQL Exercises, Practice, Solution\nR packages for working with databases\nIntroduction to dbplyr\n\n\n\n\n\nstringr vignette\nstringr package\nJenny Bryan et al.’s STAT 545 notes\nHadley Wickham’s book R for Data Science\nregexpal\n\nRegExr\nRegexOne\n\n\n\n\nR will be used for many assignments. You can use R on the Smith server: https://rstudio.smith.edu/.\nAlternatively, feel free to download both R and RStudio onto your own computer. R is freely available at http://www.r-project.org/; RStudio is also free and allows you to turn in all R assignments using Quarto http://rstudio.org/.\n\n\n\nAssignments will be turned in using GitHub. See instructions for using GitHub on the course website."
  },
  {
    "objectID": "syllabus.html#important-features",
    "href": "syllabus.html#important-features",
    "title": "syllabus",
    "section": "",
    "text": "The prerequisite for this class is SDS 192, Introduction to Data Science.\n\n\n\nLabs will take place on most days with the lab write-up due just before the following class period. See instructions for using GitHub on the course website for how to turn in assignments.\n\n\n\nThe class expectations are that you show up for class and labs and turn in a final project. A successful final project is required to pass the class. Additionally, you should not miss more than 1 or 2 classes nor should you miss turning in more than 1 or 2 labs."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nadapted from Monica Linden, Brown University↩︎"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "Class notes can be found at http://st47s.com/SDS261/Notes/.\n\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "clicker.html",
    "href": "clicker.html",
    "title": "Clicker Questions",
    "section": "",
    "text": "to go with Modern Data Science with R, 3rd edition by Baumer, Kaplan, and Horton.\nMany questions taken directly from * w3schools SQL quiz. * Java Guides * study.com\n\n\n\n\nWhat is a SQL server?.1\n\nA relational database management system.\nA software whose main purpose is to store and retrieve data.\nA highly secure server and does not allow any database file manipulation during execution.\nAll of the above.\n\n\n\n\nWhen was SQL created?2\n\n1960s\n1970s\n1980s\n1990s\n2000s\n\n\n\n\nWhat type of databases is SQL designed for?3\n\nhierarchical database management systems.\nnetwork database management systems.\nobject-oriented database management systems.\nrelational database management systems.\n\n\n\n\nWhich is bigger:4\n\ncomputer’s hard drive / storage\ncomputer’s memory / RAM\n\n\n\n\nWhere are each stored?5\n\nSQL tbl and R tibble both in storage\nSQL tbl and R tibble both in memory\nSQL tbl in storage and R tibble in memory\nSQL tbl in memory and R tibble in storage\n\n\n\n\nWhich SQL clause is used to extract data from a database?6\n\nOPEN\nEXTRACT\nSELECT\nGET\n\n\n\n\nWith SQL, how to you retrieve a column named “FirstName” from a table named “Persons”?7\n\nSELECT Persons.FirstName\nEXTRACT FIRSTNAME FROM Persons\nSELECT FirstName FROM Persons\nSELECT “FirstName” FROM “Persons”\n\n\n\n\nWith SQL, how do you select all the columns from a table named “Persons”?8\n\nSELECT Persons\nSELECT * FROM Persons\nSELECT [all] FROM Persons\nSELECT *.Persons\n\n\n\n\nWith SQL, how can you return the number of records in the “Persons” table?9\n\nSELECT COLUMNS(*) FROM Persons\nSELECT COUNT(*) FROM Persons\nSELECT NO(*) FROM Persons\nSELECT LEN(*) FROM Persons\n\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the value of the column “FirstName” is “Peter”?10\n\n\nSELECT * FROM Persons WHERE FirstName &lt;&gt; ‘Peter’\nSELECT * FROM Persons WHERE FirstName = ‘Peter’\nSELECT * FROM Persons WHERE FirstName == ‘Peter’\nSELECT [all] FROM Persons WHERE FirstName LIKE ‘Peter’\nSELECT [all] FROM Persons WHERE FirstName = ‘Peter’\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the “FirstName” is “Peter” and the “LastName” is “Jackson”?11\n\n\nSELECT FirstName = ‘Peter’, LastName = ‘Jackson’ FROM Persons\nSELECT * FROM Persons WHERE FirstName &lt;&gt; ‘Peter’ AND LastName &lt;&gt; ‘Jackson’\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ AND LastName = ‘Jackson’\nSELECT * FROM Persons WHERE FirstName == ‘Peter’ AND LastName == ‘Jackson’\n\n\n\nWhich operator selects values within a range?12\n\nBEWTEEN\nWITHIN\nRANGE\n\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the “LastName” is alphabetically between (and including) “Hansen” and “Pettersen”?13\n\nSELECT LastName &gt; ‘Hansen’ AND LastName &lt; ‘Pettersen’ FROM Persons\nSELECT * FROM Persons WHERE LastName BETWEEN ‘Hansen’ AND ‘Pettersen’\nSELECT * FROM Persons WHERE LastName &gt; ‘Hansen’ AND LastName &lt; ‘Pettersen’\n\n\n\n\nWhich SQL statement returns only different values?14\n\nSELECT UNIQUE\nSELECT DISTINCT\nSELECT DIFFERENT\n\n\n\n\nWhich SQL keyword is used to sort the result-set?15\n\nORDER BY\nORDER\nSORT\nSORT BY\n\n\n\n\nWith SQL, how can you return all the records from a table named “Persons” sorted descending by “FirstName”?16\n\nSELECT * FROM Persons ORDER FirstName DESC\nSELECT * FROM Persons SORT ‘FirstName’ DESC\nSELECT * FROM Persons ORDER BY FirstName DESC\nSELECT * FROM Persons SORT BY ‘FirstName’ DESC\n\n\n\n\nThe OR operator displays a record if ANY conditions listed are true. The AND operator displays a record if ALL of the conditions listed are true.17\n\nTRUE\nFALSE\n\n\n\n\nIn order to SELECT the records with foods that are either green or yellow fruit:18\n\n… WHERE type = ‘fruit’ AND color = ‘yellow’ OR color = ‘green’\n\n… WHERE (type = ‘fruit’ AND color = ‘yellow’) OR color = ‘green’\n\n… WHERE type = ‘fruit’ AND (color = ‘yellow’ OR color = ‘green’)\n\n… WHERE type = ‘fruit’ AND color = ‘yellow’ AND color = ‘green’\n\n… WHERE type = ‘fruit’ AND (color = ‘yellow’ AND color = ‘green’)\n\n\n\n\nWhat is the purpose of a JOIN?19\n\nit filters the rows returned by the SELECT statement.\nit specifies the columns to be retrieved.\nit combines rows from two or more tables based on a related column.\nit orders the results in ascending or descending order.\n\n\n\n\nWhat is the purpose of the UNION operator in SQL?20\n\nit combines the results of two or more SELECT statements.\nit performs a pattern match on a string.\nit retrieves the maximum value in a column.\nit filters the rows returned by the SELECT statement.\n\n\n\n\nWhat is the purpose of the INNER JOIN in SQL?21\n\nit retrieves the maximum value in a column.\nit combines rows from two or more tables based on a related column.\nit filters the rows returned by the SELECT statement.\nit performs a pattern match on a string.\n\n\n\n\nWhat is the purpose of the LEFT JOIN in SQL?22\n\nit combines rows from two or more tables based on a related column.\nit retrieves the maximum value in a column.\nit filters the rows returned by the SELECT statement.\nit performs a pattern match on a string.\n\n\n\n\nRIGHT JOIN keeps all the rows in …?23\n\nthe first table.\nthe second table.\nboth tables.\nneither table\n\n\n\n\nWho is removed in a RIGHT JOIN?24\n\nMick\nJohn\nPaul\nKeith\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich variable(s) are removed in a RIGHT JOIN?25\n\nname\nband\nplays\nnone of them\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn SQL, what happens to Mick’s “plays” variables in a FULL JOIN?26\n\nMick is removed\nguitar\nbass\nNA\nNULL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrep(\"q[^u]\", very.large.word.list) would not match which of the following?27\n\nIraqi\nIraqian\nIraq\nzaqqun (tree that “springs out of the bottom of Hell”, in the Quran)\nQantas (the Australian airline)\n\n\n\n\nWhich of the following regex would match to both “grey” and “gray”?28\n\n“gr[ae]y”\n“gr(a|e)y”\n“gray | grey”\n“gr[a|e]y”\nsome / all of the above – which ones?\n\n\n\n\nWhat will the result be for the following code?29\n\n10\n1\n0\nNA\n\n\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d\")\n\n\n\nWhat will the result be for the following code?30\n\n10\n1\n0\nNA\n\n\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d+\")\n\n\n\nWhat will the result be for the following code?31\n\n.\nEpisode 2: The pie whisperer. (4 August 2015)\nEpisode\nE\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".\")\n\n\n\nWhat will the result be for the following code?32\n\n.\nEpisode 2: The pie whisperer. (4 August 2015)\nEpisode\nE\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".+\")\n\n\n\nWhat will the result be for the following code?33\n\n.\nEpisode 2: The pie whisperer. (4 August 2015)\nEpisode\nE\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \"\\\\.\")\n\n\n\nHow can I pull out just the numerical information in $47?34\n\n“(?&lt;=\\$)\\d”\n“(?&lt;=\\$)\\d+”\n“\\d(?=\\$)”\n“\\d+(?=\\$)”\n\n\n\n\nYou want to know all the types of pies in the text strings. They are written as, for example “apple pie”.35\n\n“\\w+(?!pie)”\n“\\w+(?! pie)”\n“\\w+(?=pie)”\n“\\w+(?= pie)”\n\n\n\n\nstr_extract(c(\"apple pie\", \"chocolate pie\", \"peach pie\"), \"\\\\w+(?= pie)\")\n\n[1] \"apple\"     \"chocolate\" \"peach\"    \n\n\n\nstr_extract(c(\"apple pie\", \"chocolate pie\", \"peach pie\"), \"\\\\w+(?=pie)\")\n\n[1] NA NA NA\n\n\n\n\nWe say that lookarounds are “zero-lenghth assertions”. What does that mean?36\n\nwe return the string in the lookaround\nwe replace the string in the lookaround\nwe return the string at the lookaround\nwe replace the string at the lookaround\n\n\n\n\n\nWith SQL, how do you select all the records from a table named “Persons” where the value of the column “FirstName” starts with an “a”?37\n\nSELECT * FROM Persons WHERE FirstName = ’a.*’\nSELECT * FROM Persons WHERE FirstName = ’a*’\nSELECT * FROM Persons WHERE FirstName REGEXP ’a.*’\nSELECT * FROM Persons WHERE FirstName REGEXP ’a*’\nSELECT * FROM Persons WHERE FirstName REGEXP ’(?i)a.*’\n\n\n\n\nWhat is the main way to absolutely recognize a record within a database?38\n\nForeign key\nPrimary key\nUnique key\nNatural key\nAlternate key\n\n\n\n\nWhat does a foreign key do?39\n\nDirectly identifies another table\nDirectly identifies another column\nGives access to another entire database\nTranslates the database into another language\n\n\n\n\nWhich of these would likely be used as a foreign key between a table on student enrollment and student grades?40\n\ngrades\ntuition\nstudent_name\nstudent_hometown\n\n\n\n\nFor the student records (for two tables: enrollment and grades), which is the most likely combination?41\n\nname as primary key to both\nname as foreign to both\nname as primary in enrollment and foreign in grades\nname as foreign in enrollment and primary in grades\n\n\n\n\nWhich SQL statement is used to create a database table called ‘Customers’?42\n\nCREATE DATABASE TAB Customers\nCREATE DATABASE Customers\nCREATE DATABASE TABLE Customers\nCREATE TABLE Customers\nCREATE DB Customers\n\n\n\n\nWhich SQL statement revises data in a database?43\n\nSAVE AS\nMODIFY\nSAVE\nUPDATE\n\n\n\n\nWhich SQL statement takes out data from a database?44\n\nREMOVE\nDELETE\nCOLLAPSE\n\n\n\n\nThe NOT NULL constraint enforces a column to not accept NULL values.45\n\nFALSE\nTRUE\n\n\n\n\nWhich SQL statement places new data in a database?46\n\nADD RECORD\nINSERT INTO\nADD NEW\nINSERT NEW\n\n\n\n\nWith SQL, how can you insert a new record into the “Persons” table?47\n\nINSERT INTO Persons VALUES (‘Jimmy’, ‘Jackson’)\nINSERT (‘Jimmy’, ‘Jacskon’) INTO Persons\nINSERT VALUES (‘Jimmy’, ‘Jackson’) INTO Persons\n\n\n\n\nWith SQL, how can you insert “Olsen” as the “LastName” in the “Persons” table?48\n\nINSERT INTO Persons (LastName) VALUES (‘Olsen’)\nINSERT INTO Persons (’Olsen) INTO LastName\nINSERT (‘Olsen’) INTO Persons (LastName)\n\n\n\n\nHow can you change “Hansen” into “Nilsen” in the “LastName” column in the Persons table?49\n\nMODIFY Persons SET LastName=‘Nilsen’ WHERE LastName=‘Hansen’\nUPDATE Persons SET LastName=‘Hansen’ INTO LastName=‘Nilsen’\nMODIFY Persons SET LastName=‘Hansen’ INTO LastName=‘Nilsen’\nUPDATE Persons SET LastName=‘Nilsen’ WHERE LastName=‘Hansen’\n\n\n\n\nWith SQL, how can you delete the records where the “FirstName” is “Peter” in the Persons Table?50\n\nDELETE FROM Persons WHERE FirstName=‘Peter’\nDELETE FirstName=‘Peter’ FROM Persons\nDELETE ROW FirstName=‘Peter’ FROM Persons\n\n\n\n\nIn the flights table, the following INDEXes exist: Tailnum, Year, and Date. How many rows would be looked through if the WHERE filter was on month only?51\n\nmore than 6.3 million\nless than 6.3 million\nmore than 700,000\nless than 700,000\n\n\n\n\nWhich has a larger cardinality, Tailnum or Year?52\n\nTailnum\nYear\nthey have the same cardinality\nneither has a cardinality\n\n\n\n\nWhich index takes up more storage space, the one on Tailnum or the one on Year?53\n\nTailnum\nYear\nthey take up the same space\nyou can’t index on either variable\n\n\n\n\nWhich index is more effective at reducing querying time, the one on Tailnum or the one on Year?54\n\nTailnum\nYear\nthe queries would be the same\nyou can’t query on either variable\n\n\n\n\nWhat does the R function ifelse(a, b, c) do?55\n\na = TRUE option, b = FALSE option, c = question\na = FALSE option, b = TRUE option, c = question\na = question, b = TRUE option, c = FALSE option\na = question, b = FALSE option, c = TRUE option\n\n\n\n\nWhat does the R function case_when() do?56\n\nrenames a variable\nchanges the data type of a variable\npartitions a numeric variable\ncreates a new variable by re-coding an original variable\n\n\n\n\nWhat does the R function cut() do?57\n\nrenames a variable\nchanges the data type of a variable\npartitions a numeric variable\ncreates a new variable by re-coding an original variable"
  },
  {
    "objectID": "clicker_slides.html",
    "href": "clicker_slides.html",
    "title": "Clicker Questions",
    "section": "",
    "text": "Clicker Questions\nto go with Modern Data Science wi\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "The final project for SDS 261 is meant to bring together concepts from the class. You can choose to focus on one aspect, or you can bring together all of the concepts that we have covered. Each project must include at least one of the following topics:\nA bold project may incorporate all three topics."
  },
  {
    "objectID": "project.html#building-a-database",
    "href": "project.html#building-a-database",
    "title": "Final Project",
    "section": "Building a Database",
    "text": "Building a Database\nbuild a database using the skills we’ve covered in the two week course.\n\nData\nYou will need to find your own (large!) data with at least 3 publicly available tables that have keys connecting them. Additionally, the data should have some strings that need parsing.\n\nuse the rvest package to scrape html data… it will be messy!\n\n\n\nDue Dates\n\nTuesday, January 16. Email prof with dataset idea for project. Include the following:\n\nHolistic description of the dataset (a few sentences).\nExplanation of keys that link the data tables.\nDescription of the observational units and columns in each data table.\nFull reference for data citation.\nLink to the resources.\n\nEnd of week 2. We will have some time in class to work on the project.\nTuesday, January 23. Completed project is due."
  },
  {
    "objectID": "project.html#assignment",
    "href": "project.html#assignment",
    "title": "Final Project",
    "section": "Assignment",
    "text": "Assignment\n\nInput data\nDescribe creation / construction / changing of the DB using DuckDB or MySQL.\nSome data wrangling in SQL and R (comparison). Should include some joining.\nSomething with regular expressions\nSome analysis (probably in R). Must include at least one visualization. For fun, you could make a Shiny App (not required)."
  },
  {
    "objectID": "project.html#something-new",
    "href": "project.html#something-new",
    "title": "Final Project",
    "section": "",
    "text": "Each individual should have some analysis that goes beyond a Cox PH model. For your analysis, you should give details of what is going on, how it is relevant, what are the technical conditions, what are the conclusions, etc. Your analysis should indicate a sense that you understand and that you can communicate the results to a possible client. Some possible topics to investigate include:\n\nInvestigation of the proportional hazards assumption (what does the R function cox.zph() do?)\nExponential or Weibull PH regression (parametric survival model)\nDeriving / detailing AIC & BIC for model selection on Cox PH\nPower analysis (a simulation?)\nDerivation of the sample size calculation for the log rank test (and application to the data)\nAn analysis of the Schoenfeld residuals (how are they calculated and why is that calculation relevant?)\nBootstrapping the survival model (what are the assumptions? what do you conclude?)\nAn analysis of possible time dependent covariates (what should you see? what do you see? do transformations help?)\nAn analysis / understanding / simulation of the multiple comparisons issues for assessing many different models (or other exploratory hypotheses).\nAndersen-Gill extension of the Cox PH model for time-varying covariates (available in rms R package). [Note: A-G isn’t meant to test PH, per se, but rather it allows for variables that are time varying.]\nAnother topic related to survival analysis that you find interesting."
  },
  {
    "objectID": "project.html#r-thoughts",
    "href": "project.html#r-thoughts",
    "title": "Final Project",
    "section": "",
    "text": "Use R Markdown to create a reproducible analysis. Anyone should be able to run your analysis using only the .Rmd file.\nTurn in both .Rmd and .pdf files for your final analysis.\nIf you are working in pairs, the project is extended in two ways. 1. You must both be able to work on the files. Ideally, you will share your work via GitHub or other software which tracks changes and coordinates work. 2. You must do two new items (one each).\nNote that the event of interest is “visit to primary care physician.”\nBe as creative as possible trying to think about how you might like to graphically display the data. If you come up with a cool idea for a graph but don’t know how to implement it, please let me know, and I will write the code for you!!\nPlease do not re-code the variables or change the variable names outside of R. You may, however, transform (mutate()) the variables within your R code (that is, for example, if you wanted to divide months by 12 to have years, or square a variable, etc.).\n\n\n\n\nYour primary assessment will be based on the above items (modeling, understanding of new topic, additional analysis, interpretation).\nAdditionally there will be two competitions. Winning either will add 5 points (out of 100) to your score.\n\nGraphic: the class will vote on who has the best graphic.\nModel: using a holdout sample (I only gave you part of the data), I will assess your final model. The group whose model best describes the holdout sample (as measured by the c-index) will win the model prize."
  },
  {
    "objectID": "project.html#footnotes",
    "href": "project.html#footnotes",
    "title": "Final Project",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nmeasured by the \\(c\\) index↩︎"
  },
  {
    "objectID": "clicker_study.html#footnotes",
    "href": "clicker_study.html#footnotes",
    "title": "Clicker Questions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\nA relational database management system.\n\n↩︎\n\nThe first versions were created in the 1970s and called SEQUEL (Structured English QUEry Language). c. SQL came about in particular systems in the 1980s.\n\n↩︎\n\nrelational database management systems.\n\n↩︎\n\ncomputer’s hard drive / storage\n\n↩︎\n\nSQL tbl in storage and R tibble in memory\n\n↩︎\n\nSELECT\n\n↩︎\n\nSELECT FirstName FROM Persons\n\n↩︎\n\nSELECT * FROM Persons\n\n↩︎\n\nSELECT COUNT(*) FROM Persons\n\n↩︎\n\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ (d. would also work.)\n\n↩︎\n\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ AND LastName = ‘Jackson’\n\n↩︎\n\nBEWTEEN\n\n↩︎\n\nSELECT * FROM Persons WHERE LastName BETWEEN ‘Hansen’ AND ‘Pettersen’\n\n↩︎\n\nSELECT DISTINCT\n\n↩︎\n\nORDER BY\n\n↩︎\n\nSELECT * FROM Persons ORDER BY FirstName DESC\n\n↩︎\n\nTRUE\n\n↩︎\n\n… WHERE type = ‘fruit’ AND (color = ‘yellow’ OR color = ‘green’)\n\n↩︎\n\nit combines rows from two or more tables based on a related column.\n\n↩︎\n\nit combines the results of two or more SELECT statements.\n\n↩︎\n\nit combines rows from two or more tables based on a related column.\n\n↩︎\n\nit combines rows from two or more tables based on a related column.\n\n↩︎\n\nthe first table\n\n↩︎\n\nMick\n\n↩︎\n\nnone of them (all variables are kept in all joins)\n\n↩︎\n\nNULL (it would be NA in R)\n\n↩︎\nneither c. nor e. would match. Inside the bracket “[^u]” matches anything other than a “u”, but it has to match something.↩︎\n\nall of the above. Inside a character class | is a normal character and would therefore match “grey” and “gray” and “gr|y”. Which is not what we want, but would work to match both “grey” and “gray”.\n\n↩︎\n\n1 (because \\d matches only a single digit).\n\n↩︎\n\n10 (because \\d+ matches at least one digit).\n\n↩︎\n\nE (because . matches anything, and returns only a single character).\n\n↩︎\n\nEpisode 2: The pie whisperer. (4 August 2015) (because . matches anything, and with the + it returns multiple characters).\n\n↩︎\n\n. (because \\. matches the period, .).\n\n↩︎\n\n“(?&lt;=\\$)\\d+”\n\n↩︎\n\n“\\w+(?= pie)”\n\n↩︎\n\nwe return the string at the lookaround\n\n↩︎\n\nSELECT * FROM Persons WHERE FirstName REGEXP ’(?i)a.*’ (n.b., the LIKE function will give you a similar result, with % as a wildcard: SELECT*FROMPersonsWHERE` FirstName LIKE ‘a%’)\n\n↩︎\n\nPrimary key\n\n↩︎\n\nDirectly identifies another column\n\n↩︎\n\nstudent_name\n\n↩︎\n\nname as primary in enrollment and foreign in grades (the primary key must uniquely identify the records, and name is unlikely to do that in a grades database.)\n\n↩︎\n\nCREATE TABLE Customers\n\n↩︎\n\nUPDATE\n\n↩︎\n\nDELETE\n\n↩︎\n\nTRUE\n\n↩︎\n\nINSERT INTO\n\n↩︎\n\nINSERT INTO Persons VALUES (‘Jimmy’, ‘Jackson’)\n\n↩︎\n\nINSERT INTO Persons (LastName) VALUES (‘Olsen’)\n\n↩︎\n\nUPDATE Persons SET LastName=‘Nilsen’ WHERE LastName=‘Hansen’\n\n↩︎\n\nDELETE FROM Persons WHERE FirstName=‘Peter’\n\n↩︎\n\nmore than 6.3 million. Because there is no index on month (and we don’t have a year to incorporate month into the Date index), we need to look through all 48 million rows.\n\n↩︎\n\nTailnum. The cardinality is the number of unique values, and there are many more unique planes than years.\n\n↩︎\n\nTailnum. Because the cardinality is higher, it will take up much more space in the index.\n\n↩︎\n\nTailnum. Because the index is more complete, it will make the querying more efficient.\n\n↩︎\n\na = question, b = TRUE option, c = FALSE option\n\n↩︎\n\ncreates a new variable by re-coding an original variable\n\n↩︎\n\npartitions a numeric variable\n\n↩︎"
  },
  {
    "objectID": "clicker_slides.html#footnotes",
    "href": "clicker_slides.html#footnotes",
    "title": "Data Science, the SQL",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\nA relational database management system.\n\n\n\nThe first versions were created in the 1970s and called SEQUEL (Structured English QUEry Language). c. SQL came about in particular systems in the 1980s.\n\n\n\nrelational database management systems.\n\n\n\ncomputer’s hard drive / storage\n\n\n\nSQL tbl in storage and R tibble in memory\n\n\n\nSELECT\n\n\n\nSELECT FirstName FROM Persons\n\n\n\nSELECT * FROM Persons\n\n\n\nSELECT COUNT(*) FROM Persons\n\n\n\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ (d. would also work.)\n\n\n\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ AND LastName = ‘Jackson’\n\n\n\nBEWTEEN\n\n\n\nSELECT * FROM Persons WHERE LastName BETWEEN ‘Hansen’ AND ‘Pettersen’\n\n\n\nSELECT DISTINCT\n\n\n\nORDER BY\n\n\n\nSELECT * FROM Persons ORDER BY FirstName DESC\n\n\n\nTRUE\n\n\n\n… WHERE type = ‘fruit’ AND (color = ‘yellow’ OR color = ‘green’)\n\n\n\nit combines rows from two or more tables based on a related column.\n\n\n\nit combines the results of two or more SELECT statements.\n\n\n\nit combines rows from two or more tables based on a related column.\n\n\n\nit combines rows from two or more tables based on a related column.\n\n\n\nthe first table\n\n\n\nMick\n\n\n\nnone of them (all variables are kept in all joins)\n\n\n\nNULL (it would be NA in R)\n\n\nneither c. nor e. would match. Inside the bracket “[^u]” matches anything other than a “u”, but it has to match something.\n\nall of the above. Inside a character class | is a normal character and would therefore match “grey” and “gray” and “gr|y”. Which is not what we want, but would work to match both “grey” and “gray”.\n\n\n\n1 (because \\d matches only a single digit).\n\n\n\n10 (because \\d+ matches at least one digit).\n\n\n\nE (because . matches anything, and returns only a single character).\n\n\n\nEpisode 2: The pie whisperer. (4 August 2015) (because . matches anything, and with the + it returns multiple characters).\n\n\n\n. (because \\. matches the period, .).\n\n\n\n“(?&lt;=\\$)\\d+”\n\n\n\n“\\w+(?= pie)”\n\n\n\nwe return the string at the lookaround\n\n\n\nSELECT * FROM Persons WHERE FirstName REGEXP ’(?i)a.*’ (n.b., the LIKE function will give you a similar result, with % as a wildcard: SELECT*FROMPersonsWHERE` FirstName LIKE ‘a%’)\n\n\n\nPrimary key\n\n\n\nDirectly identifies another column\n\n\n\nstudent_name\n\n\n\nname as primary in enrollment and foreign in grades (the primary key must uniquely identify the records, and name is unlikely to do that in a grades database.)\n\n\n\nCREATE TABLE Customers\n\n\n\nUPDATE\n\n\n\nDELETE\n\n\n\nTRUE\n\n\n\nINSERT INTO\n\n\n\nINSERT INTO Persons VALUES (‘Jimmy’, ‘Jackson’)\n\n\n\nINSERT INTO Persons (LastName) VALUES (‘Olsen’)\n\n\n\nUPDATE Persons SET LastName=‘Nilsen’ WHERE LastName=‘Hansen’\n\n\n\nDELETE FROM Persons WHERE FirstName=‘Peter’\n\n\n\nmore than 6.3 million. Because there is no index on month (and we don’t have a year to incorporate month into the Date index), we need to look through all 48 million rows.\n\n\n\nTailnum. The cardinality is the number of unique values, and there are many more unique planes than years.\n\n\n\nTailnum. Because the cardinality is higher, it will take up much more space in the index.\n\n\n\nTailnum. Because the index is more complete, it will make the querying more efficient.\n\n\n\na = question, b = TRUE option, c = FALSE option\n\n\n\ncreates a new variable by re-coding an original variable\n\n\n\npartitions a numeric variable"
  },
  {
    "objectID": "clicker.html#footnotes",
    "href": "clicker.html#footnotes",
    "title": "Clicker Questions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\nA relational database management system.\n\n↩︎\n\nThe first versions were created in the 1970s and called SEQUEL (Structured English QUEry Language). c. SQL came about in particular systems in the 1980s.\n\n↩︎\n\nrelational database management systems.\n\n↩︎\n\ncomputer’s hard drive / storage\n\n↩︎\n\nSQL tbl in storage and R tibble in memory\n\n↩︎\n\nSELECT\n\n↩︎\n\nSELECT FirstName FROM Persons\n\n↩︎\n\nSELECT * FROM Persons\n\n↩︎\n\nSELECT COUNT(*) FROM Persons\n\n↩︎\n\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ (d. would also work.)\n\n↩︎\n\nSELECT * FROM Persons WHERE FirstName = ‘Peter’ AND LastName = ‘Jackson’\n\n↩︎\n\nBEWTEEN\n\n↩︎\n\nSELECT * FROM Persons WHERE LastName BETWEEN ‘Hansen’ AND ‘Pettersen’\n\n↩︎\n\nSELECT DISTINCT\n\n↩︎\n\nORDER BY\n\n↩︎\n\nSELECT * FROM Persons ORDER BY FirstName DESC\n\n↩︎\n\nTRUE\n\n↩︎\n\n… WHERE type = ‘fruit’ AND (color = ‘yellow’ OR color = ‘green’)\n\n↩︎\n\nit combines rows from two or more tables based on a related column.\n\n↩︎\n\nit combines the results of two or more SELECT statements.\n\n↩︎\n\nit combines rows from two or more tables based on a related column.\n\n↩︎\n\nit combines rows from two or more tables based on a related column.\n\n↩︎\n\nthe first table\n\n↩︎\n\nMick\n\n↩︎\n\nnone of them (all variables are kept in all joins)\n\n↩︎\n\nNULL (it would be NA in R)\n\n↩︎\nneither c. nor e. would match. Inside the bracket “[^u]” matches anything other than a “u”, but it has to match something.↩︎\n\nall of the above. Inside a character class | is a normal character and would therefore match “grey” and “gray” and “gr|y”. Which is not what we want, but would work to match both “grey” and “gray”.\n\n↩︎\n\n1 (because \\d matches only a single digit).\n\n↩︎\n\n10 (because \\d+ matches at least one digit).\n\n↩︎\n\nE (because . matches anything, and returns only a single character).\n\n↩︎\n\nEpisode 2: The pie whisperer. (4 August 2015) (because . matches anything, and with the + it returns multiple characters).\n\n↩︎\n\n. (because \\. matches the period, .).\n\n↩︎\n\n“(?&lt;=\\$)\\d+”\n\n↩︎\n\n“\\w+(?= pie)”\n\n↩︎\n\nwe return the string at the lookaround\n\n↩︎\n\nSELECT * FROM Persons WHERE FirstName REGEXP ’(?i)a.*’ (n.b., the LIKE function will give you a similar result, with % as a wildcard: SELECT*FROMPersonsWHERE` FirstName LIKE ‘a%’)\n\n↩︎\n\nPrimary key\n\n↩︎\n\nDirectly identifies another column\n\n↩︎\n\nstudent_name\n\n↩︎\n\nname as primary in enrollment and foreign in grades (the primary key must uniquely identify the records, and name is unlikely to do that in a grades database.)\n\n↩︎\n\nCREATE TABLE Customers\n\n↩︎\n\nUPDATE\n\n↩︎\n\nDELETE\n\n↩︎\n\nTRUE\n\n↩︎\n\nINSERT INTO\n\n↩︎\n\nINSERT INTO Persons VALUES (‘Jimmy’, ‘Jackson’)\n\n↩︎\n\nINSERT INTO Persons (LastName) VALUES (‘Olsen’)\n\n↩︎\n\nUPDATE Persons SET LastName=‘Nilsen’ WHERE LastName=‘Hansen’\n\n↩︎\n\nDELETE FROM Persons WHERE FirstName=‘Peter’\n\n↩︎\n\nmore than 6.3 million. Because there is no index on month (and we don’t have a year to incorporate month into the Date index), we need to look through all 48 million rows.\n\n↩︎\n\nTailnum. The cardinality is the number of unique values, and there are many more unique planes than years.\n\n↩︎\n\nTailnum. Because the cardinality is higher, it will take up much more space in the index.\n\n↩︎\n\nTailnum. Because the index is more complete, it will make the querying more efficient.\n\n↩︎\n\na = question, b = TRUE option, c = FALSE option\n\n↩︎\n\ncreates a new variable by re-coding an original variable\n\n↩︎\n\npartitions a numeric variable\n\n↩︎"
  },
  {
    "objectID": "handout/lab1_db_sds261_j24.html",
    "href": "handout/lab1_db_sds261_j24.html",
    "title": "Lab 1 - working with Databases",
    "section": "",
    "text": "Today’s lab will provide practice working with the different tools we can use to implement SQL code. We haven’t covered much SQL syntax, so the focus will be more on the tools than on writing code. You should, however, be trying to understand the SQL code as you go along.\nThe goals for lab 1 include:"
  },
  {
    "objectID": "syllabus.html#sds-261-januar-2024",
    "href": "syllabus.html#sds-261-januar-2024",
    "title": "syllabus",
    "section": "",
    "text": "Class: daily 10-11:30am Lab: daily (not Fridays) 1:30-3pm Office hours: daily 11:30-1:30pm\nJo Hardin\njo.hardin@pomona.edu\n\n\n\n\n\nArtwork by @allison_horst."
  },
  {
    "objectID": "syllabus.html#student-learning-outcomes.",
    "href": "syllabus.html#student-learning-outcomes.",
    "title": "syllabus",
    "section": "",
    "text": "By the end of the term, students will:\n\nDatabase Concepts: be able to explain basic database concepts such as tables, records, fields, and relationships.\nIntroduction to SQL: gain a fundamental understanding of Structured Query Language (SQL), including its history, purpose, and key components.\nSQL Querying:\n\nWriting SQL Queries: learn how to write basic SQL queries to retrieve data from a single table.\nFiltering and Sorting Data: be able to use SQL to filter and sort data based on specific criteria.\nJoining Tables: understand how to perform inner and outer joins to combine data from multiple tables.\n\nCreating Tables: be able to create a SQL database with multiple tables that link to one another using DuckDB.\nInserting and Updating Data: be able to use SQL to insert new records into a table and update existing records. Use SQL to delete records from a table.\nBasics of Regular Expressions: understand the fundamental concepts of regular expressions. Identify and use basic metacharacters for pattern matching to write simple regular expressions for text search and matching."
  },
  {
    "objectID": "handout/lab4_regexp_sds261_j24.html",
    "href": "handout/lab4_regexp_sds261_j24.html",
    "title": "Lab 4 - regular expressions",
    "section": "",
    "text": "do something with chatgpt. ask chat gpt how to answer the question. then ask using SQL then ask using stringr.\nSolution: ^(?([0-9]{3}))?[-. ]?([0-9]{3})[-. ]?([0-9]{4})$\nTest your solution on the following potential phone numbers:\nSolution: 1?[0-9]/[0-3]?[0-9]/([0-9]{2})?[0-9]{2}\nTest your solution on the following potential dates:\nSolution: ^(1|t(rue)?|y(es)?|ok(ay)?)$\n–&gt;&gt; need to figure out about lower and upper case in R / grep()\nTest your solution on the following potential responses:\nSolution: 2{1,3}(,[0-9]{3})*.[0-9]+$\nTest your solution on the following potential values:"
  },
  {
    "objectID": "syllabus.html#sds-261-january-2024",
    "href": "syllabus.html#sds-261-january-2024",
    "title": "syllabus",
    "section": "",
    "text": "Class: daily 10-11:30am\nLab: daily (not Fridays) 1:30-3pm\nOffice hours: daily 11:30-1:30pm\n\n\n\n\n\nArtwork by @allison_horst."
  },
  {
    "objectID": "handout/lab2_R_SQL_sds261_j24.html",
    "href": "handout/lab2_R_SQL_sds261_j24.html",
    "title": "Lab2 - SQL in R",
    "section": "",
    "text": "do something with NA / NULL. see hadley’s comments in the where section. https://r4ds.hadley.nz/databases#where\ndo something with distinct()\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/lab4_joins_sds261_j24.html",
    "href": "handout/lab4_joins_sds261_j24.html",
    "title": "Lab4 - joins",
    "section": "",
    "text": "according to Ben: Yelp data does not have referential integrity, and you can find reviews written by users who don’t exist and/or about restaurants that aren’t in the other table.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "Working on assignments with GitHub",
    "section": "",
    "text": "In SDS 261, we will use GitHub to access and submit assignments. Here is the basic structure of how it will work:\n\nGet the assignment materials from GitHub classroom.\nClone the repository to any machine you are using.\nWork on the assignment and push back to GitHub.\n\n\n\n\n\n\n\nimage credit: https://xkcd.com/1597/,\n\n\n\n\n\nThe following diagram lays out the process, and the rest of the document provides a more detailed set of instructions.\n\n\n\n\n\nFlowchart of assignment process."
  },
  {
    "objectID": "github.html#pull",
    "href": "github.html#pull",
    "title": "Working on assignments with GitHub",
    "section": "pull",
    "text": "pull\nIf you are working with a colleague or on different machines it is so incredibly important to get in the habit of immediately clicking on pull when you start your work. (If you are working alone on a single machine pull won’t hurt! You’ll just be told that your files are already up to date.)\n\n\n\n\n\nAlways pull before you start. pull-work-save-commit-push"
  },
  {
    "objectID": "github.html#knit-your-work",
    "href": "github.html#knit-your-work",
    "title": "Working on assignments with GitHub",
    "section": "knit your work",
    "text": "knit your work\nDon’t forget to put your name on the assignment. Also, make sure that you knit to pdf. Knit early and often. The more often you knit, the fewer headaches you will have.\n\n\n\n\n\nAlways pull before you start. pull-work-knit-commit-push"
  },
  {
    "objectID": "github.html#commit-your-work",
    "href": "github.html#commit-your-work",
    "title": "Working on assignments with GitHub",
    "section": "commit your work",
    "text": "commit your work\nYou don’t need to commit every file, but you do need to commit files that are integral to the analysis (always commit .qmd, .pdf, data files, images that created the pdf, etc.).\n\n\n\n\n\npull-work-render-commit-push"
  },
  {
    "objectID": "github.html#push-your-work-to-github",
    "href": "github.html#push-your-work-to-github",
    "title": "Working on assignments with GitHub",
    "section": "push your work to GitHub",
    "text": "push your work to GitHub\nIt is good practice to use meaningful commit messages to help your future self figure out your past work.\n\n\n\n\n\npull-work-render-commit-push"
  },
  {
    "objectID": "github.html#check-your-work-on-github",
    "href": "github.html#check-your-work-on-github",
    "title": "Working on assignments with GitHub",
    "section": "check your work on GitHub",
    "text": "check your work on GitHub\nTo make sure that the work went through, always check your GitHub repo online to confirm any changes you made.\n\n\n\n\n\nCheck that your changes are correct.\n\n\n\n\nYou can submit multiple times before the deadline. Your last submission will be assessed.\nOnce assignments are assessed, you will be able to see feedback on GitHub. You can pull assignment feedback back onto your own computer."
  },
  {
    "objectID": "project.html#big-picture",
    "href": "project.html#big-picture",
    "title": "Project",
    "section": "Big picture",
    "text": "Big picture\nYour project is meant to answer a question using data. The vast majority of the work will be on the data wrangling side, but you might hope to have a plot or two at the end to help tie together your ideas.\n\nTopics\nThe topics above are meant to direct the project productively. They are not meant to limit you. If you have an idea for a project that doesn’t quite fit into what is outlined above (but is related to the course content), let’s talk about it! Most likely, your idea will fit into the project goals.\nExpanding on the topics above to get you started…\n\n1. SQL queries\nThroughout the course, we’ve seen a few different databases. There are more available in the R mdsr package, and you also have access to some additional MySQL server databases through Smith. Additionally, the professor has access to a MySQL server that contains all of the Stanford Open Policing data, and you are welcome to work with it (just ask for login information). So many interesting questions to consider!\n\n\n2. Regular expressions\nYou might think about web scraping to retrieve data (probably using the rvest R package). For example, you might scrape details about every Taylor Swift song and use regular expressions to format the information in a way that allows easy question asking.\nOr you might find a dataset on the Gilmore Girls and scrape IMDb to match the ratings for each episode.\n\n\n3. Creating SQL database\nYou can use any of a variety of platforms to create a SQL database. As in the class notes and labs, you can create a database using DuckDB. Alternatively, you can use Smith’s MySQL server. Or, you can use SQLite to create a database (in a similar way to DuckDB).\nFor example, you might create a database using the Saturday Night Live data and update all of the files with more recent episodes.\nOr you might look for a TidyTuesday dataset to upload. For example, consider data on cats in the UK which references similar datasets in the US, Australia, and New Zealand.\nIf you are creating a new SQL database, make sure that your database has three or more tables that link to one another."
  },
  {
    "objectID": "project.html#technical-details",
    "href": "project.html#technical-details",
    "title": "Project",
    "section": "Technical details",
    "text": "Technical details\n\nYou may work alone or in pairs.\nThere must be a narrative to accompany all technical products including code, output tables, visualizations, etc. No naked code or graphs. (Figures and Tables should have captions.)\nThe expectation is that you turn in a reproducible Quarto file and accompanying pdf or html file. If you plan to turn in the project in a different format, please check with the professor in advance.\n\n\nDue Dates\n\nTuesday, January 16. Email prof with dataset details and idea for project. Include the following:\n\nQuestion of interest that you hope to address.\nHolistic description of the dataset(s) (a few sentences).\nDescription of the observational units and columns in each data table.\nFull reference for data citation.\nLink to the resources.\n\nEnd of week 2. We will have some time in class to work on the project.\nTuesday, January 23. Completed project is due."
  },
  {
    "objectID": "slides/2024-01-08-db.html#what-is-a-database",
    "href": "slides/2024-01-08-db.html#what-is-a-database",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "What is a database?",
    "text": "What is a database?\n\nstructured collection of data organized with\n\nefficient storage\neasy retrieval\nconsistent management\n\ndata stored in tables which are linked to one another via keys"
  },
  {
    "objectID": "slides/2024-01-08-db.html#tidy-data",
    "href": "slides/2024-01-08-db.html#tidy-data",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "Tidy data",
    "text": "Tidy data\n\ndata frame (R) or table (SQL)\ncolumns of variables\nrows of observational units"
  },
  {
    "objectID": "slides/2024-01-08-db.html#differences-between-r-and-sql",
    "href": "slides/2024-01-08-db.html#differences-between-r-and-sql",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "Differences between R and SQL",
    "text": "Differences between R and SQL\n\ntables in SQL databases can be arbitrarily large\n\nlive in storage, computer’s hard drive (usually remote)\n\ndata frames in R\n\nlive in memory (RAM) on your personal computer\n\ntables in a database are linked via a key."
  },
  {
    "objectID": "slides/2024-01-08-db.html#sql-connection",
    "href": "slides/2024-01-08-db.html#sql-connection",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "SQL connection",
    "text": "SQL connection\nTo set up a SQL connection, you need the location of the server (host) as well as a username and password.\n\ncon_air &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"airlines\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)\n\nHadley Wickham discusses how to use Sys.getenv: https://cran.r-project.org/web/packages/httr/vignettes/secrets.html"
  },
  {
    "objectID": "slides/2024-01-08-db.html#sql-tables-as-tbl",
    "href": "slides/2024-01-08-db.html#sql-tables-as-tbl",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "SQL tables as tbl",
    "text": "SQL tables as tbl\n\ncarriers &lt;- dplyr::tbl(con_air, \"carriers\")\ndim(carriers)\n\n[1] NA  2\n\nhead(carriers)\n\n# Source:   SQL [6 x 2]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  carrier name                         \n  &lt;chr&gt;   &lt;chr&gt;                        \n1 02Q     Titan Airways                \n2 04Q     Tradewind Aviation           \n3 05Q     Comlux Aviation, AG          \n4 06Q     Master Top Linhas Aereas Ltd.\n5 07Q     Flair Airlines Ltd.          \n6 09Q     Swift Air, LLC"
  },
  {
    "objectID": "slides/2024-01-08-db.html#sql-tables-as-tibble",
    "href": "slides/2024-01-08-db.html#sql-tables-as-tibble",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "SQL tables as tibble",
    "text": "SQL tables as tibble\nThe function collect() copies a SQL table from it’s server location on disk to your local memory location in R.\n\ncarriers_tibble &lt;- carriers |&gt;\n  dplyr::collect()\n\ndim(carriers_tibble)\n\n[1] 1610    2\n\nhead(carriers_tibble)\n\n# A tibble: 6 × 2\n  carrier name                         \n  &lt;chr&gt;   &lt;chr&gt;                        \n1 02Q     Titan Airways                \n2 04Q     Tradewind Aviation           \n3 05Q     Comlux Aviation, AG          \n4 06Q     Master Top Linhas Aereas Ltd.\n5 07Q     Flair Airlines Ltd.          \n6 09Q     Swift Air, LLC"
  },
  {
    "objectID": "slides/2024-01-08-db.html#how-much-space-does-carriers-take-up",
    "href": "slides/2024-01-08-db.html#how-much-space-does-carriers-take-up",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "How much space does carriers take up?",
    "text": "How much space does carriers take up?\nThe data frame in R takes up 2 orders of magnitude of memory more than the table which just points to the object in SQL.\n\ncarriers |&gt;\n  object.size() |&gt;\n  print(units = \"Kb\")\n\n5.2 Kb\n\ncarriers_tibble |&gt;\n  object.size() |&gt;\n  print(units = \"Kb\")\n\n234.8 Kb"
  },
  {
    "objectID": "slides/2024-01-08-db.html#what-is-sql-structured-query-language",
    "href": "slides/2024-01-08-db.html#what-is-sql-structured-query-language",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "What is SQL (Structured Query Language) ?",
    "text": "What is SQL (Structured Query Language) ?\n\nSQL is a programming language for working with relational databases.\nSQL has been around since the 1970s, but has, unfortunately, many different dialects.\nTo connect to the Smith and mdsr databases (via R and DBeaver), we will use MySQL.\nTo connect to DuckDB, we will use the dialect native to DuckDB."
  },
  {
    "objectID": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql",
    "href": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\nThe function dbListTables() in the DBI package will tell us what tables exist in the airlines database.\n\nDBI::dbListTables(con_air)\n\n[1] \"airports\" \"carriers\" \"flights\"  \"planes\"  \n\nflights &lt;- dplyr::tbl(con_air, \"flights\")\ncarriers &lt;- dplyr::tbl(con_air, \"carriers\")"
  },
  {
    "objectID": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-1",
    "href": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-1",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\n\nOver what years is the flights data taken?\n\n\nyrs &lt;- flights |&gt;\n  summarize(min_year = min(year), max_year = max(year))\n\nyrs\n\n# Source:   SQL [1 x 2]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  min_year max_year\n     &lt;int&gt;    &lt;int&gt;\n1     2010     2017"
  },
  {
    "objectID": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-2",
    "href": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-2",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\nBecause flights is not actually a data.frame in R (but instead a tbl in SQL), the work that was done above was actually performed in SQL. To see the SQL code, we can use the function show_query.\n\ndplyr::show_query(yrs)\n\n&lt;SQL&gt;\nSELECT MIN(`year`) AS `min_year`, MAX(`year`) AS `max_year`\nFROM `flights`"
  },
  {
    "objectID": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-3",
    "href": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-3",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\n\nCreate a data set containing only flights between LAX and BOS in 2012.\n\n\nla_bos &lt;- flights |&gt;\n  filter(year == 2012 & ((origin == \"LAX\" & dest == \"BOS\") | \n           (origin == \"BOS\" & dest == \"LAX\"))) \n\ndplyr::show_query(la_bos)\n\n&lt;SQL&gt;\nSELECT *\nFROM `flights`\nWHERE (`year` = 2012.0 AND ((`origin` = 'LAX' AND `dest` = 'BOS') OR (`origin` = 'BOS' AND `dest` = 'LAX')))"
  },
  {
    "objectID": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-4",
    "href": "slides/2024-01-08-db.html#translating-dplyr-code-into-sql-4",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\n\ndbplyr doesn’t translate every R command into SQL.\nSQL is not a statistical software and doesn’t, for example, have a mechanism for creating data visualizations.\ntrack which R commands are connected to SQL at the dbplyr reference sheet."
  },
  {
    "objectID": "slides/2024-01-08-db.html#sql-queries-through-the-dbi-package",
    "href": "slides/2024-01-08-db.html#sql-queries-through-the-dbi-package",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "2. SQL queries through the DBI package",
    "text": "2. SQL queries through the DBI package\n\nLook at the first few rows of the flights data.\n\n\nDBI::dbGetQuery(con_air,\n                \"SELECT * FROM flights LIMIT 8;\")\n\n  year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n1 2010    10   1        1           2100       181      159           2320\n2 2010    10   1        1           1920       281      230           2214\n3 2010    10   1        3           2355         8      339            334\n4 2010    10   1        5           2200       125       41           2249\n5 2010    10   1        7           2245        82      104           2347\n6 2010    10   1        7             10        -3      451            500\n7 2010    10   1        7           2150       137      139           2337\n8 2010    10   1        8             15        -7      538            537\n  arr_delay carrier tailnum flight origin dest air_time distance cancelled\n1       159      XE  N11137   2558    EWR  OMA      162     1133         0\n2       256      B6  N659JB    562    FLL  SWF      131     1119         0\n3         5      B6  N563JB    701    JFK  SJU      196     1597         0\n4       112      XE  N16559   5982    IAD  BNA       82      542         0\n5        77      OO  N908SW   6433    LAX  FAT       37      209         0\n6        -9      AA  N3FRAA    700    LAX  DFW      150     1235         0\n7       122      DL  N347NW   1752    ATL  IAD       70      533         0\n8         1      CO  N73283   1740    SMF  IAH      193     1609         0\n  diverted hour minute           time_hour\n1        0   21      0 2010-10-01 21:00:00\n2        0   19     20 2010-10-01 19:20:00\n3        0   23     55 2010-10-01 23:55:00\n4        0   22      0 2010-10-01 22:00:00\n5        0   22     45 2010-10-01 22:45:00\n6        0    0     10 2010-10-01 00:10:00\n7        0   21     50 2010-10-01 21:50:00\n8        0    0     15 2010-10-01 00:15:00"
  },
  {
    "objectID": "slides/2024-01-08-db.html#sql-queries-through-the-dbi-package-1",
    "href": "slides/2024-01-08-db.html#sql-queries-through-the-dbi-package-1",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "2. SQL queries through the DBI package",
    "text": "2. SQL queries through the DBI package\n\nHow many flights per year are in the flights table?\n\n\ndbGetQuery(con_air, \n  \"SELECT year, count(*) AS num_flights FROM flights GROUP BY year ORDER BY num_flights;\")\n\n  year num_flights\n1 2016     5617658\n2 2017     5674621\n3 2015     5819079\n4 2014     5819811\n5 2011     6085281\n6 2012     6096762\n7 2013     6369482\n8 2010     6450117"
  },
  {
    "objectID": "slides/2024-01-08-db.html#direct-sql-queries-through-a-sql-chunk",
    "href": "slides/2024-01-08-db.html#direct-sql-queries-through-a-sql-chunk",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "3. Direct SQL queries through a sql chunk",
    "text": "3. Direct SQL queries through a sql chunk\nSQL queries can be written directly inside a sql chunk in RStudio.\n\n```{sql}\n#| connection: con_air\n\nSELECT * FROM flights LIMIT 8;\n```\n\n\n\n\n8 records\n\n\n\n\nyear\n\n\nmonth\n\n\nday\n\n\ndep_time\n\n\nsched_dep_time\n\n\ndep_delay\n\n\narr_time\n\n\nsched_arr_time\n\n\narr_delay\n\n\ncarrier\n\n\ntailnum\n\n\nflight\n\n\norigin\n\n\ndest\n\n\nair_time\n\n\ndistance\n\n\ncancelled\n\n\ndiverted\n\n\nhour\n\n\nminute\n\n\ntime_hour\n\n\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n1\n\n\n2100\n\n\n181\n\n\n159\n\n\n2320\n\n\n159\n\n\nXE\n\n\nN11137\n\n\n2558\n\n\nEWR\n\n\nOMA\n\n\n162\n\n\n1133\n\n\n0\n\n\n0\n\n\n21\n\n\n0\n\n\n2010-10-01 21:00:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n1\n\n\n1920\n\n\n281\n\n\n230\n\n\n2214\n\n\n256\n\n\nB6\n\n\nN659JB\n\n\n562\n\n\nFLL\n\n\nSWF\n\n\n131\n\n\n1119\n\n\n0\n\n\n0\n\n\n19\n\n\n20\n\n\n2010-10-01 19:20:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n3\n\n\n2355\n\n\n8\n\n\n339\n\n\n334\n\n\n5\n\n\nB6\n\n\nN563JB\n\n\n701\n\n\nJFK\n\n\nSJU\n\n\n196\n\n\n1597\n\n\n0\n\n\n0\n\n\n23\n\n\n55\n\n\n2010-10-01 23:55:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n5\n\n\n2200\n\n\n125\n\n\n41\n\n\n2249\n\n\n112\n\n\nXE\n\n\nN16559\n\n\n5982\n\n\nIAD\n\n\nBNA\n\n\n82\n\n\n542\n\n\n0\n\n\n0\n\n\n22\n\n\n0\n\n\n2010-10-01 22:00:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n2245\n\n\n82\n\n\n104\n\n\n2347\n\n\n77\n\n\nOO\n\n\nN908SW\n\n\n6433\n\n\nLAX\n\n\nFAT\n\n\n37\n\n\n209\n\n\n0\n\n\n0\n\n\n22\n\n\n45\n\n\n2010-10-01 22:45:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n10\n\n\n-3\n\n\n451\n\n\n500\n\n\n-9\n\n\nAA\n\n\nN3FRAA\n\n\n700\n\n\nLAX\n\n\nDFW\n\n\n150\n\n\n1235\n\n\n0\n\n\n0\n\n\n0\n\n\n10\n\n\n2010-10-01 00:10:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n2150\n\n\n137\n\n\n139\n\n\n2337\n\n\n122\n\n\nDL\n\n\nN347NW\n\n\n1752\n\n\nATL\n\n\nIAD\n\n\n70\n\n\n533\n\n\n0\n\n\n0\n\n\n21\n\n\n50\n\n\n2010-10-01 21:50:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n8\n\n\n15\n\n\n-7\n\n\n538\n\n\n537\n\n\n1\n\n\nCO\n\n\nN73283\n\n\n1740\n\n\nSMF\n\n\nIAH\n\n\n193\n\n\n1609\n\n\n0\n\n\n0\n\n\n0\n\n\n15\n\n\n2010-10-01 00:15:00"
  },
  {
    "objectID": "slides/2024-01-08-db.html#direct-sql-queries-through-a-sql-chunk-1",
    "href": "slides/2024-01-08-db.html#direct-sql-queries-through-a-sql-chunk-1",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "3. Direct SQL queries through a sql chunk",
    "text": "3. Direct SQL queries through a sql chunk\nSQL queries can be written directly inside a sql chunk in RStudio.\n\n```{sql}\n#| connection: con_air\n\nSELECT year, count(*) AS num_flights \n       FROM flights \n       GROUP BY year \n       ORDER BY num_flights;\n```\n\n\n\n\n8 records\n\n\n\n\nyear\n\n\nnum_flights\n\n\n\n\n\n\n2016\n\n\n5617658\n\n\n\n\n2017\n\n\n5674621\n\n\n\n\n2015\n\n\n5819079\n\n\n\n\n2014\n\n\n5819811\n\n\n\n\n2011\n\n\n6085281\n\n\n\n\n2012\n\n\n6096762\n\n\n\n\n2013\n\n\n6369482\n\n\n\n\n2010\n\n\n6450117"
  },
  {
    "objectID": "slides/2024-01-08-db.html#sql-queries-via-the-dbi-package",
    "href": "slides/2024-01-08-db.html#sql-queries-via-the-dbi-package",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "2. SQL queries via the DBI package",
    "text": "2. SQL queries via the DBI package\n\nLook at the first few rows of the flights data.\n\n\nDBI::dbGetQuery(con_air,\n                \"SELECT * FROM flights LIMIT 8;\")\n\n  year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n1 2010    10   1        1           2100       181      159           2320\n2 2010    10   1        1           1920       281      230           2214\n3 2010    10   1        3           2355         8      339            334\n4 2010    10   1        5           2200       125       41           2249\n5 2010    10   1        7           2245        82      104           2347\n6 2010    10   1        7             10        -3      451            500\n7 2010    10   1        7           2150       137      139           2337\n8 2010    10   1        8             15        -7      538            537\n  arr_delay carrier tailnum flight origin dest air_time distance cancelled\n1       159      XE  N11137   2558    EWR  OMA      162     1133         0\n2       256      B6  N659JB    562    FLL  SWF      131     1119         0\n3         5      B6  N563JB    701    JFK  SJU      196     1597         0\n4       112      XE  N16559   5982    IAD  BNA       82      542         0\n5        77      OO  N908SW   6433    LAX  FAT       37      209         0\n6        -9      AA  N3FRAA    700    LAX  DFW      150     1235         0\n7       122      DL  N347NW   1752    ATL  IAD       70      533         0\n8         1      CO  N73283   1740    SMF  IAH      193     1609         0\n  diverted hour minute           time_hour\n1        0   21      0 2010-10-01 21:00:00\n2        0   19     20 2010-10-01 19:20:00\n3        0   23     55 2010-10-01 23:55:00\n4        0   22      0 2010-10-01 22:00:00\n5        0   22     45 2010-10-01 22:45:00\n6        0    0     10 2010-10-01 00:10:00\n7        0   21     50 2010-10-01 21:50:00\n8        0    0     15 2010-10-01 00:15:00"
  },
  {
    "objectID": "slides/2024-01-08-db.html#sql-queries-via-the-dbi-package-1",
    "href": "slides/2024-01-08-db.html#sql-queries-via-the-dbi-package-1",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "2. SQL queries via the DBI package",
    "text": "2. SQL queries via the DBI package\n\nHow many flights per year are in the flights table?\n\n\nDBI::dbGetQuery(con_air, \n  \"SELECT year, count(*) AS num_flights FROM flights GROUP BY year ORDER BY num_flights;\")\n\n  year num_flights\n1 2016     5617658\n2 2017     5674621\n3 2015     5819079\n4 2014     5819811\n5 2011     6085281\n6 2012     6096762\n7 2013     6369482\n8 2010     6450117"
  },
  {
    "objectID": "slides/2024-01-08-db.html#direct-sql-queries-via-sql-chunks",
    "href": "slides/2024-01-08-db.html#direct-sql-queries-via-sql-chunks",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "3. Direct SQL queries via sql chunks",
    "text": "3. Direct SQL queries via sql chunks\nSQL queries can be written directly inside a sql chunk in RStudio.\n\n```{sql}\n#| connection: con_air\n\nSELECT * FROM flights LIMIT 8;\n```\n\n\n\n\n8 records\n\n\n\n\nyear\n\n\nmonth\n\n\nday\n\n\ndep_time\n\n\nsched_dep_time\n\n\ndep_delay\n\n\narr_time\n\n\nsched_arr_time\n\n\narr_delay\n\n\ncarrier\n\n\ntailnum\n\n\nflight\n\n\norigin\n\n\ndest\n\n\nair_time\n\n\ndistance\n\n\ncancelled\n\n\ndiverted\n\n\nhour\n\n\nminute\n\n\ntime_hour\n\n\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n1\n\n\n2100\n\n\n181\n\n\n159\n\n\n2320\n\n\n159\n\n\nXE\n\n\nN11137\n\n\n2558\n\n\nEWR\n\n\nOMA\n\n\n162\n\n\n1133\n\n\n0\n\n\n0\n\n\n21\n\n\n0\n\n\n2010-10-01 21:00:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n1\n\n\n1920\n\n\n281\n\n\n230\n\n\n2214\n\n\n256\n\n\nB6\n\n\nN659JB\n\n\n562\n\n\nFLL\n\n\nSWF\n\n\n131\n\n\n1119\n\n\n0\n\n\n0\n\n\n19\n\n\n20\n\n\n2010-10-01 19:20:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n3\n\n\n2355\n\n\n8\n\n\n339\n\n\n334\n\n\n5\n\n\nB6\n\n\nN563JB\n\n\n701\n\n\nJFK\n\n\nSJU\n\n\n196\n\n\n1597\n\n\n0\n\n\n0\n\n\n23\n\n\n55\n\n\n2010-10-01 23:55:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n5\n\n\n2200\n\n\n125\n\n\n41\n\n\n2249\n\n\n112\n\n\nXE\n\n\nN16559\n\n\n5982\n\n\nIAD\n\n\nBNA\n\n\n82\n\n\n542\n\n\n0\n\n\n0\n\n\n22\n\n\n0\n\n\n2010-10-01 22:00:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n2245\n\n\n82\n\n\n104\n\n\n2347\n\n\n77\n\n\nOO\n\n\nN908SW\n\n\n6433\n\n\nLAX\n\n\nFAT\n\n\n37\n\n\n209\n\n\n0\n\n\n0\n\n\n22\n\n\n45\n\n\n2010-10-01 22:45:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n10\n\n\n-3\n\n\n451\n\n\n500\n\n\n-9\n\n\nAA\n\n\nN3FRAA\n\n\n700\n\n\nLAX\n\n\nDFW\n\n\n150\n\n\n1235\n\n\n0\n\n\n0\n\n\n0\n\n\n10\n\n\n2010-10-01 00:10:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n2150\n\n\n137\n\n\n139\n\n\n2337\n\n\n122\n\n\nDL\n\n\nN347NW\n\n\n1752\n\n\nATL\n\n\nIAD\n\n\n70\n\n\n533\n\n\n0\n\n\n0\n\n\n21\n\n\n50\n\n\n2010-10-01 21:50:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n8\n\n\n15\n\n\n-7\n\n\n538\n\n\n537\n\n\n1\n\n\nCO\n\n\nN73283\n\n\n1740\n\n\nSMF\n\n\nIAH\n\n\n193\n\n\n1609\n\n\n0\n\n\n0\n\n\n0\n\n\n15\n\n\n2010-10-01 00:15:00"
  },
  {
    "objectID": "slides/2024-01-08-db.html#direct-sql-queries-via-sql-chunks-1",
    "href": "slides/2024-01-08-db.html#direct-sql-queries-via-sql-chunks-1",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "3. Direct SQL queries via sql chunks",
    "text": "3. Direct SQL queries via sql chunks\nSQL queries can be written directly inside a sql chunk in RStudio.\n\n```{sql}\n#| connection: con_air\n\nSELECT year, count(*) AS num_flights \n       FROM flights \n       GROUP BY year \n       ORDER BY num_flights;\n```\n\n\n\n\n8 records\n\n\n\n\nyear\n\n\nnum_flights\n\n\n\n\n\n\n2016\n\n\n5617658\n\n\n\n\n2017\n\n\n5674621\n\n\n\n\n2015\n\n\n5819079\n\n\n\n\n2014\n\n\n5819811\n\n\n\n\n2011\n\n\n6085281\n\n\n\n\n2012\n\n\n6096762\n\n\n\n\n2013\n\n\n6369482\n\n\n\n\n2010\n\n\n6450117"
  },
  {
    "objectID": "handout/lab1_db_sds261_j24.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab1_db_sds261_j24.html#advice-for-turning-in-the-assignment",
    "title": "Lab 1 - working with Databases",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nrender early and often. In fact, go ahead and render your .qmd file right now. Maybe set a timer so that you render every 5 minutes. Do not wait until you are done with the assignment to render\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox."
  },
  {
    "objectID": "github.html#render-your-work",
    "href": "github.html#render-your-work",
    "title": "Working on assignments with GitHub",
    "section": "render your work",
    "text": "render your work\nDon’t forget to put your name on the assignment. Also, make sure that you render to pdf. Render early and often. The more often you render, the fewer headaches you will have.\n\n\n\n\n\nAlways pull before you start. pull-work-render-commit-push"
  },
  {
    "objectID": "slides/2024-01-08-db.html#steps-for-weekly-homework",
    "href": "slides/2024-01-08-db.html#steps-for-weekly-homework",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "Steps for weekly homework",
    "text": "Steps for weekly homework\n\nReceive a link to the new assignment (clicking on the link will create a new private repo)\n\nUse RStudio\n\nNew Project, version control, Git\n\nClone the repo using SSH\n\n\nCreate a new file sds261-lab#-lname-fname.qmd. (If the .qmd file already exists, rename the file to sds261-lab#-lname-fname.qmd.)\nDo the assignment\n\ncommit and push after every problem\n\n\nFor work done in DBeaver (.sql files), use the same naming convention: sds261-lab#-lname-fname.sql.\nAll necessary files must be in the same folder (e.g., data, .sql files, etc.)"
  },
  {
    "objectID": "handout/lab1_db_sds261_j24.html#assignment",
    "href": "handout/lab1_db_sds261_j24.html#assignment",
    "title": "Lab 1 - working with Databases",
    "section": "Assignment",
    "text": "Assignment\nPreliminary: You’ll need to create a quarto document. To do so click on: New file -&gt; quarto document.\n\nThe document should be saved in the R Project as lab1-sds261-yourlastname-yourfirstname.qmd.\nThe yaml at the top of the file should look like this (change the author and date fields):\n\n---\ntitle: 'Lab 1 - working with Databases'\nauthor: 'your name goes here'\ndate: 'due 10am Tuesday, January 9, 2024'\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\nFor much of the assignment, Consider the task of figuring out how many flights came into or flew out of Bradley International Airport (BDL) last year.\n\nSet up a connection within an R chunk. See the README file.\n\n\nPull in the flights table as a tbl (do not use collect()!). Use dplyr commands to calculate the number of flights that flew into or out of BDL in 2012. Then use dplyr::show_query() to output the SQL query. (All done inside an R chunk.)\n\n\nAgain, inside an R chunk, use DBI::dbGetQuery() to run the SQL code calculated in the previous question.\n\n\nNow, inside a SQL chunk, use the SQL commands directly (same task: how many flights in and out of BDL in 2012).\n\n\nRerun all three scenarios, using the tictoc R package to see which method calculates the desired number most quickly. Below is an example of how to use tictoc. For the SQL chunk, you’ll need to place tic() in an R chunk before the SQL chunk and toc() in an R chunk after the SQL chunk. Write 1-2 sentences describing the results.\n\n\nlibrary(tictoc)\n\ntic()\nrand_numbers &lt;- rnorm(1000000)\nquantile(rand_numbers)\n\n           0%           25%           50%           75%          100% \n-4.7441954424 -0.6750814407  0.0006767307  0.6734974364  5.6445201338 \n\ntoc()\n\n0.097 sec elapsed\n\n\n\nUsing R on the tbl.\n\n\nUsing dbGetQuery().\n\n\nUsing SQL chunk.\n\n\nNow create a tibble (not a tbl) that includes only flights in 2012 either to or from BDL (use collect()). After you have created the tibble, summarize the observations to get the count. Use tictoc to evaluate how long the process takes. Write 1-2 sentences describing the results.\n\n\nDBeaver: open DBeaver from your applications. Following the instructions in the DBeaver online notes, set up a connection to the mdsr SQL server. Create a file called lab1-sds261-yourlastname-yourfirstname.sql and SAVE THE FILE in the lab1 R Project folder. Run the same SQL code as above. Did you get the same result? Were there any adjustments to the SQL code from above? Explain in a few sentences.\n\n\nReflect on at least 3 things that you learned during this lab. It could be about technical aspects. It could be about understanding databases. It could be about the difference between R and SQL. Anything you learned while doing the lab.\n\n\nAlways a good idea to terminate the SQL connection when you are done with it.\n\n\ndbDisconnect(con_air, shutdown = TRUE)\n\n\nrender - commit - push to GitHub. You should push three files, those with extensions .qmd, .html, and .sql. In a browser, look at your GitHub website to make sure that all three files were successfully pushed to the correct repo (yours for lab1)."
  },
  {
    "objectID": "slides/2024-01-08-db.html#good-practice",
    "href": "slides/2024-01-08-db.html#good-practice",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "Good practice",
    "text": "Good practice\nAlways a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_air, shutdown = TRUE)"
  },
  {
    "objectID": "handout/lab1_db_sds261_j24_sol.html",
    "href": "handout/lab1_db_sds261_j24_sol.html",
    "title": "Lab 1 - working with Databases",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(mdsr)\nToday’s lab will provide practice working with the different tools we can use to implement SQL code. We haven’t covered much SQL syntax, so the focus will be more on the tools than on writing code. You should, however, be trying to understand the SQL code as you go along.\nThe goals for lab 1 include:"
  },
  {
    "objectID": "handout/lab1_db_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab1_db_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "title": "Lab 1 - working with Databases",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nrender early and often. In fact, go ahead and render your .qmd file right now. Maybe set a timer so that you render every 5 minutes. Do not wait until you are done with the assignment to render\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox."
  },
  {
    "objectID": "handout/lab1_db_sds261_j24_sol.html#assignment",
    "href": "handout/lab1_db_sds261_j24_sol.html#assignment",
    "title": "Lab 1 - working with Databases",
    "section": "Assignment",
    "text": "Assignment\nPreliminary: You’ll need to create a quarto document. To do so click on: New file -&gt; quarto document.\n\nThe document should be saved in the R Project as lab1-sds261-yourlastname-yourfirstname.qmd.\nThe yaml at the top of the file should look like this (change the author and date fields):\n\n---\ntitle: 'Lab 1 - working with Databases'\nauthor: 'your name goes here'\ndate: 'due 10am Tuesday, January 9, 2024'\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\nFor much of the assignment, Consider the task of figuring out how many flights came into or flew out of Bradley International Airport (BDL) last year.\n\nSet up a connection within an R chunk. See the README file.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncon_air &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"airlines\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)\n\n\n\n\n\nPull in the flights table as a tbl (do not use collect()!). Use dplyr commands to calculate the number of flights that flew into or out of BDL in 2012. Then use dplyr::show_query() to output the SQL query. (All done inside an R chunk.)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nflights &lt;- tbl(con_air, \"flights\")\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"tailnum\"        \"flight\"        \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"cancelled\"      \"diverted\"       \"hour\"           \"minute\"        \n[21] \"time_hour\"     \n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbdl_query &lt;- flights |&gt;\n  filter(year == 2012 & (dest == \"BDL\" | origin == \"BDL\")) |&gt;\n  summarize(count = n())\n\nshow_query(bdl_query)\n\n&lt;SQL&gt;\nSELECT COUNT(*) AS `count`\nFROM `flights`\nWHERE (`year` = 2012.0 AND (`dest` = 'BDL' OR `origin` = 'BDL'))\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere were 41,949 flights to or from BDL in 2012.\n\n\n\n\n\nAgain, inside an R chunk, use DBI::dbGetQuery() to run the SQL code calculated in the previous question.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDBI::dbGetQuery(con_air, \"SELECT COUNT(*) AS `count`\nFROM `flights`\nWHERE (`year` = 2012 AND (`dest` = 'BDL' OR `origin` = 'BDL'))\")\n\n  count\n1 41949\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere were 41,949 flights to or from BDL in 2012.\n\n\n\n\n\nNow, inside a SQL chunk, use the SQL commands directly (same task: how many flights in and out of BDL in 2012).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n```{sql}\n#| connection: con_air\n#| unilur-solution: true\n\nSELECT COUNT(*) AS `count`\nFROM `flights`\nWHERE (`year` = 2012 AND (`dest` = 'BDL' OR `origin` = 'BDL'))\n```\n\n\n1 records\n\n\ncount\n\n\n\n\n41949\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere were 41,949 flights to or from BDL in 2012.\n\n\n\n\n\nRerun all three scenarios, using the tictoc R package to see which method calculates the desired number most quickly. Below is an example of how to use tictoc. For the SQL chunk, you’ll need to place tic() in an R chunk before the SQL chunk and toc() in an R chunk after the SQL chunk. Write 1-2 sentences describing the results.\n\n\nlibrary(tictoc)\n\ntic()\nrand_numbers &lt;- rnorm(1000000)\nquantile(rand_numbers)\n\n           0%           25%           50%           75%          100% \n-4.7441954424 -0.6750814407  0.0006767307  0.6734974364  5.6445201338 \n\ntoc()\n\n0.097 sec elapsed\n\n\n\nUsing R on the tbl.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntic()\n\nflights &lt;- tbl(con_air, \"flights\")\n\nflights |&gt;\n  filter(year == 2012 & (dest == \"BDL\" | origin == \"BDL\")) |&gt;\n  summarize(count = n())\n\n# Source:   SQL [1 x 1]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n    count\n  &lt;int64&gt;\n1   41949\n\ntoc()\n\n5.526 sec elapsed\n\n\n\n\n\n\nUsing dbGetQuery().\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntic()\n\nDBI::dbGetQuery(con_air, \"SELECT COUNT(*) AS `count`\nFROM `flights`\nWHERE (`year` = 2012 AND (`dest` = 'BDL' OR `origin` = 'BDL'))\")\n\n  count\n1 41949\n\ntoc()\n\n5.258 sec elapsed\n\n\n\n\n\n\nUsing SQL chunk.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntic()\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n```{sql}\n#| connection: con_air\n#| unilur-solution: true\n\nSELECT COUNT(*) AS `count`\nFROM `flights`\nWHERE (`year` = 2012 AND (`dest` = 'BDL' OR `origin` = 'BDL'))\n```\n\n\n1 records\n\n\ncount\n\n\n\n\n41949\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntoc()\n\n5.515 sec elapsed\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nRunning the SQL code (either directly through a SQL chunk or by using DBI::dbGetQuery()) is faster than when dbplyr is used to translate R code into SQL queries.\n\n\n\n\n\nNow create a tibble (not a tbl) that includes only flights in 2012 either to or from BDL (use collect()). After you have created the tibble, summarize the observations to get the count. Use tictoc to evaluate how long the process takes. Write 1-2 sentences describing the results.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntic()\n\nflights_BDL &lt;- flights |&gt;\n  filter(year == 2012 & (dest == \"BDL\" | origin == \"BDL\")) |&gt;\n  collect()\n\nflights_BDL |&gt;\n  summarize(count = n())\n\n# A tibble: 1 × 1\n  count\n  &lt;int&gt;\n1 41949\n\ntoc()\n\n5.538 sec elapsed\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPulling the table into R as a dataframe slows down the calculations quite a bit.\n\n\n\n\n\nDBeaver: open DBeaver from your applications. Following the instructions in the DBeaver online notes, set up a connection to the mdsr SQL server. Create a file called lab1-sds261-yourlastname-yourfirstname.sql and SAVE THE FILE in the lab1 R Project folder. Run the same SQL code as above. Did you get the same result? Were there any adjustments to the SQL code from above? Explain in a few sentences.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nYes, there were still 41,949 flights to and from BDL in 2012. Whew! It would have been very odd if there had been a different number because the database itself hasn’t changed at all, we are just sending the query using a different client.\nI needed to remove the back ticks from the table and variable names. R uses backticks but DBeaver does not. Good to remember.\nI had set up my connection to the entire mdsr database, so I needed to add the line USE airlines; to the top of my SQL query so that it would be able to find the flights table. I could have also specified where flights lives using: ... FROM airlines.flights....\n\n\n\n\n\nReflect on at least 3 things that you learned during this lab. It could be about technical aspects. It could be about understanding databases. It could be about the difference between R and SQL. Anything you learned while doing the lab.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\nthere are different ways to run the same SQL commands\nsome approaches are more efficient than other approaches\nthe RStudio IDE is flexible in that it allows both R and SQL code\nDBeaver is a more typical SQL client in that many lines of SQL code can be written simultaneously, and the SQL connection says in tact for the entire set of queries.\nthe airlines database has a ginormous about of information which exists in four tables: airports, carriers, flights, and planes\n\n\n\n\n\n\nAlways a good idea to terminate the SQL connection when you are done with it.\n\n\ndbDisconnect(con_air, shutdown = TRUE)\n\n\nrender - commit - push to GitHub. You should push three files, those with extensions .qmd, .html, and .sql. In a browser, look at your GitHub website to make sure that all three files were successfully pushed to the correct repo (yours for lab1)."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#nyc-taxis",
    "href": "slides/2024-01-09-clauses.html#nyc-taxis",
    "title": "SQL clauses",
    "section": "NYC Taxis",
    "text": "NYC Taxis\nConsider a database of taxi rides from the Yellow Cab company in NYC in March of 2014.\n\nFigure 1: image credit: Mariordo (Mario Roberto Durán Ortiz), CC BY-SA 3.0"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#establishing-a-sql-connection",
    "href": "slides/2024-01-09-clauses.html#establishing-a-sql-connection",
    "title": "SQL clauses",
    "section": "Establishing a SQL connection",
    "text": "Establishing a SQL connection\n\ncon_taxi &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"nyctaxi\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#what-is-a-database",
    "href": "slides/2024-01-09-clauses.html#what-is-a-database",
    "title": "SQL clauses",
    "section": "What is a database?",
    "text": "What is a database?\n\nstructured collection of data organized with\n\nefficient storage\neasy retrieval\nconsistent management\n\ndata stored in tables which are linked to one another via keys"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#tidy-data",
    "href": "slides/2024-01-09-clauses.html#tidy-data",
    "title": "SQL clauses",
    "section": "Tidy data",
    "text": "Tidy data\n\ndata frame (R) or table (SQL)\ncolumns of variables\nrows of observational units"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#differences-between-r-and-sql",
    "href": "slides/2024-01-09-clauses.html#differences-between-r-and-sql",
    "title": "SQL clauses",
    "section": "Differences between R and SQL",
    "text": "Differences between R and SQL\n\ntables in SQL databases can be arbitrarily large\n\nlive in storage, computer’s hard drive (usually remote)\n\ndata frames in R\n\nlive in memory (RAM) on your personal computer\n\ntables in a database are linked via a key."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#sql-connection",
    "href": "slides/2024-01-09-clauses.html#sql-connection",
    "title": "SQL clauses",
    "section": "SQL connection",
    "text": "SQL connection\nTo set up a SQL connection, you need the location of the server (host) as well as a username and password.\n\ncon_air &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"airlines\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)\n\nHadley Wickham discusses how to use Sys.getenv: https://cran.r-project.org/web/packages/httr/vignettes/secrets.html"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#sql-tables-as-tbl",
    "href": "slides/2024-01-09-clauses.html#sql-tables-as-tbl",
    "title": "SQL clauses",
    "section": "SQL tables as tbl",
    "text": "SQL tables as tbl\n\ncarriers &lt;- dplyr::tbl(con_air, \"carriers\")\ndim(carriers)\n\n[1] NA  2\n\nhead(carriers)\n\n# Source:   SQL [6 x 2]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  carrier name                         \n  &lt;chr&gt;   &lt;chr&gt;                        \n1 02Q     Titan Airways                \n2 04Q     Tradewind Aviation           \n3 05Q     Comlux Aviation, AG          \n4 06Q     Master Top Linhas Aereas Ltd.\n5 07Q     Flair Airlines Ltd.          \n6 09Q     Swift Air, LLC"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#sql-tables-as-tibble",
    "href": "slides/2024-01-09-clauses.html#sql-tables-as-tibble",
    "title": "SQL clauses",
    "section": "SQL tables as tibble",
    "text": "SQL tables as tibble\nThe function collect() copies a SQL table from it’s server location on disk to your local memory location in R.\n\ncarriers_tibble &lt;- carriers |&gt;\n  dplyr::collect()\n\ndim(carriers_tibble)\n\n[1] 1610    2\n\nhead(carriers_tibble)\n\n# A tibble: 6 × 2\n  carrier name                         \n  &lt;chr&gt;   &lt;chr&gt;                        \n1 02Q     Titan Airways                \n2 04Q     Tradewind Aviation           \n3 05Q     Comlux Aviation, AG          \n4 06Q     Master Top Linhas Aereas Ltd.\n5 07Q     Flair Airlines Ltd.          \n6 09Q     Swift Air, LLC"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#how-much-space-does-carriers-take-up",
    "href": "slides/2024-01-09-clauses.html#how-much-space-does-carriers-take-up",
    "title": "SQL clauses",
    "section": "How much space does carriers take up?",
    "text": "How much space does carriers take up?\nThe data frame in R takes up 2 orders of magnitude of memory than the table which just points to the object in SQL.\n\ncarriers |&gt;\n  object.size() |&gt;\n  print(units = \"Kb\")\n\n5.2 Kb\n\ncarriers_tibble |&gt;\n  object.size() |&gt;\n  print(units = \"Kb\")\n\n234.8 Kb"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#what-is-sql-structured-query-language",
    "href": "slides/2024-01-09-clauses.html#what-is-sql-structured-query-language",
    "title": "SQL clauses",
    "section": "What is SQL (Structured Query Language) ?",
    "text": "What is SQL (Structured Query Language) ?\n\nSQL is a programming language for working with relational databases.\nSQL has been around since the 1970s, but has, unfortunately, many different dialects.\nTo connect to the Smith and mdsr databases (via R and DBeaver), we will use MySQL.\nTo connect to DuckDB, we will use the dialect native to DuckDB."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql",
    "href": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql",
    "title": "SQL clauses",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\nThe function dbListTables() in the DBI package will tell us what tables exist in the airlines database.\n\nDBI::dbListTables(con_air)\n\n[1] \"airports\" \"carriers\" \"flights\"  \"planes\"  \n\nflights &lt;- dplyr::tbl(con_air, \"flights\")\ncarriers &lt;- dplyr::tbl(con_air, \"carriers\")"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-1",
    "href": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-1",
    "title": "SQL clauses",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\n\nOver what years is the flights data taken?\n\n\nyrs &lt;- flights |&gt;\n  summarize(min_year = min(year), max_year = max(year))\n\nyrs\n\n# Source:   SQL [1 x 2]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  min_year max_year\n     &lt;int&gt;    &lt;int&gt;\n1     2010     2017"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-2",
    "href": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-2",
    "title": "SQL clauses",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\nBecause flights is not actually a data.frame in R (but instead a tbl in SQL), the work that was done above was actually performed in SQL. To see the SQL code, we can use the function show_query.\n\ndplyr::show_query(yrs)\n\n&lt;SQL&gt;\nSELECT MIN(`year`) AS `min_year`, MAX(`year`) AS `max_year`\nFROM `flights`"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-3",
    "href": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-3",
    "title": "SQL clauses",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\n\nCreate a data set containing only flights between LAX and BOS in 2012.\n\n\nla_bos &lt;- flights |&gt;\n  filter(year == 2012 & ((origin == \"LAX\" & dest == \"BOS\") | \n           (origin == \"BOS\" & dest == \"LAX\"))) \n\ndplyr::show_query(la_bos)\n\n&lt;SQL&gt;\nSELECT *\nFROM `flights`\nWHERE (`year` = 2012.0 AND ((`origin` = 'LAX' AND `dest` = 'BOS') OR (`origin` = 'BOS' AND `dest` = 'LAX')))"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-4",
    "href": "slides/2024-01-09-clauses.html#translating-dplyr-code-into-sql-4",
    "title": "SQL clauses",
    "section": "1. Translating dplyr code into SQL",
    "text": "1. Translating dplyr code into SQL\n\ndbplyr doesn’t translate every R command into SQL.\nSQL is not a statistical software and doesn’t, for example, have a mechanism for creating data visualizations.\ntrack which R commands are connected to SQL at the dbplyr reference sheet."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#sql-queries-via-the-dbi-package",
    "href": "slides/2024-01-09-clauses.html#sql-queries-via-the-dbi-package",
    "title": "SQL clauses",
    "section": "2. SQL queries via the DBI package",
    "text": "2. SQL queries via the DBI package\n\nLook at the first few rows of the flights data.\n\n\nDBI::dbGetQuery(con_air,\n                \"SELECT * FROM flights LIMIT 8;\")\n\n  year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n1 2010    10   1        1           2100       181      159           2320\n2 2010    10   1        1           1920       281      230           2214\n3 2010    10   1        3           2355         8      339            334\n4 2010    10   1        5           2200       125       41           2249\n5 2010    10   1        7           2245        82      104           2347\n6 2010    10   1        7             10        -3      451            500\n7 2010    10   1        7           2150       137      139           2337\n8 2010    10   1        8             15        -7      538            537\n  arr_delay carrier tailnum flight origin dest air_time distance cancelled\n1       159      XE  N11137   2558    EWR  OMA      162     1133         0\n2       256      B6  N659JB    562    FLL  SWF      131     1119         0\n3         5      B6  N563JB    701    JFK  SJU      196     1597         0\n4       112      XE  N16559   5982    IAD  BNA       82      542         0\n5        77      OO  N908SW   6433    LAX  FAT       37      209         0\n6        -9      AA  N3FRAA    700    LAX  DFW      150     1235         0\n7       122      DL  N347NW   1752    ATL  IAD       70      533         0\n8         1      CO  N73283   1740    SMF  IAH      193     1609         0\n  diverted hour minute           time_hour\n1        0   21      0 2010-10-01 21:00:00\n2        0   19     20 2010-10-01 19:20:00\n3        0   23     55 2010-10-01 23:55:00\n4        0   22      0 2010-10-01 22:00:00\n5        0   22     45 2010-10-01 22:45:00\n6        0    0     10 2010-10-01 00:10:00\n7        0   21     50 2010-10-01 21:50:00\n8        0    0     15 2010-10-01 00:15:00"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#sql-queries-via-the-dbi-package-1",
    "href": "slides/2024-01-09-clauses.html#sql-queries-via-the-dbi-package-1",
    "title": "SQL clauses",
    "section": "2. SQL queries via the DBI package",
    "text": "2. SQL queries via the DBI package\n\nHow many flights per year are in the flights table?\n\n\nDBI::dbGetQuery(con_air, \n  \"SELECT year, count(*) AS num_flights FROM flights GROUP BY year ORDER BY num_flights;\")\n\n  year num_flights\n1 2016     5617658\n2 2017     5674621\n3 2015     5819079\n4 2014     5819811\n5 2011     6085281\n6 2012     6096762\n7 2013     6369482\n8 2010     6450117"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#direct-sql-queries-via-sql-chunks",
    "href": "slides/2024-01-09-clauses.html#direct-sql-queries-via-sql-chunks",
    "title": "SQL clauses",
    "section": "3. Direct SQL queries via sql chunks",
    "text": "3. Direct SQL queries via sql chunks\nSQL queries can be written directly inside a sql chunk in RStudio.\n\n```{sql}\n#| connection: con_air\n\nSELECT * FROM flights LIMIT 8;\n```\n\n\n\n\n8 records\n\n\n\n\nyear\n\n\nmonth\n\n\nday\n\n\ndep_time\n\n\nsched_dep_time\n\n\ndep_delay\n\n\narr_time\n\n\nsched_arr_time\n\n\narr_delay\n\n\ncarrier\n\n\ntailnum\n\n\nflight\n\n\norigin\n\n\ndest\n\n\nair_time\n\n\ndistance\n\n\ncancelled\n\n\ndiverted\n\n\nhour\n\n\nminute\n\n\ntime_hour\n\n\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n1\n\n\n2100\n\n\n181\n\n\n159\n\n\n2320\n\n\n159\n\n\nXE\n\n\nN11137\n\n\n2558\n\n\nEWR\n\n\nOMA\n\n\n162\n\n\n1133\n\n\n0\n\n\n0\n\n\n21\n\n\n0\n\n\n2010-10-01 21:00:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n1\n\n\n1920\n\n\n281\n\n\n230\n\n\n2214\n\n\n256\n\n\nB6\n\n\nN659JB\n\n\n562\n\n\nFLL\n\n\nSWF\n\n\n131\n\n\n1119\n\n\n0\n\n\n0\n\n\n19\n\n\n20\n\n\n2010-10-01 19:20:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n3\n\n\n2355\n\n\n8\n\n\n339\n\n\n334\n\n\n5\n\n\nB6\n\n\nN563JB\n\n\n701\n\n\nJFK\n\n\nSJU\n\n\n196\n\n\n1597\n\n\n0\n\n\n0\n\n\n23\n\n\n55\n\n\n2010-10-01 23:55:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n5\n\n\n2200\n\n\n125\n\n\n41\n\n\n2249\n\n\n112\n\n\nXE\n\n\nN16559\n\n\n5982\n\n\nIAD\n\n\nBNA\n\n\n82\n\n\n542\n\n\n0\n\n\n0\n\n\n22\n\n\n0\n\n\n2010-10-01 22:00:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n2245\n\n\n82\n\n\n104\n\n\n2347\n\n\n77\n\n\nOO\n\n\nN908SW\n\n\n6433\n\n\nLAX\n\n\nFAT\n\n\n37\n\n\n209\n\n\n0\n\n\n0\n\n\n22\n\n\n45\n\n\n2010-10-01 22:45:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n10\n\n\n-3\n\n\n451\n\n\n500\n\n\n-9\n\n\nAA\n\n\nN3FRAA\n\n\n700\n\n\nLAX\n\n\nDFW\n\n\n150\n\n\n1235\n\n\n0\n\n\n0\n\n\n0\n\n\n10\n\n\n2010-10-01 00:10:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n7\n\n\n2150\n\n\n137\n\n\n139\n\n\n2337\n\n\n122\n\n\nDL\n\n\nN347NW\n\n\n1752\n\n\nATL\n\n\nIAD\n\n\n70\n\n\n533\n\n\n0\n\n\n0\n\n\n21\n\n\n50\n\n\n2010-10-01 21:50:00\n\n\n\n\n2010\n\n\n10\n\n\n1\n\n\n8\n\n\n15\n\n\n-7\n\n\n538\n\n\n537\n\n\n1\n\n\nCO\n\n\nN73283\n\n\n1740\n\n\nSMF\n\n\nIAH\n\n\n193\n\n\n1609\n\n\n0\n\n\n0\n\n\n0\n\n\n15\n\n\n2010-10-01 00:15:00"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#direct-sql-queries-via-sql-chunks-1",
    "href": "slides/2024-01-09-clauses.html#direct-sql-queries-via-sql-chunks-1",
    "title": "SQL clauses",
    "section": "3. Direct SQL queries via sql chunks",
    "text": "3. Direct SQL queries via sql chunks\nSQL queries can be written directly inside a sql chunk in RStudio.\n\n```{sql}\n#| connection: con_air\n\nSELECT year, count(*) AS num_flights \n       FROM flights \n       GROUP BY year \n       ORDER BY num_flights;\n```\n\n\n\n\n8 records\n\n\n\n\nyear\n\n\nnum_flights\n\n\n\n\n\n\n2016\n\n\n5617658\n\n\n\n\n2017\n\n\n5674621\n\n\n\n\n2015\n\n\n5819079\n\n\n\n\n2014\n\n\n5819811\n\n\n\n\n2011\n\n\n6085281\n\n\n\n\n2012\n\n\n6096762\n\n\n\n\n2013\n\n\n6369482\n\n\n\n\n2010\n\n\n6450117"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#good-practice",
    "href": "slides/2024-01-09-clauses.html#good-practice",
    "title": "SQL clauses",
    "section": "Good practice",
    "text": "Good practice\nAlways a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_taxi, shutdown = TRUE)"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#steps-for-weekly-homework",
    "href": "slides/2024-01-09-clauses.html#steps-for-weekly-homework",
    "title": "SQL clauses",
    "section": "Steps for weekly homework",
    "text": "Steps for weekly homework\n\nReceive a link to the new assignment (clicking on the link will create a new private repo)\n\nUse R Studio\n\nNew Project, version control, Git\n\nClone the repo using SSH\n\n\nCreate a new file sds261-lab#-lname-fname.qmd. (If the .qmd file already exists, rename the file to sds261-lab#-lname-fname.qmd.)\nDo the assignment\n\ncommit and push after every problem\n\n\nFor work done in DBeaver (.sql files), use the same naming convention: sds261-lab#-lname-fname.sql.\nAll necessary files must be in the same folder (e.g., data, .sql files, etc.)"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#show-tables",
    "href": "slides/2024-01-09-clauses.html#show-tables",
    "title": "SQL clauses",
    "section": "SHOW TABLES",
    "text": "SHOW TABLES\nThere is only one table in the nyctaxi database. It is called yellow_old.\n\n```{sql}\n#| connection: con_taxi\n\nSHOW TABLES;\n```\n\n\n\n\n1 records\n\n\n\n\nTables_in_nyctaxi\n\n\n\n\n\n\nyellow_old"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#describe-tables",
    "href": "slides/2024-01-09-clauses.html#describe-tables",
    "title": "SQL clauses",
    "section": "DESCRIBE tables",
    "text": "DESCRIBE tables\nStill using a {sql} chunk. The DESCRIBE command shows the 18 field names (variables) in the yellow_old table. Some of the variables are characters (text) and some are numeric (either double or bigint)\n\nDESCRIBE yellow_old;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nField\n\n\nType\n\n\nNull\n\n\nKey\n\n\nDefault\n\n\nExtra\n\n\n\n\n\n\nvendor_id\n\n\ntext\n\n\nYES\n\n\n\n\n\n\n\n\n\n\npickup_datetime\n\n\ntext\n\n\nYES\n\n\n\n\n\n\n\n\n\n\ndropoff_datetime\n\n\ntext\n\n\nYES\n\n\n\n\n\n\n\n\n\n\npassenger_count\n\n\nbigint(20)\n\n\nYES\n\n\n\n\n\n\n\n\n\n\ntrip_distance\n\n\ndouble\n\n\nYES\n\n\n\n\n\n\n\n\n\n\npickup_longitude\n\n\ndouble\n\n\nYES\n\n\n\n\n\n\n\n\n\n\npickup_latitude\n\n\ndouble\n\n\nYES\n\n\n\n\n\n\n\n\n\n\nrate_code\n\n\nbigint(20)\n\n\nYES\n\n\n\n\n\n\n\n\n\n\nstore_and_fwd_flag\n\n\ntext\n\n\nYES\n\n\n\n\n\n\n\n\n\n\ndropoff_longitude\n\n\ndouble\n\n\nYES"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#order-of-clauses",
    "href": "slides/2024-01-09-clauses.html#order-of-clauses",
    "title": "SQL clauses",
    "section": "Order of clauses",
    "text": "Order of clauses\nQueries in SQL start with the SELECT keyword and consist of several clauses, which must be written in the following order:\n\n\n\nSELECT\nFROM\nJOIN\nWHERE\n\n\n\nGROUP BY\nHAVING\nORDER BY\nLIMIT\n\n\n\nThe clauses are similar to data wrangling verbs in R."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-from",
    "href": "slides/2024-01-09-clauses.html#select-from",
    "title": "SQL clauses",
    "section": "SELECT … FROM",
    "text": "SELECT … FROM\n\nstart with a SELECT, include a corresponding FROM\ncolumns may be specified or * returns every column\n\nThe shortest SQL query is the following SELECT command. Do not run this command!!! The yellow_old table has 15 million rows, and we do not want to look at them simultaneously.\n\nDO NOT RUN:  SELECT * FROM yellow_old;"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-from-1",
    "href": "slides/2024-01-09-clauses.html#select-from-1",
    "title": "SQL clauses",
    "section": "SELECT … FROM",
    "text": "SELECT … FROM\nMuch better for big tables:\n\nSELECT * FROM yellow_old LIMIT 0, 14;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nvendor_id\n\n\npickup_datetime\n\n\ndropoff_datetime\n\n\npassenger_count\n\n\ntrip_distance\n\n\npickup_longitude\n\n\npickup_latitude\n\n\nrate_code\n\n\nstore_and_fwd_flag\n\n\ndropoff_longitude\n\n\ndropoff_latitude\n\n\npayment_type\n\n\nfare_amount\n\n\nsurcharge\n\n\nmta_tax\n\n\ntip_amount\n\n\ntolls_amount\n\n\ntotal_amount\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCMT\n\n\n2014-03-01 01:07:38\n\n\n2014-03-01 01:16:26\n\n\n1\n\n\n2.0\n\n\n-74.0\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-73.9\n\n\n40.7\n\n\nCRD\n\n\n9.0\n\n\n0.5\n\n\n0.5\n\n\n2.0\n\n\n0\n\n\n12.0\n\n\n\n\nCMT\n\n\n2014-03-01 01:08:03\n\n\n2014-03-01 01:12:51\n\n\n2\n\n\n1.2\n\n\n-74.0\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.7\n\n\nCRD\n\n\n6.0\n\n\n0.5\n\n\n0.5\n\n\n1.0\n\n\n0\n\n\n8.0\n\n\n\n\nCMT\n\n\n2014-03-01 01:08:51\n\n\n2014-03-01 01:13:18\n\n\n3\n\n\n0.5\n\n\n-73.9\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.7\n\n\nCRD\n\n\n5.0\n\n\n0.5\n\n\n0.5\n\n\n1.2\n\n\n0\n\n\n7.2\n\n\n\n\nCMT\n\n\n2014-03-01 01:09:20\n\n\n2014-03-01 01:24:18\n\n\n3\n\n\n3.5\n\n\n-74.0\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.8\n\n\nCRD\n\n\n14.0\n\n\n0.5\n\n\n0.5\n\n\n3.0\n\n\n0\n\n\n18.0\n\n\n\n\nCMT\n\n\n2014-03-01 01:09:46\n\n\n2014-03-01 01:22:34\n\n\n1\n\n\n1.8\n\n\n-74.0\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.7\n\n\nCRD\n\n\n10.5\n\n\n0.5\n\n\n0.5\n\n\n1.0\n\n\n0\n\n\n12.5\n\n\n\n\nCMT\n\n\n2014-03-01 01:12:41\n\n\n2014-03-01 01:15:38\n\n\n1\n\n\n0.5\n\n\n-74.0\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.7\n\n\nCRD\n\n\n4.0\n\n\n0.5\n\n\n0.5\n\n\n0.5\n\n\n0\n\n\n5.5\n\n\n\n\nCMT\n\n\n2014-03-01 01:12:11\n\n\n2014-03-01 01:27:38\n\n\n2\n\n\n3.7\n\n\n-74.0\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.7\n\n\nCRD\n\n\n14.5\n\n\n0.5\n\n\n0.5\n\n\n3.1\n\n\n0\n\n\n18.6\n\n\n\n\nCMT\n\n\n2014-03-01 01:13:55\n\n\n2014-03-01 01:34:54\n\n\n1\n\n\n5.4\n\n\n-74.0\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.7\n\n\nCRD\n\n\n20.0\n\n\n0.5\n\n\n0.5\n\n\n3.0\n\n\n0\n\n\n24.0\n\n\n\n\nCMT\n\n\n2014-03-01 01:14:06\n\n\n2014-03-01 01:28:25\n\n\n1\n\n\n3.5\n\n\n-74.0\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-74.0\n\n\n40.8\n\n\nCRD\n\n\n13.5\n\n\n0.5\n\n\n0.5\n\n\n2.9\n\n\n0\n\n\n17.4"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-from-2",
    "href": "slides/2024-01-09-clauses.html#select-from-2",
    "title": "SQL clauses",
    "section": "SELECT … FROM",
    "text": "SELECT … FROM\nHow do we know how many taxi rides are recorded? Two different ways of counting the rows:\n\nSELECT COUNT(*), SUM(1) FROM yellow_old LIMIT 0, 14;\n\n\n\n\n1 records\n\n\n\n\nCOUNT(*)\n\n\nSUM(1)\n\n\n\n\n\n\n15428128\n\n\n15428128\n\n\n\n\n\n\n\nYikes, more than 15 million taxi rides!"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-from-3",
    "href": "slides/2024-01-09-clauses.html#select-from-3",
    "title": "SQL clauses",
    "section": "SELECT … FROM",
    "text": "SELECT … FROM\nWhat is the length of a taxi ride (in time)? … unfortunately, pickup_datetime and dropoff_datetime are saved as character strings instead of in DateTime format.\n\nSELECT\n      pickup_datetime, dropoff_datetime,\n      STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\") AS pickup,\n      STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\") AS dropoff\n   FROM yellow_old\n   LIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npickup_datetime\n\n\ndropoff_datetime\n\n\npickup\n\n\ndropoff\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2014-03-01 01:07:38\n\n\n2014-03-01 01:16:26\n\n\n2014-03-01 01:07:38\n\n\n2014-03-01 01:16:26\n\n\n\n\n2014-03-01 01:08:03\n\n\n2014-03-01 01:12:51\n\n\n2014-03-01 01:08:03\n\n\n2014-03-01 01:12:51\n\n\n\n\n2014-03-01 01:08:51\n\n\n2014-03-01 01:13:18\n\n\n2014-03-01 01:08:51\n\n\n2014-03-01 01:13:18\n\n\n\n\n2014-03-01 01:09:20\n\n\n2014-03-01 01:24:18\n\n\n2014-03-01 01:09:20\n\n\n2014-03-01 01:24:18\n\n\n\n\n2014-03-01 01:09:46\n\n\n2014-03-01 01:22:34\n\n\n2014-03-01 01:09:46\n\n\n2014-03-01 01:22:34\n\n\n\n\n2014-03-01 01:12:41\n\n\n2014-03-01 01:15:38\n\n\n2014-03-01 01:12:41\n\n\n2014-03-01 01:15:38\n\n\n\n\n2014-03-01 01:12:11\n\n\n2014-03-01 01:27:38\n\n\n2014-03-01 01:12:11\n\n\n2014-03-01 01:27:38\n\n\n\n\n2014-03-01 01:13:55\n\n\n2014-03-01 01:34:54\n\n\n2014-03-01 01:13:55\n\n\n2014-03-01 01:34:54\n\n\n\n\n2014-03-01 01:14:06\n\n\n2014-03-01 01:28:25\n\n\n2014-03-01 01:14:06\n\n\n2014-03-01 01:28:25"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-from-4",
    "href": "slides/2024-01-09-clauses.html#select-from-4",
    "title": "SQL clauses",
    "section": "SELECT … FROM",
    "text": "SELECT … FROM\nWhy can’t we find the difference between the new two time variables?\n\nSELECT\n      pickup_datetime, dropoff_datetime,\n      STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\") AS pickup,\n      STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\") AS dropoff,\n      TIMEDIFF(pickup, dropoff) AS length_time\n   FROM yellow_old\n   LIMIT 0, 10;\n\nError: Unknown column 'pickup' in 'field list' [1054]"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-from-5",
    "href": "slides/2024-01-09-clauses.html#select-from-5",
    "title": "SQL clauses",
    "section": "SELECT … FROM",
    "text": "SELECT … FROM\nSolution 1: two layers of SELECT\n\nfirst SELECT (i.e., inside) layer creates the new variables\nsecond SELECT (i.e., outside) layer subtracts the two times\n\n\nSELECT \n   pickup,\n   dropoff, \n   TIMEDIFF(pickup, dropoff) AS length_time \nFROM (\n   SELECT\n      STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\") AS pickup,\n      STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\") AS dropoff\n   FROM yellow_old)\n   AS subquery_table\nLIMIT 0, 20;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npickup\n\n\ndropoff\n\n\nlength_time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2014-03-01 01:07:38\n\n\n2014-03-01 01:16:26\n\n\n00:08:48\n\n\n\n\n2014-03-01 01:08:03\n\n\n2014-03-01 01:12:51\n\n\n00:04:48\n\n\n\n\n2014-03-01 01:08:51\n\n\n2014-03-01 01:13:18\n\n\n00:04:27\n\n\n\n\n2014-03-01 01:09:20\n\n\n2014-03-01 01:24:18\n\n\n00:14:58\n\n\n\n\n2014-03-01 01:09:46\n\n\n2014-03-01 01:22:34\n\n\n00:12:48\n\n\n\n\n2014-03-01 01:12:41\n\n\n2014-03-01 01:15:38\n\n\n00:02:57\n\n\n\n\n2014-03-01 01:12:11\n\n\n2014-03-01 01:27:38\n\n\n00:15:27\n\n\n\n\n2014-03-01 01:13:55\n\n\n2014-03-01 01:34:54\n\n\n00:20:59\n\n\n\n\n2014-03-01 01:14:06\n\n\n2014-03-01 01:28:25\n\n\n00:14:19"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-from-6",
    "href": "slides/2024-01-09-clauses.html#select-from-6",
    "title": "SQL clauses",
    "section": "SELECT … FROM",
    "text": "SELECT … FROM\nSolution 2: apply the STR_TO_DATE() function inside the TIMEDIFF() function\n\nSELECT \n   pickup_datetime,\n   dropoff_datetime, \n   TIMEDIFF(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\"), \n            STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\")) AS length_time \nFROM yellow_old\nLIMIT 0, 20;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npickup_datetime\n\n\ndropoff_datetime\n\n\nlength_time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2014-03-01 01:07:38\n\n\n2014-03-01 01:16:26\n\n\n00:08:48\n\n\n\n\n2014-03-01 01:08:03\n\n\n2014-03-01 01:12:51\n\n\n00:04:48\n\n\n\n\n2014-03-01 01:08:51\n\n\n2014-03-01 01:13:18\n\n\n00:04:27\n\n\n\n\n2014-03-01 01:09:20\n\n\n2014-03-01 01:24:18\n\n\n00:14:58\n\n\n\n\n2014-03-01 01:09:46\n\n\n2014-03-01 01:22:34\n\n\n00:12:48\n\n\n\n\n2014-03-01 01:12:41\n\n\n2014-03-01 01:15:38\n\n\n00:02:57\n\n\n\n\n2014-03-01 01:12:11\n\n\n2014-03-01 01:27:38\n\n\n00:15:27\n\n\n\n\n2014-03-01 01:13:55\n\n\n2014-03-01 01:34:54\n\n\n00:20:59\n\n\n\n\n2014-03-01 01:14:06\n\n\n2014-03-01 01:28:25\n\n\n00:14:19"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#important-note",
    "href": "slides/2024-01-09-clauses.html#important-note",
    "title": "SQL clauses",
    "section": "Important note:",
    "text": "Important note:\nThere is a distinction between clauses that operate on the variables of the original table versus those that operate on the variables of the results set.\npickup_datetime and dropoff_datetime are columns in the original table - they are written to disk on the SQL server.\npickup, dropoff, and length_time exist only in the results set, which is passed from the server (SQL server) to the client (e.g., RStudio or DBeaver) and is not written to disk."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#where",
    "href": "slides/2024-01-09-clauses.html#where",
    "title": "SQL clauses",
    "section": "WHERE",
    "text": "WHERE\nThe WHERE clause is analogous to the filter() function in dplyr. However, keep in mind that there are two SQL commands that resemble the dplyr filter() function. WHERE operates on the original data in the table and HAVING operates on the result set."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#where-1",
    "href": "slides/2024-01-09-clauses.html#where-1",
    "title": "SQL clauses",
    "section": "WHERE",
    "text": "WHERE\nWhat was the fare for those taxi rides where the tip_amount was more than $10 and the person used cash?\nNote that in SQL the equality logical is = and in R the equality logical is ==.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount &gt; 10\n   AND payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npayment_type\n\n\nfare_amount\n\n\ntip_amount\n\n\ntotal_amount\n\n\n\n\n\n\nCSH\n\n\n65.5\n\n\n15.3\n\n\n91.8\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCSH\n\n\n55.0\n\n\n16.2\n\n\n81.2\n\n\n\n\nCSH\n\n\n71.5\n\n\n20.0\n\n\n103.5\n\n\n\n\nCSH\n\n\n70.0\n\n\n16.2\n\n\n97.1\n\n\n\n\nCSH\n\n\n95.0\n\n\n21.9\n\n\n131.2\n\n\n\n\nCSH\n\n\n62.5\n\n\n15.5\n\n\n93.0\n\n\n\n\nCSH\n\n\n66.0\n\n\n15.0\n\n\n90.0\n\n\n\n\nCSH\n\n\n65.0\n\n\n13.2\n\n\n79.2"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#where-2",
    "href": "slides/2024-01-09-clauses.html#where-2",
    "title": "SQL clauses",
    "section": "WHERE",
    "text": "WHERE\nBETWEEN can be used to specify a range of values for a numeric value. BETWEEN is inclusive.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 12\n   AND payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npayment_type\n\n\nfare_amount\n\n\ntip_amount\n\n\ntotal_amount\n\n\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCSH\n\n\n88.0\n\n\n10.0\n\n\n107.0\n\n\n\n\nCSH\n\n\n72.0\n\n\n10.0\n\n\n94.0\n\n\n\n\nCSH\n\n\n64.5\n\n\n10.0\n\n\n85.5\n\n\n\n\nCSH\n\n\n66.0\n\n\n12.0\n\n\n93.0\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCSH\n\n\n69.0\n\n\n10.0\n\n\n88.0\n\n\n\n\nCSH\n\n\n90.0\n\n\n10.0\n\n\n100.0\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#where-3",
    "href": "slides/2024-01-09-clauses.html#where-3",
    "title": "SQL clauses",
    "section": "WHERE",
    "text": "WHERE\nIN is similar to the dplyr %in% function which specifies distinct values for the variable.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount IN (10, 12)\n   AND payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npayment_type\n\n\nfare_amount\n\n\ntip_amount\n\n\ntotal_amount\n\n\n\n\n\n\nCSH\n\n\n88.0\n\n\n10\n\n\n107.0\n\n\n\n\nCSH\n\n\n72.0\n\n\n10\n\n\n94.0\n\n\n\n\nCSH\n\n\n64.5\n\n\n10\n\n\n85.5\n\n\n\n\nCSH\n\n\n66.0\n\n\n12\n\n\n93.0\n\n\n\n\nCSH\n\n\n69.0\n\n\n10\n\n\n88.0\n\n\n\n\nCSH\n\n\n90.0\n\n\n10\n\n\n100.0\n\n\n\n\nCSH\n\n\n74.5\n\n\n10\n\n\n90.3\n\n\n\n\nCSH\n\n\n89.0\n\n\n10\n\n\n118.1\n\n\n\n\nCSH\n\n\n52.0\n\n\n10\n\n\n67.8\n\n\n\n\nCSH\n\n\n66.0\n\n\n12\n\n\n90.0"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#where-4",
    "href": "slides/2024-01-09-clauses.html#where-4",
    "title": "SQL clauses",
    "section": "WHERE",
    "text": "WHERE\nAND takes precedent over OR in the order of operations, when there are no parentheses.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 12 OR \n      total_amount BETWEEN 100 and 112 AND \n      payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npayment_type\n\n\nfare_amount\n\n\ntip_amount\n\n\ntotal_amount\n\n\n\n\n\n\nCRD\n\n\n52.0\n\n\n10.5\n\n\n63.0\n\n\n\n\nCRD\n\n\n35.0\n\n\n10.2\n\n\n51.0\n\n\n\n\nCRD\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCRD\n\n\n30.5\n\n\n10.8\n\n\n47.2\n\n\n\n\nCRD\n\n\n52.0\n\n\n10.5\n\n\n63.0\n\n\n\n\nCRD\n\n\n52.0\n\n\n10.5\n\n\n63.0\n\n\n\n\nCRD\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCRD\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCRD\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCRD\n\n\n52.0\n\n\n11.6\n\n\n69.4"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#where-5",
    "href": "slides/2024-01-09-clauses.html#where-5",
    "title": "SQL clauses",
    "section": "WHERE",
    "text": "WHERE\nParentheses take precedent over AND and OR.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE (tip_amount BETWEEN 10 and 12 OR \n      total_amount BETWEEN 100 and 112 ) AND \n      payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\npayment_type\n\n\nfare_amount\n\n\ntip_amount\n\n\ntotal_amount\n\n\n\n\n\n\nCSH\n\n\n107.0\n\n\n0.0\n\n\n108.0\n\n\n\n\nCSH\n\n\n92.5\n\n\n0.0\n\n\n103.5\n\n\n\n\nCSH\n\n\n99.5\n\n\n0.0\n\n\n105.3\n\n\n\n\nCSH\n\n\n92.0\n\n\n0.0\n\n\n106.3\n\n\n\n\nCSH\n\n\n103.0\n\n\n0.0\n\n\n109.3\n\n\n\n\nCSH\n\n\n107.0\n\n\n0.0\n\n\n107.0\n\n\n\n\nCSH\n\n\n104.5\n\n\n0.0\n\n\n105.5\n\n\n\n\nCSH\n\n\n112.0\n\n\n0.0\n\n\n112.0\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4\n\n\n\n\nCSH\n\n\n52.0\n\n\n11.6\n\n\n69.4"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#group-by",
    "href": "slides/2024-01-09-clauses.html#group-by",
    "title": "SQL clauses",
    "section": "GROUP BY",
    "text": "GROUP BY\nThe GROUP BY clause will direct SQL to carry out the query separately for each category in the grouped variable.\n\naggregate functions include COUNT(), SUM(), MAX(), MIN(), and AVG().\n\n\nSELECT COUNT(*) AS num_transactions, \n       SUM(1) AS num_transactions_also,\n       SUM(2) AS double_transactions,\n       payment_type \nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 20\nGROUP BY payment_type;\n\n\n\n\n5 records\n\n\n\n\nnum_transactions\n\n\nnum_transactions_also\n\n\ndouble_transactions\n\n\npayment_type\n\n\n\n\n\n\n213872\n\n\n213872\n\n\n427744\n\n\nCRD\n\n\n\n\n78\n\n\n78\n\n\n156\n\n\nCSH\n\n\n\n\n3\n\n\n3\n\n\n6\n\n\nDIS\n\n\n\n\n7\n\n\n7\n\n\n14\n\n\nNOC\n\n\n\n\n609\n\n\n609\n\n\n1218\n\n\nUNK"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#group-by-1",
    "href": "slides/2024-01-09-clauses.html#group-by-1",
    "title": "SQL clauses",
    "section": "GROUP BY",
    "text": "GROUP BY\nFor those people who tipped between $10 and $20, what was the lowest and highest fare for each of the types of payments?\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type \nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 20\nGROUP BY payment_type;\n\n\n\n\n5 records\n\n\n\n\nnum_transactions\n\n\nlowest_fare\n\n\nhighest_fare\n\n\npayment_type\n\n\n\n\n\n\n213872\n\n\n0.0\n\n\n370.0\n\n\nCRD\n\n\n\n\n78\n\n\n52.0\n\n\n102.0\n\n\nCSH\n\n\n\n\n3\n\n\n52.0\n\n\n79.5\n\n\nDIS\n\n\n\n\n7\n\n\n58.0\n\n\n94.0\n\n\nNOC\n\n\n\n\n609\n\n\n4.5\n\n\n147.0\n\n\nUNK"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#group-by-2",
    "href": "slides/2024-01-09-clauses.html#group-by-2",
    "title": "SQL clauses",
    "section": "GROUP BY",
    "text": "GROUP BY\nGROUP BY will work applied to multiple columns.\nWhat is wday?\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nnum_transactions\n\n\nlowest_fare\n\n\nhighest_fare\n\n\npayment_type\n\n\nwday\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n1247397\n\n\n2.5\n\n\n477\n\n\nCRD\n\n\nFriday\n\n\n\n\n1278362\n\n\n-612.4\n\n\n500\n\n\nCRD\n\n\nMonday\n\n\n\n\n1533796\n\n\n2.5\n\n\n420\n\n\nCRD\n\n\nSaturday\n\n\n\n\n1324394\n\n\n2.5\n\n\n480\n\n\nCRD\n\n\nSunday\n\n\n\n\n1258098\n\n\n2.5\n\n\n500\n\n\nCRD\n\n\nThursday\n\n\n\n\n1121081\n\n\n2.5\n\n\n500\n\n\nCRD\n\n\nTuesday\n\n\n\n\n1192892\n\n\n2.5\n\n\n400\n\n\nCRD\n\n\nWednesday\n\n\n\n\n860920\n\n\n2.5\n\n\n444\n\n\nCSH\n\n\nFriday\n\n\n\n\n918653\n\n\n0.0\n\n\n873\n\n\nCSH\n\n\nMonday"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#order-by",
    "href": "slides/2024-01-09-clauses.html#order-by",
    "title": "SQL clauses",
    "section": "ORDER BY",
    "text": "ORDER BY\nORDER BY allows us to look at interesting aspects of the data by sorting the data.\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nORDER BY lowest_fare ASC;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nnum_transactions\n\n\nlowest_fare\n\n\nhighest_fare\n\n\npayment_type\n\n\nwday\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n1278362\n\n\n-612.4\n\n\n500\n\n\nCRD\n\n\nMonday\n\n\n\n\n918653\n\n\n0.0\n\n\n873\n\n\nCSH\n\n\nMonday\n\n\n\n\n5440\n\n\n0.0\n\n\n950\n\n\nNOC\n\n\nMonday\n\n\n\n\n1537\n\n\n0.0\n\n\n102\n\n\nDIS\n\n\nMonday\n\n\n\n\n1533796\n\n\n2.5\n\n\n420\n\n\nCRD\n\n\nSaturday\n\n\n\n\n1121081\n\n\n2.5\n\n\n500\n\n\nCRD\n\n\nTuesday\n\n\n\n\n1192892\n\n\n2.5\n\n\n400\n\n\nCRD\n\n\nWednesday\n\n\n\n\n1258098\n\n\n2.5\n\n\n500\n\n\nCRD\n\n\nThursday\n\n\n\n\n1247397\n\n\n2.5\n\n\n477\n\n\nCRD\n\n\nFriday\n\n\n\n\n\n\n\nWHAT?!?!! How in the world was one of the fares -$612.40?"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#order-by-1",
    "href": "slides/2024-01-09-clauses.html#order-by-1",
    "title": "SQL clauses",
    "section": "ORDER BY",
    "text": "ORDER BY\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nORDER BY highest_fare DESC;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nnum_transactions\n\n\nlowest_fare\n\n\nhighest_fare\n\n\npayment_type\n\n\nwday\n\n\n\n\n\n\n5440\n\n\n0.0\n\n\n950\n\n\nNOC\n\n\nMonday\n\n\n\n\n918653\n\n\n0.0\n\n\n873\n\n\nCSH\n\n\nMonday\n\n\n\n\n1278362\n\n\n-612.4\n\n\n500\n\n\nCRD\n\n\nMonday\n\n\n\n\n1121081\n\n\n2.5\n\n\n500\n\n\nCRD\n\n\nTuesday\n\n\n\n\n1258098\n\n\n2.5\n\n\n500\n\n\nCRD\n\n\nThursday\n\n\n\n\n1324394\n\n\n2.5\n\n\n480\n\n\nCRD\n\n\nSunday\n\n\n\n\n1247397\n\n\n2.5\n\n\n477\n\n\nCRD\n\n\nFriday\n\n\n\n\n1222\n\n\n2.5\n\n\n475\n\n\nDIS\n\n\nTuesday\n\n\n\n\n813813\n\n\n2.5\n\n\n475\n\n\nCSH\n\n\nThursday\n\n\n\n\n860920\n\n\n2.5\n\n\n444\n\n\nCSH\n\n\nFriday\n\n\n\n\n\n\n\n$950 is a lot to pay for a cab ride! But in NYC, I’d believe it."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#order-by-2",
    "href": "slides/2024-01-09-clauses.html#order-by-2",
    "title": "SQL clauses",
    "section": "ORDER BY",
    "text": "ORDER BY\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nORDER BY wday, payment_type;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nnum_transactions\n\n\nlowest_fare\n\n\nhighest_fare\n\n\npayment_type\n\n\nwday\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n1247397\n\n\n2.5\n\n\n477\n\n\nCRD\n\n\nFriday\n\n\n\n\n860920\n\n\n2.5\n\n\n444\n\n\nCSH\n\n\nFriday\n\n\n\n\n1592\n\n\n2.5\n\n\n255\n\n\nDIS\n\n\nFriday\n\n\n\n\n5252\n\n\n2.5\n\n\n229\n\n\nNOC\n\n\nFriday\n\n\n\n\n10131\n\n\n2.5\n\n\n130\n\n\nUNK\n\n\nFriday\n\n\n\n\n1278362\n\n\n-612.4\n\n\n500\n\n\nCRD\n\n\nMonday\n\n\n\n\n918653\n\n\n0.0\n\n\n873\n\n\nCSH\n\n\nMonday\n\n\n\n\n1537\n\n\n0.0\n\n\n102\n\n\nDIS\n\n\nMonday\n\n\n\n\n5440\n\n\n0.0\n\n\n950\n\n\nNOC\n\n\nMonday"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#order-by-3",
    "href": "slides/2024-01-09-clauses.html#order-by-3",
    "title": "SQL clauses",
    "section": "ORDER BY",
    "text": "ORDER BY\n\n\n\nNote that both GROUP BY and ORDER BY evaluate the data after it has been retrieved. Therefore, the functions operate on the results set, not the original rows of the data.\n\n\n\nWe are able to GROUP BY and ORDER BY on the new variables we had created, wday."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#having",
    "href": "slides/2024-01-09-clauses.html#having",
    "title": "SQL clauses",
    "section": "HAVING",
    "text": "HAVING\nRecall that WHERE acts only on the original data. If we are interested in rides that took place on Friday, we need to use the derived variable wday instead of the raw variable pickup_datetime. Fortunately, HAVING works on the results set."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#having-1",
    "href": "slides/2024-01-09-clauses.html#having-1",
    "title": "SQL clauses",
    "section": "HAVING",
    "text": "HAVING\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nHAVING wday = 'Friday';\n\n\n\n\n5 records\n\n\n\n\nnum_transactions\n\n\nlowest_fare\n\n\nhighest_fare\n\n\npayment_type\n\n\nwday\n\n\n\n\n\n\n1247397\n\n\n2.5\n\n\n477\n\n\nCRD\n\n\nFriday\n\n\n\n\n860920\n\n\n2.5\n\n\n444\n\n\nCSH\n\n\nFriday\n\n\n\n\n1592\n\n\n2.5\n\n\n255\n\n\nDIS\n\n\nFriday\n\n\n\n\n5252\n\n\n2.5\n\n\n229\n\n\nNOC\n\n\nFriday\n\n\n\n\n10131\n\n\n2.5\n\n\n130\n\n\nUNK\n\n\nFriday"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#having-2",
    "href": "slides/2024-01-09-clauses.html#having-2",
    "title": "SQL clauses",
    "section": "HAVING",
    "text": "HAVING\nWhile it worked out quite well for us that HAVING was able to filter the data based on the results set, the use of HAVING was quite onerous because the entire data set was considered before the filter was applied. That is, if the filter can be done on the original data using WHERE, the query will be much faster and more efficient.\nNote: HAVING requires a GROUP BY clause. And the variable(s) used in HAVING must also be part of the GROUP BY clause."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#limit",
    "href": "slides/2024-01-09-clauses.html#limit",
    "title": "SQL clauses",
    "section": "LIMIT",
    "text": "LIMIT\nLIMIT truncates the query to specified rows. The first number is the offset (i.e., the number of rows to skip), the second number is the (maximum) number of rows to return. Here, we return rows 15428119 through 15428128.\nThe first number is optional.\n\nSELECT * FROM yellow_old LIMIT 15428118, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nvendor_id\n\n\npickup_datetime\n\n\ndropoff_datetime\n\n\npassenger_count\n\n\ntrip_distance\n\n\npickup_longitude\n\n\npickup_latitude\n\n\nrate_code\n\n\nstore_and_fwd_flag\n\n\ndropoff_longitude\n\n\ndropoff_latitude\n\n\npayment_type\n\n\nfare_amount\n\n\nsurcharge\n\n\nmta_tax\n\n\ntip_amount\n\n\ntolls_amount\n\n\ntotal_amount\n\n\n\n\n\n\nCMT\n\n\n2014-03-18 14:35:21\n\n\n2014-03-18 14:52:01\n\n\n1\n\n\n2.7\n\n\n0\n\n\n0.0\n\n\n1\n\n\nN\n\n\n0\n\n\n0.0\n\n\nCRD\n\n\n13.0\n\n\n0\n\n\n0.5\n\n\n2.50\n\n\n0.00\n\n\n16.0\n\n\n\n\nCMT\n\n\n2014-03-18 14:08:23\n\n\n2014-03-18 14:19:29\n\n\n2\n\n\n1.3\n\n\n0\n\n\n0.0\n\n\n1\n\n\nN\n\n\n0\n\n\n0.0\n\n\nCRD\n\n\n9.0\n\n\n0\n\n\n0.5\n\n\n1.90\n\n\n0.00\n\n\n11.4\n\n\n\n\nCMT\n\n\n2014-03-18 09:18:38\n\n\n2014-03-18 09:19:41\n\n\n1\n\n\n0.2\n\n\n-74\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74\n\n\n40.8\n\n\nCRD\n\n\n3.0\n\n\n0\n\n\n0.5\n\n\n1.00\n\n\n0.00\n\n\n4.5\n\n\n\n\nCMT\n\n\n2014-03-18 06:28:12\n\n\n2014-03-18 06:49:49\n\n\n1\n\n\n9.9\n\n\n0\n\n\n0.0\n\n\n1\n\n\nN\n\n\n0\n\n\n0.0\n\n\nCRD\n\n\n30.0\n\n\n0\n\n\n0.5\n\n\n7.16\n\n\n5.33\n\n\n43.0\n\n\n\n\nCMT\n\n\n2014-03-18 17:39:28\n\n\n2014-03-18 17:53:01\n\n\n1\n\n\n4.9\n\n\n-74\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74\n\n\n40.7\n\n\nCRD\n\n\n16.5\n\n\n1\n\n\n0.5\n\n\n3.00\n\n\n0.00\n\n\n21.0\n\n\n\n\nCMT\n\n\n2014-03-18 18:14:19\n\n\n2014-03-18 18:27:22\n\n\n1\n\n\n0.3\n\n\n-74\n\n\n40.7\n\n\n1\n\n\nN\n\n\n-74\n\n\n40.7\n\n\nCRD\n\n\n3.5\n\n\n1\n\n\n0.5\n\n\n6.00\n\n\n0.00\n\n\n11.0\n\n\n\n\nCMT\n\n\n2014-03-18 10:12:33\n\n\n2014-03-18 10:28:09\n\n\n1\n\n\n3.3\n\n\n-74\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74\n\n\n40.8\n\n\nCRD\n\n\n13.5\n\n\n0\n\n\n0.5\n\n\n4.20\n\n\n0.00\n\n\n18.2\n\n\n\n\nCMT\n\n\n2014-03-18 09:02:37\n\n\n2014-03-18 09:16:29\n\n\n1\n\n\n6.2\n\n\n-74\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74\n\n\n40.7\n\n\nCRD\n\n\n19.5\n\n\n0\n\n\n0.5\n\n\n1.00\n\n\n0.00\n\n\n21.0\n\n\n\n\nCMT\n\n\n2014-03-18 10:10:19\n\n\n2014-03-18 10:19:25\n\n\n1\n\n\n1.7\n\n\n-74\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74\n\n\n40.8\n\n\nCRD\n\n\n8.5\n\n\n0\n\n\n0.5\n\n\n1.80\n\n\n0.00\n\n\n10.8\n\n\n\n\nCMT\n\n\n2014-03-18 15:24:53\n\n\n2014-03-18 15:42:42\n\n\n1\n\n\n1.7\n\n\n-74\n\n\n40.8\n\n\n1\n\n\nN\n\n\n-74\n\n\n40.7\n\n\nCRD\n\n\n12.5\n\n\n0\n\n\n0.5\n\n\n2.60\n\n\n0.00\n\n\n15.6"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#saving-sql-queries-as-r-objects",
    "href": "slides/2024-01-09-clauses.html#saving-sql-queries-as-r-objects",
    "title": "SQL clauses",
    "section": "Saving SQL queries as R objects",
    "text": "Saving SQL queries as R objects\nIf you are working in R to run SQL commands, you may want to use the query output for further analysis or visualizations.\n\nuse #|output.var: \"name_of_variable\" inside the {sql} chunk.\nname_of_variable will then be available to be used in the R environment.\n\n\n```{sql}\n#| connection: con_taxi\n#| label: new-table\n#| output.var: \"new_table\"\n\nSELECT *, DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old \nLIMIT 0, 1000;\n```"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#saving-sql-queries-as-r-objects-1",
    "href": "slides/2024-01-09-clauses.html#saving-sql-queries-as-r-objects-1",
    "title": "SQL clauses",
    "section": "Saving SQL queries as R objects",
    "text": "Saving SQL queries as R objects\n\n```{r}\nnew_table |&gt;\n  drop_na(wday) |&gt;\n  ggplot(aes(x = fare_amount, y = tip_amount, color = wday)) + \n  geom_point() \n```"
  },
  {
    "objectID": "slides/2024-01-08-db.html#the-airlines-database",
    "href": "slides/2024-01-08-db.html#the-airlines-database",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "The airlines database",
    "text": "The airlines database\nConsider a database of US flights between 2010 and 2017. The flights are downloaded from the Bureau of Transportation Statistics, US Department of Transportation. The database is a superset of the nycflights13 R package that tracks only flights in and out of airports serving New York City in 2013."
  },
  {
    "objectID": "handout/ws4_sds261_j24.html",
    "href": "handout/ws4_sds261_j24.html",
    "title": "WS4 - regular expressions I",
    "section": "",
    "text": "Your Name: __________________________________\nNames of people you worked with: __________________________________\n\nIntroduce yourself. What is the most challenging thing you have to do in the next 10 days?\nWhat classes are you taking in the spring? How many of them are SDS?\n\nTask:\nThe Jewish Festival of Lights is written as ה כ נ ח in Hebrew and translated to many different spellings in English. The correct English spelling of the holiday can be given in any of the following thirteen variants, according to https://www.holidays.net/chanukah/spelling.htm.\n\nlights &lt;- c(\"Chanuka\", \"Chanukah\", \"Chanukkah\", \"Channukah\", \"Hanukah\", \"Hannukah\",\n            \"Hanukkah\", \"Hanuka\", \"Hanukka\", \"Hanaka\", \"Haneka\", \"Hanika\", \"Khanukkah\")\n\nlights\n\n [1] \"Chanuka\"   \"Chanukah\"  \"Chanukkah\" \"Channukah\" \"Hanukah\"   \"Hannukah\" \n [7] \"Hanukkah\"  \"Hanuka\"    \"Hanukka\"   \"Hanaka\"    \"Haneka\"    \"Hanika\"   \n[13] \"Khanukkah\"\n\n\nProvide a regular expression which will capture all thirteen variants.\n\nSolution:\n[CHK]h?ann?[aeiu]kk?ah?\n\ngrepl(\"[CHK]h?ann?[aeiu]kk?ah?\", lights)\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/lab2_clauses_sds261_j24.html",
    "href": "handout/lab2_clauses_sds261_j24.html",
    "title": "Lab 2 - SQL clauses",
    "section": "",
    "text": "Today’s lab will provide practice working with SQL clauses in DBeaver. Don’t forget the importance of the order of the SQL clauses.\nThe goals for lab 2 include:"
  },
  {
    "objectID": "handout/lab2_clauses_sds261_j24.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab2_clauses_sds261_j24.html#advice-for-turning-in-the-assignment",
    "title": "Lab 2 - SQL clauses",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .sql file) which problem is being answered with which SQL code. Use the following syntax to comment within a .sql file: /* here is where comments go */. Indeed, feel free to copy the question into the .sql file so that you have it for your own records.\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe SQL document should be saved in the R Project as lab2-sds261-yourlastname-yourfirstname.sql. You will have to navigate to the R Project to save the DBeaver file in the correct place.\nConnect to the nyctaxi database, which contains the yellow_old table. See README file (or lab 1) for connection details."
  },
  {
    "objectID": "handout/lab2_clauses_sds261_j24.html#assignment",
    "href": "handout/lab2_clauses_sds261_j24.html#assignment",
    "title": "Lab 2 - SQL clauses",
    "section": "Assignment",
    "text": "Assignment\n\nSelect the trip_distance and total_amount columns from the yellow_old table. For safety (i.e., not crashing your computer), only return the first 5 rows.\n\n\nUsing the AVG() function, find the average total_amount paid in the yellow_old table.\n\n\nWhich type of payment_type had the highest total_amount? How much was it?\n\n\nHow many taxi trips happened on each day of the week? Sort your results so that the day of the week with the fewest rides is at the top of the output.\n\n\nWhich day of the week had the longest trip_distance? Sort the results to have the day of the week with the longest rides at the top of the output.\n\n\nHow many different rate_codes are given in the dataset?\n\n\nStart with the following lines of query:\n\n\nSELECT AVG(trip_distance) AS avg_trip, \n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\n\n\nCan you use WHERE to subset only Saturday and Sunday to find the average trip distance across the weekend? Why or why not?\nCan you use HAVING to subset only Saturday and Sunday to find the average trip distance across the weekend? Why or why not?"
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24.html",
    "href": "handout/lab3_joins_sds261_j24.html",
    "title": "Lab 3 - SQL joins",
    "section": "",
    "text": "Today’s lab will provide practice working with SQL clauses in DBeaver. Don’t forget the importance of the order of the SQL clauses.\nThe goals for lab 3 include:"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#regular-expressions",
    "href": "slides/2024-01-11-regex1.html#regular-expressions",
    "title": "Regular Expressions I",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n\nA regular expression … is a sequence of characters that define a search pattern. Usually such patterns are used by string searching algorithms for “find” or “find and replace” operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#escape-sequences",
    "href": "slides/2024-01-11-regex1.html#escape-sequences",
    "title": "Regular Expressions I",
    "section": "Escape sequences",
    "text": "Escape sequences\nJust to scratch the surface, here are a few special characters that cannot be directly coded. Therefore, they are escaped with a backslash, \\.\n\n\\': single quote.\n\n\\\": double quote.\n\n\\n: newline.\n\n\\r: carriage return.\n\n\\t: tab character."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#quantifiers",
    "href": "slides/2024-01-11-regex1.html#quantifiers",
    "title": "Regular Expressions I",
    "section": "Quantifiers",
    "text": "Quantifiers\nQuantifiers specify how many repetitions of the pattern.\n\n*: matches at least 0 times.\n\n+: matches at least 1 times.\n\n?: matches at most 1 times.\n\n{n}: matches exactly n times.\n\n{n,}: matches at least n times.\n\n{n,m}: matches between n and m times."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#examples-of-quantifiers",
    "href": "slides/2024-01-11-regex1.html#examples-of-quantifiers",
    "title": "Regular Expressions I",
    "section": "Examples of quantifiers",
    "text": "Examples of quantifiers\n\nstrings &lt;- c(\"a\", \"ab\", \"acb\", \"accb\", \"acccb\", \"accccb\")\ngrep(\"ac*b\", strings, value = TRUE)\ngrep(\"ac*b\", strings, value = FALSE)\ngrep(\"ac+b\", strings, value = TRUE)\ngrep(\"ac?b\", strings, value = TRUE)\ngrep(\"ac{2}b\", strings, value = TRUE)\ngrep(\"ac{2,}b\", strings, value = TRUE)\ngrep(\"ac{2,3}b\", strings, value = TRUE)\n\ngrep() stands for “global regular expression print”. grep() returns a character vector containing the selected elements, grepl() returns a logical vector of TRUE/FALSE for whether or not there was a match."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#position-of-pattern-within-the-string",
    "href": "slides/2024-01-11-regex1.html#position-of-pattern-within-the-string",
    "title": "Regular Expressions I",
    "section": "Position of pattern within the string",
    "text": "Position of pattern within the string\n\n^: matches the start of the string.\n\n$: matches the end of the string.\n\n\\b: matches the boundary of a word. Don’t confuse it with ^ $ which marks the edge of a string.\n\n\\B: matches the empty string provided it is not at an edge of a word."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#examples-of-positions",
    "href": "slides/2024-01-11-regex1.html#examples-of-positions",
    "title": "Regular Expressions I",
    "section": "Examples of positions",
    "text": "Examples of positions\n\nstrings &lt;- c(\"abcd\", \"cdab\", \"cabd\", \"c abd\")\ngrep(\"ab\", strings, value = TRUE)\ngrep(\"^ab\", strings, value = TRUE)\ngrep(\"ab$\", strings, value = TRUE)\ngrep(\"\\\\bab\", strings, value = TRUE)"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#examples-of-quantifiers---solution",
    "href": "slides/2024-01-11-regex1.html#examples-of-quantifiers---solution",
    "title": "Regular Expressions I",
    "section": "Examples of quantifiers - solution",
    "text": "Examples of quantifiers - solution\n\nstrings &lt;- c(\"a\", \"ab\", \"acb\", \"accb\", \"acccb\", \"accccb\")\ngrep(\"ac*b\", strings, value = TRUE)\n\n[1] \"ab\"     \"acb\"    \"accb\"   \"acccb\"  \"accccb\"\n\ngrep(\"ac*b\", strings, value = FALSE)\n\n[1] 2 3 4 5 6\n\ngrep(\"ac+b\", strings, value = TRUE)\n\n[1] \"acb\"    \"accb\"   \"acccb\"  \"accccb\"\n\ngrep(\"ac?b\", strings, value = TRUE)\n\n[1] \"ab\"  \"acb\"\n\ngrep(\"ac{2}b\", strings, value = TRUE)\n\n[1] \"accb\"\n\ngrep(\"ac{2,}b\", strings, value = TRUE)\n\n[1] \"accb\"   \"acccb\"  \"accccb\"\n\ngrep(\"ac{2,3}b\", strings, value = TRUE)\n\n[1] \"accb\"  \"acccb\"\n\n\ngrep() stands for “global regular expression print”. grep() returns a character vector containing the selected elements, grepl() returns a logical vector of TRUE/FALSE for whether or not there was a match."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#examples-of-positions---solution",
    "href": "slides/2024-01-11-regex1.html#examples-of-positions---solution",
    "title": "Regular Expressions I",
    "section": "Examples of positions - solution",
    "text": "Examples of positions - solution\n\nstrings &lt;- c(\"abcd\", \"cdab\", \"cabd\", \"c abd\")\ngrep(\"ab\", strings, value = TRUE)\n\n[1] \"abcd\"  \"cdab\"  \"cabd\"  \"c abd\"\n\ngrep(\"^ab\", strings, value = TRUE)\n\n[1] \"abcd\"\n\ngrep(\"ab$\", strings, value = TRUE)\n\n[1] \"cdab\"\n\ngrep(\"\\\\bab\", strings, value = TRUE)\n\n[1] \"abcd\"  \"c abd\""
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#operators",
    "href": "slides/2024-01-11-regex1.html#operators",
    "title": "Regular Expressions I",
    "section": "Operators",
    "text": "Operators\n\n.: matches any single character,\n[...]: a character list, matches any one of the characters inside the square brackets. A - inside the brackets specifies a range of characters.\n\n[^...]: an inverted character list, similar to [...], but matches any characters except those inside the square brackets.\n\n\\: suppress the special meaning of metacharacters in regular expression, i.e. $ * + . ? [ ] ^ { } | ( ) \\. Since \\ itself needs to be escaped in R, we need to escape metacharacters with double backslash like \\\\$.\n\n|: an “or” operator, matches patterns on either side of the |.\n\n(...): grouping in regular expressions. This allows you to retrieve the bits that matched various parts of your regular expression so you can alter them or use them for building up a new string."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#examples-of-operators",
    "href": "slides/2024-01-11-regex1.html#examples-of-operators",
    "title": "Regular Expressions I",
    "section": "Examples of operators",
    "text": "Examples of operators\n\nstrings &lt;- c(\"^ab\", \"ab\", \"abc\", \"abd\", \"abe\", \"ab 12\", \"a|b\")\ngrep(\"ab.\", strings, value = TRUE)\ngrep(\"ab[c-e]\", strings, value = TRUE)\ngrep(\"ab[^c]\", strings, value = TRUE)\ngrep(\"^ab\", strings, value = TRUE)\ngrep(\"\\\\^ab\", strings, value = TRUE)\ngrep(\"abc|abd\", strings, value = TRUE)\ngrep(\"a[b|c]\", strings, value = TRUE)\nstr_extract(strings, \"a[b|c]\")"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#examples-of-operators---solution",
    "href": "slides/2024-01-11-regex1.html#examples-of-operators---solution",
    "title": "Regular Expressions I",
    "section": "Examples of operators - solution",
    "text": "Examples of operators - solution\n\nstrings &lt;- c(\"^ab\", \"ab\", \"abc\", \"abd\", \"abe\", \"ab 12\", \"a|b\")\ngrep(\"ab.\", strings, value = TRUE)\n\n[1] \"abc\"   \"abd\"   \"abe\"   \"ab 12\"\n\ngrep(\"ab[c-e]\", strings, value = TRUE)\n\n[1] \"abc\" \"abd\" \"abe\"\n\ngrep(\"ab[^c]\", strings, value = TRUE)\n\n[1] \"abd\"   \"abe\"   \"ab 12\"\n\ngrep(\"^ab\", strings, value = TRUE)\n\n[1] \"ab\"    \"abc\"   \"abd\"   \"abe\"   \"ab 12\"\n\ngrep(\"\\\\^ab\", strings, value = TRUE)\n\n[1] \"^ab\"\n\ngrep(\"abc|abd\", strings, value = TRUE)\n\n[1] \"abc\" \"abd\"\n\ngrep(\"a[b|c]\", strings, value = TRUE)\n\n[1] \"^ab\"   \"ab\"    \"abc\"   \"abd\"   \"abe\"   \"ab 12\" \"a|b\"  \n\nstr_extract(strings, \"a[b|c]\")\n\n[1] \"ab\" \"ab\" \"ab\" \"ab\" \"ab\" \"ab\" \"a|\""
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#character-classes",
    "href": "slides/2024-01-11-regex1.html#character-classes",
    "title": "Regular Expressions I",
    "section": "Character classes",
    "text": "Character classes\nCharacter classes allow specifying entire classes of characters, such as numbers, letters, etc. There are two flavors of character classes, one uses [: and :] around a predefined name inside square brackets and the other uses \\ and a special character. They are sometimes interchangeable.\n\n(?i) before the string indicates that the match should be case insensitive.\n[:digit:] or \\d: digits, 0 1 2 3 4 5 6 7 8 9, equivalent to [0-9].\n\n\\D: non-digits, equivalent to [^0-9].\n\n[:lower:]: lower-case letters, equivalent to [a-z].\n\n[:upper:]: upper-case letters, equivalent to [A-Z].\n\n[:alpha:]: alphabetic characters, equivalent to [[:lower:][:upper:]] or [A-z].\n\n[:alnum:]: alphanumeric characters, equivalent to [[:alpha:][:digit:]] or [A-z0-9].\n\n\\w: word characters, equivalent to [[:alnum:]_] or [A-z0-9_] (letter, number, or underscore).\n\n\\W: not word, equivalent to [^A-z0-9_].\n\n[:blank:]: blank characters, i.e. space and tab.\n\n[:space:]: space characters: tab, newline, vertical tab, form feed, carriage return, space.\n\\s: space, .\n\n\\S: not space.\n\n[:punct:]: punctuation characters, ! ” # $ % & ’ ( ) * + , - . / : ; &lt; = &gt; ? @ [  ] ^ _ ` { | } ~.\n[:graph:]: graphical (human readable) characters: equivalent to [[:alnum:][:punct:]].\n[:print:]: printable characters, equivalent to [[:alnum:][:punct:]\\\\s]."
  },
  {
    "objectID": "handout/lab4_regexp_sds261_j24.html#footnotes",
    "href": "handout/lab4_regexp_sds261_j24.html#footnotes",
    "title": "Lab 4 - regular expressions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n0-1↩︎\n0-9↩︎"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#lookaround",
    "href": "slides/2024-01-12-regex2.html#lookaround",
    "title": "Regular Expressions II",
    "section": "Lookaround",
    "text": "Lookaround\nA lookaround specifies a place in the regular expression that will anchor the string you’d like to match.\n\n“x(?=y)” – positive lookahead (matches ‘x’ when it is followed by ‘y’)\n“x(?!y)” – negative lookahead (matches ‘x’ when it is not followed by ‘y’)\n“(?&lt;=y)x” – positive lookbehind (matches ‘x’ when it is preceded by ‘y’)\n“(?&lt;!y)x” – negative lookbehind (matches ‘x’ when it is not preceded by ‘y’)"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#example---taskmaster",
    "href": "slides/2024-01-12-regex2.html#example---taskmaster",
    "title": "Regular Expressions II",
    "section": "Example - Taskmaster",
    "text": "Example - Taskmaster\nData scraped from the wiki site for the TV series, Taskmaster.\n\nFigure 2: Taskmaster Wiki https://taskmaster.fandom.com/wiki/Series_11"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#goal-taskmaster-information",
    "href": "slides/2024-01-12-regex2.html#goal-taskmaster-information",
    "title": "Regular Expressions II",
    "section": "Goal: Taskmaster information",
    "text": "Goal: Taskmaster information\nOur goal is to scrape the Taskmaster wiki to create a dataframe which includes the task, description, episode, episode name, air date, contestant, score, and series.1\n\n   Task  Description     episode episode_name air_date contestant score series\n 1 1     Prize: Best th… 1       \"It's not y… 18 Marc… Charlotte… 1         11\n 2 1     Prize: Best th… 1       \"It's not y… 18 Marc… Jamali Ma… 2         11\n 3 1     Prize: Best th… 1       \"It's not y… 18 Marc… Lee Mack   4         11\n 4 1     Prize: Best th… 1       \"It's not y… 18 Marc… Mike Wozn… 5         11\n 5 1     Prize: Best th… 1       \"It's not y… 18 Marc… Sarah Ken… 3         11\n 6 2     Do the most im… 1       \"It's not y… 18 Marc… Charlotte… 2         11\n 7 2     Do the most im… 1       \"It's not y… 18 Marc… Jamali Ma… 3         11\n 8 2     Do the most im… 1       \"It's not y… 18 Marc… Lee Mack   3         11\n 9 2     Do the most im… 1       \"It's not y… 18 Marc… Mike Wozn… 5         11\n10 2     Do the most im… 1       \"It's not y… 18 Marc… Sarah Ken… 4         11\n\nThanks to Ciaran Evans at Wake Forest University for example and code, https://sta279-f23.github.io/"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#scraping-and-wrangling-taskmaster-data",
    "href": "slides/2024-01-12-regex2.html#scraping-and-wrangling-taskmaster-data",
    "title": "Regular Expressions II",
    "section": "Scraping and wrangling Taskmaster data",
    "text": "Scraping and wrangling Taskmaster data\nOur goal is to scrape the Taskmaster wiki to create a dataframe which includes the task, description, episode, episode name, air date, contestant, score, and series.1\n\nresults &lt;- read_html(\"https://taskmaster.fandom.com/wiki/Series_11\") |&gt;\n  html_element(\".tmtable\") |&gt; \n  html_table() |&gt;\n  mutate(episode = ifelse(startsWith(Task, \"Episode\"), Task, NA)) |&gt;\n  fill(episode, .direction = \"down\") |&gt;\n  filter(!startsWith(Task, \"Episode\"), \n         !(Task %in% c(\"Total\", \"Grand Total\"))) |&gt;\n  pivot_longer(cols = -c(Task, Description, episode),\n               names_to = \"contestant\",\n               values_to = \"score\") |&gt;\n  mutate(series = 11)\n\nThanks to Ciaran Evans at Wake Forest University for example and code, https://sta279-f23.github.io/"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#scraping-and-wrangling-taskmaster-data---results",
    "href": "slides/2024-01-12-regex2.html#scraping-and-wrangling-taskmaster-data---results",
    "title": "Regular Expressions II",
    "section": "Scraping and wrangling Taskmaster data - results",
    "text": "Scraping and wrangling Taskmaster data - results\n\nresults |&gt; \n  select(Task, Description, episode, contestant, score, series) |&gt;\n  head(10)\n\n# A tibble: 10 × 6\n  Task  Description                              episode contestant score series\n  &lt;chr&gt; &lt;chr&gt;                                    &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;\n1 1     Prize: Best thing you can carry, but on… Episod… Charlotte… 1         11\n2 1     Prize: Best thing you can carry, but on… Episod… Jamali Ma… 2         11\n3 1     Prize: Best thing you can carry, but on… Episod… Lee Mack   4         11\n4 1     Prize: Best thing you can carry, but on… Episod… Mike Wozn… 5         11\n5 1     Prize: Best thing you can carry, but on… Episod… Sarah Ken… 3         11\n6 2     Do the most impressive thing under the … Episod… Charlotte… 2         11\n# ℹ 4 more rows"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#more-succinct-results",
    "href": "slides/2024-01-12-regex2.html#more-succinct-results",
    "title": "Regular Expressions II",
    "section": "more succinct results",
    "text": "more succinct results\n\n   Task  Description         episode   contestant score series\n  1     Prize: Best thing…  Episode 1… Charlotte… 1         11\n  1     Prize: Best thing…  Episode 1… Jamali Ma… 2         11\n  1     Prize: Best thing…  Episode 1… Lee Mack   4         11\n  1     Prize: Best thing…  Episode 1… Mike Wozn… 5         11\n  1     Prize: Best thing…  Episode 1… Sarah Ken… 3         11\n  2     Do the most…        Episode 1… Charlotte… 2         11\n  2     Do the most…        Episode 1… Jamali Ma… 3[1]      11\n  2     Do the most…        Episode 1… Lee Mack   3         11\n  2     Do the most…        Episode 1… Mike Wozn… 5         11\n  2     Do the most…        Episode 1… Sarah Ken… 4         11\n\nCurrently, the episode column contains entries like\n\n\"Episode 1: It's not your fault. (18 March 2021)\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#cleaning-the-score-column",
    "href": "slides/2024-01-12-regex2.html#cleaning-the-score-column",
    "title": "Regular Expressions II",
    "section": "Cleaning the score column",
    "text": "Cleaning the score column\n\ntable(results$score)\n\n\n   –    ✔    ✘    0    1    2    3 3[1] 3[2]    4 4[2]    5   DQ \n   7    1    1   11   37   42   48    1    3   50    1   55   13 \n\n\nHow should the scores be stored? What is the cleaning task?\n\nFigure 3: Taskmaster Wiki https://taskmaster.fandom.com/wiki/Series_11"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-numeric-information",
    "href": "slides/2024-01-12-regex2.html#extracting-numeric-information",
    "title": "Regular Expressions II",
    "section": "Extracting numeric information",
    "text": "Extracting numeric information\nSuppose we have the following string:\n\n\"3[1]\"\n\nAnd we want to extract just the number “3”:\n\nstr_extract(\"3[1]\", \"3\")\n\n[1] \"3\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-numeric-information-1",
    "href": "slides/2024-01-12-regex2.html#extracting-numeric-information-1",
    "title": "Regular Expressions II",
    "section": "Extracting numeric information",
    "text": "Extracting numeric information\nWhat if we don’t know which number to extract?\n\nstr_extract(\"3[1]\", \"\\\\d\")\n\n[1] \"3\"\n\n\n\nstr_extract(\"4[1]\", \"\\\\d\")\n\n[1] \"4\"\n\n\n\nstr_extract(\"10[1]\", \"\\\\d\")\n\n[1] \"1\"\n\n\n\nstr_extract(\"10[1]\", \"\\\\d+\")\n\n[1] \"10\"\n\n\n\nstr_extract(\"DQ\", \"\\\\d\")\n\n[1] NA"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#str_extract",
    "href": "slides/2024-01-12-regex2.html#str_extract",
    "title": "Regular Expressions II",
    "section": "str_extract()",
    "text": "str_extract()\nstr_extract() is an R function in the stringr package which finds regular expressions in strings of text.\n\nstr_extract(\"My cat is 3 years old\", \"cat\")\n\n[1] \"cat\"\n\n\n\nstr_extract(\"My cat is 3 years old\", \"3\")\n\n[1] \"3\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#matching-multiple-options",
    "href": "slides/2024-01-12-regex2.html#matching-multiple-options",
    "title": "Regular Expressions II",
    "section": "Matching multiple options",
    "text": "Matching multiple options\nstr_extract() returns the first match; str_extract_all() allows more than one match.\n\nstr_extract(\"My cat is 3 years old\", \"cat|dog\")\n\n[1] \"cat\"\n\nstr_extract(\"My dog is 10 years old\", \"cat|dog\")\n\n[1] \"dog\"\n\nstr_extract(\"My dog is 10 years old, my cat is 3 years old\", \n            \"cat|dog\")\n\n[1] \"dog\"\n\nstr_extract_all(\"My dog is 10 years old, my cat is 3 years old\", \n                \"cat|dog\")\n\n[[1]]\n[1] \"dog\" \"cat\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#matching-groups-of-characters",
    "href": "slides/2024-01-12-regex2.html#matching-groups-of-characters",
    "title": "Regular Expressions II",
    "section": "Matching groups of characters",
    "text": "Matching groups of characters\nWhat if I want to extract a number?\n\nstr_extract(\"My cat is 3 years old\", \"\\\\d\")\n\n[1] \"3\"\n\n\nWhat will the result be for the following code?\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d\")"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#matching-groups-of-characters-1",
    "href": "slides/2024-01-12-regex2.html#matching-groups-of-characters-1",
    "title": "Regular Expressions II",
    "section": "Matching groups of characters",
    "text": "Matching groups of characters\nWhat if I want to extract a number?\n\nstr_extract(\"My cat is 3 years old\", \"\\\\d\")\n\n[1] \"3\"\n\n\nWhat will the result be for the following code?\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d\")\n\n[1] \"1\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#matching-groups-of-characters-2",
    "href": "slides/2024-01-12-regex2.html#matching-groups-of-characters-2",
    "title": "Regular Expressions II",
    "section": "Matching groups of characters",
    "text": "Matching groups of characters\nWhat if I want to extract a number?\n\nstr_extract(\"My cat is 3 years old\", \"\\\\d\")\n\n[1] \"3\"\n\n\nWhat will the result be for the following code?\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d\")\n\n[1] \"1\"\n\n\nThe + symbol in a regular expression means “repeated one or more times”\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d+\")\n\n[1] \"10\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-from-multiple-strings",
    "href": "slides/2024-01-12-regex2.html#extracting-from-multiple-strings",
    "title": "Regular Expressions II",
    "section": "Extracting from multiple strings",
    "text": "Extracting from multiple strings\n\nstrings &lt;- c(\"My cat is 3 years old\", \"My dog is 10 years old\")\nstr_extract(strings, \"\\\\d+\")\n\n[1] \"3\"  \"10\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-episode-information",
    "href": "slides/2024-01-12-regex2.html#extracting-episode-information",
    "title": "Regular Expressions II",
    "section": "Extracting episode information",
    "text": "Extracting episode information\nCurrently, the episode column contains entries like:\n\n\"Episode 2: The pie whisperer. (4 August 2015)\"\n\nHow would I extract just the episode number?"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-episode-information-1",
    "href": "slides/2024-01-12-regex2.html#extracting-episode-information-1",
    "title": "Regular Expressions II",
    "section": "Extracting episode information",
    "text": "Extracting episode information\nCurrently, the episode column contains entries like:\n\n\"Episode 2: The pie whisperer. (4 August 2015)\"\n\nHow would I extract just the episode number?\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \"\\\\d+\")\n\n[1] \"2\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-episode-information-2",
    "href": "slides/2024-01-12-regex2.html#extracting-episode-information-2",
    "title": "Regular Expressions II",
    "section": "Extracting episode information",
    "text": "Extracting episode information\nCurrently, the episode column contains entries like:\n\n\"Episode 2: The pie whisperer. (4 August 2015)\"\n\nHow would I extract the episode name?\nGoal: find a pattern to match: anything that starts with a :, ends with a .\nLet’s break down that task into pieces."
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-episode-information-3",
    "href": "slides/2024-01-12-regex2.html#extracting-episode-information-3",
    "title": "Regular Expressions II",
    "section": "Extracting episode information",
    "text": "Extracting episode information\nHow can we find the period at the end of the sentence? What does each of these lines of code return?\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".\")\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".+\")\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \"\\\\.\")"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-episode-information---solution",
    "href": "slides/2024-01-12-regex2.html#extracting-episode-information---solution",
    "title": "Regular Expressions II",
    "section": "Extracting episode information - solution",
    "text": "Extracting episode information - solution\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".\")\n\n[1] \"E\"\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".+\")\n\n[1] \"Episode 2: The pie whisperer. (4 August 2015)\"\n\n\nWe use an escape character when we actually want to choose a period:\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \"\\\\.\")\n\n[1] \".\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-episode-information-4",
    "href": "slides/2024-01-12-regex2.html#extracting-episode-information-4",
    "title": "Regular Expressions II",
    "section": "Extracting episode information",
    "text": "Extracting episode information\nGoal: find a pattern to match: anything that starts with a :, ends with a .\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\",\n            \":.+\\\\.\")\n\n[1] \": The pie whisperer.\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-episode-information-5",
    "href": "slides/2024-01-12-regex2.html#extracting-episode-information-5",
    "title": "Regular Expressions II",
    "section": "Extracting episode information",
    "text": "Extracting episode information\nGetting everything between the : and the .\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=: ).+(?=\\\\.)\")\n\n[1] \"The pie whisperer\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#lookbehinds",
    "href": "slides/2024-01-12-regex2.html#lookbehinds",
    "title": "Regular Expressions II",
    "section": "Lookbehinds",
    "text": "Lookbehinds\n(?&lt;=) is a positive lookbehind. It is used to identify expressions which are preceded by a particular expression.\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=: ).+\")\n\n[1] \"The pie whisperer. (4 August 2015)\"\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=\\\\. ).+\")\n\n[1] \"(4 August 2015)\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#lookaheads",
    "href": "slides/2024-01-12-regex2.html#lookaheads",
    "title": "Regular Expressions II",
    "section": "Lookaheads",
    "text": "Lookaheads\n(?=) is a positive lookahead. It is used to identify expressions which are followed by a particular expression.\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \".+(?=\\\\.)\")\n\n[1] \"Episode 2: The pie whisperer\"\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \".+(?=:)\")\n\n[1] \"Episode 2\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-air-date",
    "href": "slides/2024-01-12-regex2.html#extracting-air-date",
    "title": "Regular Expressions II",
    "section": "Extracting air date",
    "text": "Extracting air date\nI want to extract just the air date. What pattern do I want to match?\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", ...)"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-air-date-1",
    "href": "slides/2024-01-12-regex2.html#extracting-air-date-1",
    "title": "Regular Expressions II",
    "section": "Extracting air date",
    "text": "Extracting air date\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=\\\\().+(?=\\\\))\")\n\n[1] \"4 August 2015\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#wrangling-the-episode-info",
    "href": "slides/2024-01-12-regex2.html#wrangling-the-episode-info",
    "title": "Regular Expressions II",
    "section": "Wrangling the episode info",
    "text": "Wrangling the episode info\nCurrently:\n\n\n# A tibble: 270 × 1\n  episode                                        \n  &lt;chr&gt;                                          \n1 Episode 1: It's not your fault. (18 March 2021)\n2 Episode 1: It's not your fault. (18 March 2021)\n3 Episode 1: It's not your fault. (18 March 2021)\n4 Episode 1: It's not your fault. (18 March 2021)\n5 Episode 1: It's not your fault. (18 March 2021)\n6 Episode 1: It's not your fault. (18 March 2021)\n# ℹ 264 more rows"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#wrangling-the-episode-info-1",
    "href": "slides/2024-01-12-regex2.html#wrangling-the-episode-info-1",
    "title": "Regular Expressions II",
    "section": "Wrangling the episode info",
    "text": "Wrangling the episode info\nOne option:\n\nresults |&gt;\n  select(episode) |&gt;\n  mutate(episode_name = str_extract(episode, \"(?&lt;=: ).+(?=\\\\.)\"),\n         air_date = str_extract(episode, \"(?&lt;=\\\\().+(?=\\\\))\"),\n         episode = str_extract(episode, \"\\\\d+\"))\n\n# A tibble: 270 × 3\n  episode episode_name        air_date     \n  &lt;chr&gt;   &lt;chr&gt;               &lt;chr&gt;        \n1 1       It's not your fault 18 March 2021\n2 1       It's not your fault 18 March 2021\n3 1       It's not your fault 18 March 2021\n4 1       It's not your fault 18 March 2021\n5 1       It's not your fault 18 March 2021\n6 1       It's not your fault 18 March 2021\n# ℹ 264 more rows"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#wrangling-the-episode-info-2",
    "href": "slides/2024-01-12-regex2.html#wrangling-the-episode-info-2",
    "title": "Regular Expressions II",
    "section": "Wrangling the episode info",
    "text": "Wrangling the episode info\nAnother option:\n\nresults |&gt;\n  separate_wider_regex(episode, \n                       patterns = c(\".+ \", \n                                    episode = \"\\\\d+\", \n                                    \": \", \n                                    episode_name = \".+\", \n                                    \"\\\\. \\\\(\", \n                                    air_date = \".+\", \n                                    \"\\\\)\"))\n\n\n\n# A tibble: 270 × 3\n  episode episode_name        air_date     \n  &lt;chr&gt;   &lt;chr&gt;               &lt;chr&gt;        \n1 1       It's not your fault 18 March 2021\n2 1       It's not your fault 18 March 2021\n3 1       It's not your fault 18 March 2021\n4 1       It's not your fault 18 March 2021\n5 1       It's not your fault 18 March 2021\n6 1       It's not your fault 18 March 2021\n# ℹ 264 more rows"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#lookaround-1",
    "href": "slides/2024-01-12-regex2.html#lookaround-1",
    "title": "Regular Expressions II",
    "section": "Lookaround",
    "text": "Lookaround\n\nFigure 1: Image credit: Stefan Judis https://www.stefanjudis.com/blog/a-regular-expression-lookahead-lookbehind-cheat-sheet/"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#scraping-and-wrangling-taskmaster",
    "href": "slides/2024-01-12-regex2.html#scraping-and-wrangling-taskmaster",
    "title": "Regular Expressions II",
    "section": "Scraping and wrangling Taskmaster",
    "text": "Scraping and wrangling Taskmaster\nGoal: to scrape the Taskmaster wiki into a dataframe including task, description, episode, episode name, air date, contestant, score, and series.1\n\nresults &lt;- read_html(\"https://taskmaster.fandom.com/wiki/Series_11\") |&gt;\n  html_element(\".tmtable\") |&gt; \n  html_table() |&gt;\n  mutate(episode = ifelse(startsWith(Task, \"Episode\"), Task, NA)) |&gt;\n  fill(episode, .direction = \"down\") |&gt;\n  filter(!startsWith(Task, \"Episode\"), \n         !(Task %in% c(\"Total\", \"Grand Total\"))) |&gt;\n  pivot_longer(cols = -c(Task, Description, episode),\n               names_to = \"contestant\",\n               values_to = \"score\") |&gt;\n  mutate(series = 11)\n\nThanks to Ciaran Evans at Wake Forest University for example and code, https://sta279-f23.github.io/"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#extracting-from-multiple-strings-1",
    "href": "slides/2024-01-12-regex2.html#extracting-from-multiple-strings-1",
    "title": "Regular Expressions II",
    "section": "Extracting from multiple strings",
    "text": "Extracting from multiple strings\nWhat if we have multiple instances across multiple strings? We need to be careful working with lists (instead of vectors).\n\nstrings &lt;- c(\"My cat is 3 years old\", \"My dog is 10 years old\")\nstr_extract(strings, \"\\\\w+\")\n\n[1] \"My\" \"My\"\n\nstr_extract_all(strings, \"\\\\w+\")\n\n[[1]]\n[1] \"My\"    \"cat\"   \"is\"    \"3\"     \"years\" \"old\"  \n\n[[2]]\n[1] \"My\"    \"dog\"   \"is\"    \"10\"    \"years\" \"old\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#lookaround-again",
    "href": "slides/2024-01-12-regex2.html#lookaround-again",
    "title": "Regular Expressions II",
    "section": "Lookaround (again)",
    "text": "Lookaround (again)\n\nFigure 4: Image credit: Stefan Judis https://www.stefanjudis.com/blog/a-regular-expression-lookahead-lookbehind-cheat-sheet/"
  },
  {
    "objectID": "handout/lab4_regex_sds261_j24.html",
    "href": "handout/lab4_regex_sds261_j24.html",
    "title": "Lab 4 - regular expressions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(stringr)\nToday’s lab will provide practice working with regular expressions in R.\nThe goals for lab 4 include:"
  },
  {
    "objectID": "handout/lab4_regex_sds261_j24.html#footnotes",
    "href": "handout/lab4_regex_sds261_j24.html#footnotes",
    "title": "Lab 4 - regular expressions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n0-1↩︎\n0-9↩︎\nLorem Ipsum from https://www.webfx.com/web-design/html-ipsum/.↩︎"
  },
  {
    "objectID": "handout/ws1_sds261_j24.html",
    "href": "handout/ws1_sds261_j24.html",
    "title": "Worksheet 1 - DB, R, SQL, Oh My!",
    "section": "",
    "text": "Your Name: __________________________________\nNames of people you worked with: __________________________________\n\nIntroduce yourself. Which dorm do you live in? What is one great thing and one lousy thing about that dorm?\nName one thing in the Syllabus / website / etc. for this class that either sounds strange/unusual or that you would like to know more about.\n\nTask: Consider a large hospital system that coordinates all aspects of health care: doctors, visits, prescriptions, surgeries, billing, etc. Let’s say that the hospital has a database which includes a series of tables linking all the needed information that they routinely collect.\n\nCome up with at least five tables which might exist in the hospital database. For each table indicate a few columns / variables.\nDraw arrows between the tables and indicate the variable(s) that link the tables. No table should be completely isolated.\n\n\nSolution:\nThe solution is taken directly from w3resource. Consider the hypothetical SQL schema diagram in Figure 1. Some of the tables and respective variables are described below.\n\nphysician\n\nemployeeid - unique ID of a physician\nname - name of physician\nposition - designation of a physician\nssn - social security number of physician\n\ndepartment\n\ndepartmentid - unique ID of the department\nname - name of the department\nhead - ID of the physician who is the head of the department, connects to the employeeid of the table physician\n\naffiliated_with\n\nphysician - ID of the physician, connects to the employeeid of the table physician\ndepartment - ID of the department, connects to the departmentid of the table department\nprimaryaffiliation - logical column which indicates whether the physicians are affiliated or not\n\nprocedure\n\ncode - unique ID of the medical procedure\nname - name of the medical procedure\ncost - cost of the medical procedure\n\ntrained_in\n\nphysician - ID of the physician, connects to the employeeid of the table physician\ntreatment - ID of the medical procedure, connects to the code of the procedure table\ncertificationdate - starting date of certification\ncertificationexpires - expiry date of certification\n\npatient\n\nssn - unique ID for each patient\nname - name of patient\naddress - address of patient\nphone - phone number of patient\n\n\n\n\n\n\n\nFigure 1: SQL schema describing links of tables from a hypothetical hospital database, image credit: https://www.w3resource.com/sql-exercises/hospital-database-exercise/index.php\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/lab2_clauses_sds261_j24_sol.html",
    "href": "handout/lab2_clauses_sds261_j24_sol.html",
    "title": "Lab 2 - SQL clauses",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(mdsr)\nToday’s lab will provide practice working with SQL clauses in DBeaver. Don’t forget the importance of the order of the SQL clauses.\nThe goals for lab 2 include:"
  },
  {
    "objectID": "handout/lab2_clauses_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab2_clauses_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "title": "Lab 2 - SQL clauses",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .sql file) which problem is being answered with which SQL code. Use the following syntax to comment within a .sql file: /* here is where comments go */. Indeed, feel free to copy the question into the .sql file so that you have it for your own records.\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe SQL document should be saved in the R Project as lab2-sds261-yourlastname-yourfirstname.sql. You will have to navigate to the R Project to save the DBeaver file in the correct place.\nConnect to the nyctaxi database, which contains the yellow_old table. See README file (or lab 1) for connection details."
  },
  {
    "objectID": "handout/lab2_clauses_sds261_j24_sol.html#assignment",
    "href": "handout/lab2_clauses_sds261_j24_sol.html#assignment",
    "title": "Lab 2 - SQL clauses",
    "section": "Assignment",
    "text": "Assignment\n\nSelect the trip_distance and total_amount columns from the yellow_old table. For safety (i.e., not crashing your computer), only return the first 5 rows.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT trip_distance, total_amount\nFROM yellow_old\nLIMIT 0, 5;\n\n\n5 records\n\n\ntrip_distance\ntotal_amount\n\n\n\n\nNA\nNA\n\n\n2.0\n12.0\n\n\n1.2\n8.0\n\n\n0.5\n7.2\n\n\n3.5\n18.0\n\n\n\n\n\n\n\n\n\nUsing the AVG() function, find the average total_amount paid in the yellow_old table.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT AVG(total_amount)\nFROM yellow_old\nLIMIT 0, 5;\n\n\n1 records\n\n\nAVG(total_amount)\n\n\n\n\n14.76179\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe average total fare was $14.76\n\n\n\n\n\nWhich type of payment_type had the highest total_amount? How much was it?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT MAX(total_amount), payment_type\nFROM yellow_old\nGROUP BY payment_type\nLIMIT 0, 5;\n\n\n5 records\n\n\nMAX(total_amount)\npayment_type\n\n\n\n\nNA\nNA\n\n\n540.00\nCRD\n\n\n1007.51\nCSH\n\n\n484.04\nDIS\n\n\n950.30\nNOC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe highest total amount was a cash payment for $1007.51. Yikes, that’s a big bill for a taxi ride. Note that the second highest payment was $950.30 for a no charge ride. How does that happen?\n\n\n\n\n\nHow many taxi trips happened on each day of the week? Sort your results so that the day of the week with the fewest rides is at the top of the output.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) AS num_transactions, \n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY wday\nORDER BY num_transactions;\n\n\n8 records\n\n\nnum_transactions\nwday\n\n\n\n\n1\nNA\n\n\n1887838\nTuesday\n\n\n1984031\nWednesday\n\n\n2088305\nThursday\n\n\n2125292\nFriday\n\n\n2215255\nMonday\n\n\n2364039\nSunday\n\n\n2763367\nSaturday\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nUnsurprisingly, the most rides were on the weekends. Monday is a close third, possibly a reflection of how hard it is to get out of bed on Monday mornings.\n\n\n\n\n\nWhich day of the week had the longest trip_distance? Sort the results to have the day of the week with the longest rides at the top of the output.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT MAX(trip_distance) AS long_trip, \n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY wday\nORDER BY long_trip DESC;\n\n\n8 records\n\n\nlong_trip\nwday\n\n\n\n\n5005013.0\nMonday\n\n\n100.0\nWednesday\n\n\n100.0\nFriday\n\n\n100.0\nSunday\n\n\n97.4\nTuesday\n\n\n96.1\nThursday\n\n\n92.9\nSaturday\n\n\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nHoly cow, one of the trips is 5,005,013 miles! That can’t be right!??!\n\n\n\n\n\nHow many different rate_codes are given in the dataset?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT DISTINCT rate_code\nFROM yellow_old\nLIMIT 0, 20;\n\n\nDisplaying records 1 - 10\n\n\nrate_code\n\n\n\n\nNA\n\n\n1\n\n\n2\n\n\n5\n\n\n3\n\n\n4\n\n\n0\n\n\n6\n\n\n210\n\n\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) AS num_code, rate_code\nFROM yellow_old\nGROUP BY rate_code\nORDER BY num_code DESC\nLIMIT 0, 20;\n\n\nDisplaying records 1 - 10\n\n\nnum_code\nrate_code\n\n\n\n\n15088481\n1\n\n\n268161\n2\n\n\n42092\n5\n\n\n22935\n3\n\n\n4676\n4\n\n\n1579\n0\n\n\n179\n6\n\n\n14\n210\n\n\n4\n8\n\n\n4\n7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere are 11 different rate codes. Rate codes are different because the taxi charges you a different rate if, for example, you go to JFK or go very far away.\nThe second solution not only gave rate codes, but also the number of transactions for each rate code.\n\n\n\n\n\nStart with the following lines of query:\n\n\nSELECT AVG(trip_distance) AS avg_trip, \n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\n\n\nCan you use WHERE to subset only Saturday and Sunday to find the average trip distance across the weekend? Why or why not?\nCan you use HAVING to subset only Saturday and Sunday to find the average trip distance across the weekend? Why or why not?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT AVG(trip_distance) AS avg_trip, \n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY wday\nHAVING wday = \"Saturday\" | wday = \"Sunday\"\nLIMIT 0,8;\n\n\n0 records\n\n\navg_trip\nwday\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNeither WHERE nor HAVING can be used with this query to find the average trip distance across the weekend days.\nWHERE cannot be used because wday is not in the original dataset. WHERE works on the original data.\nHAVING cannot be used because the average has already been taken across the groups, so there isn’t any way to go back and re-calculate the average across Saturday and Sunday. HAVING works on the results set."
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24_sol.html",
    "href": "handout/lab3_joins_sds261_j24_sol.html",
    "title": "Lab 3 - SQL joins",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(mdsr)\nToday’s lab will provide practice working with SQL clauses in DBeaver. Don’t forget the importance of the order of the SQL clauses.\nThe goals for lab 3 include:"
  },
  {
    "objectID": "slides/2024-01-08-db.html",
    "href": "slides/2024-01-08-db.html",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "",
    "text": "structured collection of data organized with\n\nefficient storage\neasy retrieval\nconsistent management\n\ndata stored in tables which are linked to one another via keys\n\n\n\n\n\ndata frame (R) or table (SQL)\ncolumns of variables\nrows of observational units\n\n\n\n\n\ntables in SQL databases can be arbitrarily large\n\nlive in storage, computer’s hard drive (usually remote)\n\ndata frames in R\n\nlive in memory (RAM) on your personal computer\n\ntables in a database are linked via a key."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html",
    "href": "slides/2024-01-11-regex1.html",
    "title": "Regular Expressions I",
    "section": "",
    "text": "A regular expression … is a sequence of characters that define a search pattern. Usually such patterns are used by string searching algorithms for “find” or “find and replace” operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory."
  },
  {
    "objectID": "slides/2024-01-12-regex2.html",
    "href": "slides/2024-01-12-regex2.html",
    "title": "Regular Expressions II",
    "section": "",
    "text": "A lookaround specifies a place in the regular expression that will anchor the string you’d like to match.\n\n“x(?=y)” – positive lookahead (matches ‘x’ when it is followed by ‘y’)\n“x(?!y)” – negative lookahead (matches ‘x’ when it is not followed by ‘y’)\n“x(?&lt;=y)” – positive lookbehind (matches ‘x’ when it is preceded by ‘y’)\n“x(?&lt;!y)” – negative lookbehind (matches ‘x’ when it is not preceded by ‘y’)"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#footnotes",
    "href": "slides/2024-01-12-regex2.html#footnotes",
    "title": "Regular Expressions II",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThanks to Ciaran Evans at Wake Forest University for example and code, https://sta279-f23.github.io/↩︎"
  },
  {
    "objectID": "slides/2024-01-08-db.html#tables-in-airlines-database",
    "href": "slides/2024-01-08-db.html#tables-in-airlines-database",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "Tables in airlines database",
    "text": "Tables in airlines database\n\nDBI::dbListTables(con_air)\n\n[1] \"airports\" \"carriers\" \"flights\"  \"planes\""
  },
  {
    "objectID": "slides/2024-01-08-db.html#what-is-sql",
    "href": "slides/2024-01-08-db.html#what-is-sql",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "What is SQL?",
    "text": "What is SQL?\n\nSQL is a programming language for working with relational databases.\nSQL has been around since the 1970s, but has, unfortunately, many different dialects.\nTo connect to the Smith and mdsr databases (via R and DBeaver), we will use MySQL.\nTo connect to DuckDB, we will use the dialect native to DuckDB."
  },
  {
    "objectID": "slides/2024-01-08-db.html#a-github-merge-conflict",
    "href": "slides/2024-01-08-db.html#a-github-merge-conflict",
    "title": "Databases and dbplyr and SQL, oh my!",
    "section": "A GitHub merge conflict",
    "text": "A GitHub merge conflict\n\nOn GitHub (on the web) edit the README document and Commit it with a message describing what you did.\nThen, in RStudio also edit the README document with a different change.\n\nCommit your changes\nTry to push – you’ll get an error!\nTry pulling\nResolve the merge conflict and then commit and push\n\nAs you work in teams you are likely to run into merge conflicts, learning how to resolve them properly will be very important."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#select-distinct",
    "href": "slides/2024-01-09-clauses.html#select-distinct",
    "title": "SQL clauses",
    "section": "SELECT DISTINCT",
    "text": "SELECT DISTINCT\nReturns only unique rows.\n\nSELECT DISTINCT payment_type\nFROM yellow_old\nLIMIT 0, 20;\n\n\n\n\n6 records\n\n\n\n\npayment_type\n\n\n\n\n\n\n\n\n\n\nCRD\n\n\n\n\nCSH\n\n\n\n\nNOC\n\n\n\n\nDIS\n\n\n\n\nUNK\n\n\n\n\n\n\n\n\nSELECT DISTINCT vendor_id, payment_type\nFROM yellow_old\nLIMIT 0, 20;\n\n\n\n\n8 records\n\n\n\n\nvendor_id\n\n\npayment_type\n\n\n\n\n\n\n\n\n\n\n\n\nCMT\n\n\nCRD\n\n\n\n\nCMT\n\n\nCSH\n\n\n\n\nCMT\n\n\nNOC\n\n\n\n\nCMT\n\n\nDIS\n\n\n\n\nVTS\n\n\nCRD\n\n\n\n\nVTS\n\n\nCSH\n\n\n\n\nVTS\n\n\nUNK\n\n\n\n\n\n\n\nIn case you are curious:\n\nVTS is Verifone Transportation Systems and CMT is Mobile Knowledge Systems Inc.\nCRD is credit card; CSH is cash; NOC is no charge; DIS is dispute"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#where-6",
    "href": "slides/2024-01-09-clauses.html#where-6",
    "title": "SQL clauses",
    "section": "WHERE",
    "text": "WHERE\nIS NULL not = NULL (because NULL indicates unknown)\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE payment_type IS NULL\nLIMIT 0, 10;\n\n\n\n\n1 records\n\n\n\n\npayment_type\n\n\nfare_amount\n\n\ntip_amount\n\n\ntotal_amount\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE payment_type = NULL\nLIMIT 0, 10;\n\n\n\n\n0 records\n\n\n\n\npayment_type\n\n\nfare_amount\n\n\ntip_amount\n\n\ntotal_amount"
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24.html#best-practice",
    "href": "handout/lab3_joins_sds261_j24.html#best-practice",
    "title": "Lab 3 - SQL joins",
    "section": "Best practice",
    "text": "Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\nDBI::dbDisconnect(con_yelp)"
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24_sol.html#best-practice",
    "href": "handout/lab3_joins_sds261_j24_sol.html#best-practice",
    "title": "Lab 3 - SQL joins",
    "section": "Best practice",
    "text": "Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\nDBI::dbDisconnect(con_yelp)"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#imdb",
    "href": "slides/2024-01-10-joins.html#imdb",
    "title": "SQL joins",
    "section": "IMDb",
    "text": "IMDb\nConsider a database of information from IMDb."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#join-imdb-title-votes",
    "href": "slides/2024-01-10-joins.html#join-imdb-title-votes",
    "title": "SQL joins",
    "section": "JOIN IMDb title + votes",
    "text": "JOIN IMDb title + votes\nIn the imdb database, the title table includes information about the 4,626,322 titles in the database, including the id, title, kind_id (indicator for the kind of ID it is), and production_year. It does not, however, include the review of the title.\n\nSELECT * FROM title LIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\ntitle\n\n\nimdb_index\n\n\nkind_id\n\n\nproduction_year\n\n\nimdb_id\n\n\nphonetic_code\n\n\nepisode_of_id\n\n\nseason_nr\n\n\nepisode_nr\n\n\nseries_years\n\n\nmd5sum\n\n\n\n\n\n\n78460\n\n\nAdults Recat to the Simpsons (30th Anniversary)\n\n\n\n\n7\n\n\n2017\n\n\n\n\nA3432\n\n\n78406\n\n\n\n\n\n\n\n\n2ae09eed7d576cc2c24774fed5b18168\n\n\n\n\n70273\n\n\n(2016-05-18)\n\n\n\n\n7\n\n\n2016\n\n\n\n\n\n\n68058\n\n\n\n\n\n\n\n\n511dfc14cfff7589d29a95abb30cd66a\n\n\n\n\n60105\n\n\n(2014-04-11)\n\n\n\n\n7\n\n\n2014\n\n\n\n\n\n\n59138\n\n\n\n\n\n\n\n\nc6cdce7e667e07713e431805c407feed\n\n\n\n\n32120\n\n\n(2008-05-01)\n\n\n\n\n7\n\n\n2008\n\n\n\n\n\n\n32060\n\n\n\n\n\n\n\n\n100df65742caf5afd092b2e0ead67d8e\n\n\n\n\n97554\n\n\nSchmÃ¶lders Traum\n\n\n\n\n7\n\n\n2001\n\n\n\n\nS2543\n\n\n97302\n\n\n10\n\n\n1\n\n\n\n\n46862a2f96f9fb2d59e8c9a11ecfdd28\n\n\n\n\n57966\n\n\n(#1.1)\n\n\n\n\n7\n\n\n2013\n\n\n\n\n\n\n57965\n\n\n1\n\n\n1\n\n\n\n\n409c37703766c4b24f8a86162fd9cf85\n\n\n\n\n76391\n\n\nAnniversary\n\n\n\n\n7\n\n\n1971\n\n\n\n\nA5162\n\n\n76385\n\n\n4\n\n\n9\n\n\n\n\n5e12ce73fac1d1dcf94136b6e9acd8f8\n\n\n\n\n11952\n\n\nAngus Black/Lester Barrie/DC Curry\n\n\n\n\n7\n\n\n2009\n\n\n\n\nA5214\n\n\n11937\n\n\n4\n\n\n7\n\n\n\n\n9c38b9e5601dc154444b73b518034aa1\n\n\n\n\n1554\n\n\nNew Orleans\n\n\n\n\n7\n\n\n2003\n\n\n\n\nN6452\n\n\n1508\n\n\n2\n\n\n11\n\n\n\n\n621bea735740a547e862e4a3226f35d2\n\n\n\n\n58442\n\n\nKiss Me Kate\n\n\n\n\n7\n\n\n2011\n\n\n\n\nK2523\n\n\n58436\n\n\n1\n\n\n10\n\n\n\n\n293e8c75c7f35a4035abf617962be5a9"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#join-imdb-title-votes-1",
    "href": "slides/2024-01-10-joins.html#join-imdb-title-votes-1",
    "title": "SQL joins",
    "section": "JOIN IMDb title + votes",
    "text": "JOIN IMDb title + votes\nThe movie_info_idx table does not contain much information about each particular film. It does, however, have an indicator for the movie ID (given by movie_id) as well as the number of votes (given by info where type_id = 100).\n\nSELECT * FROM movie_info_idx LIMIT 0, 6;\n\n\n\n\n6 records\n\n\n\n\nid\n\n\nmovie_id\n\n\ninfo_type_id\n\n\ninfo\n\n\nnote\n\n\n\n\n\n\n1\n\n\n1\n\n\n99\n\n\n31.2.1..2.\n\n\n\n\n\n\n2\n\n\n1\n\n\n100\n\n\n9\n\n\n\n\n\n\n3\n\n\n1\n\n\n101\n\n\n4.1\n\n\n\n\n\n\n4\n\n\n2\n\n\n99\n\n\n1000000102\n\n\n\n\n\n\n5\n\n\n2\n\n\n100\n\n\n61\n\n\n\n\n\n\n6\n\n\n2\n\n\n101\n\n\n6.4"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#join-imdb-title-votes-2",
    "href": "slides/2024-01-10-joins.html#join-imdb-title-votes-2",
    "title": "SQL joins",
    "section": "JOIN IMDb title + votes",
    "text": "JOIN IMDb title + votes\n\ncombine the titles with the number of votes so that each title with user votes is included (INNER JOIN)\n\n\nSELECT title.id,\n       title.title,\n       movie_info_idx.info\nFROM title\nJOIN movie_info_idx ON title.id = movie_info_idx.movie_id \nWHERE title.production_year = 2015 \n    AND title.kind_id = 1                  # movies only\n    AND movie_info_idx.info_type_id = 100  # info_type is votes\n    AND movie_info_idx.info &gt; 150000       # at least 150,000 votes\nORDER BY movie_info_idx.info DESC\nLIMIT 0, 20;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\ntitle\n\n\ninfo\n\n\n\n\n\n\n4260166\n\n\nStar Wars: Episode VII - The Force Awakens\n\n\n691691\n\n\n\n\n3915213\n\n\nMad Max: Fury Road\n\n\n666484\n\n\n\n\n4389619\n\n\nThe Martian\n\n\n583987\n\n\n\n\n3313672\n\n\nAvengers: Age of Ultron\n\n\n540606\n\n\n\n\n4414139\n\n\nThe Revenant\n\n\n526189\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n471237\n\n\n\n\n3752999\n\n\nInside Out\n\n\n443051\n\n\n\n\n3292159\n\n\nAnt-Man\n\n\n390965\n\n\n\n\n4364483\n\n\nThe Hateful Eight\n\n\n363199\n\n\n\n\n4251736\n\n\nSpectre\n\n\n319875\n\n\n\n\n\n\n\nSome aspects of the query are worth pointing out:\n* The variables in the output are given in the SELECT clause. The id and title (both from the title table) and the info from the movie_info_idx which represents the number of IMDb votes. * The variables are preceded by the table from which they came. While not always necessary, it is good practice so as to avoid confusion. * The JOIN happens by linking the id variable in the title table with the movie_id variable in the movie_info_idx table. * The LIMIT wasn’t necessary (there are only 12 observations), but it’s good practice so that we don’t end up with unwieldy query results. * The WHERE clause happens before the JOIN action, despite being written after. * In the WHERE clause, we keep only movies, only 2015 production year, and only at least 150,000 votes."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#join-imdb-title-actress",
    "href": "slides/2024-01-10-joins.html#join-imdb-title-actress",
    "title": "SQL joins",
    "section": "JOIN IMDb title + actress",
    "text": "JOIN IMDb title + actress\ncast_info contains the person_id and the movie_id\n\nSELECT * FROM cast_info LIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\nperson_id\n\n\nmovie_id\n\n\nperson_role_id\n\n\nnote\n\n\nnr_order\n\n\nrole_id\n\n\n\n\n\n\n1\n\n\n1\n\n\n3432997\n\n\n1\n\n\n\n\n31\n\n\n1\n\n\n\n\n2\n\n\n2\n\n\n1901690\n\n\n2\n\n\n\n\n\n\n1\n\n\n\n\n3\n\n\n3\n\n\n4027567\n\n\n2\n\n\n\n\n25\n\n\n1\n\n\n\n\n4\n\n\n3\n\n\n4282876\n\n\n3\n\n\n\n\n22\n\n\n1\n\n\n\n\n5\n\n\n4\n\n\n3542672\n\n\n\n\n\n\n12\n\n\n1\n\n\n\n\n6\n\n\n5\n\n\n3331520\n\n\n4\n\n\n(as $hutter Boy)\n\n\n10\n\n\n1\n\n\n\n\n7\n\n\n5\n\n\n4027191\n\n\n2\n\n\n(as $hutter Boy)\n\n\n1\n\n\n1\n\n\n\n\n8\n\n\n5\n\n\n4195731\n\n\n5\n\n\n(uncredited)\n\n\n\n\n1\n\n\n\n\n9\n\n\n5\n\n\n4263956\n\n\n6\n\n\n(uncredited)\n\n\n\n\n1\n\n\n\n\n10\n\n\n5\n\n\n4267787\n\n\n7\n\n\n(uncredited)\n\n\n\n\n1\n\n\n\n\n\n\n\nperson_role_id is 1 if actor and 2 if actress"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#join-imdb-title-actress-1",
    "href": "slides/2024-01-10-joins.html#join-imdb-title-actress-1",
    "title": "SQL joins",
    "section": "JOIN IMDb title + actress",
    "text": "JOIN IMDb title + actress\naka_name contains person_id and name (of actor)\n\nSELECT * FROM aka_name LIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\nperson_id\n\n\nname\n\n\nimdb_index\n\n\nname_pcode_cf\n\n\nname_pcode_nf\n\n\nsurname_pcode\n\n\nmd5sum\n\n\n\n\n\n\n1\n\n\n6188450\n\n\nSmith, Jessica Noel\n\n\n\n\nS5325\n\n\nJ2542\n\n\nS53\n\n\n25c9d464e3ff2957533546aa92b397ed\n\n\n\n\n2\n\n\n5125059\n\n\nPain, L. $ham\n\n\n\n\nP545\n\n\nL515\n\n\nP5\n\n\n569b1e885ccb51211c01753f0dad9b2c\n\n\n\n\n3\n\n\n5\n\n\nBoy, $hutter\n\n\n\n\nB36\n\n\nH361\n\n\nB\n\n\n35092b5604ce378fc48c8a6fc0038a49\n\n\n\n\n4\n\n\n4152053\n\n\nDollasign, Ty\n\n\n\n\nD4253\n\n\nT3425\n\n\nD425\n\n\n0f565a2d8027cfb8ed6c5f4bba719fcd\n\n\n\n\n5\n\n\n4152053\n\n\nSign, Ty Dolla\n\n\n\n\nS2534\n\n\nT3425\n\n\nS25\n\n\n2eded1b021b96333b4b74e0fec959650\n\n\n\n\n6\n\n\n6\n\n\nMoore, Brandon\n\n\n\n\nM6165\n\n\nB6535\n\n\nM6\n\n\n193a6f5adf4756320f622162d2475608\n\n\n\n\n7\n\n\n8\n\n\n$torm, Country\n\n\n\n\nT6525\n\n\nC5363\n\n\nT65\n\n\n1654400b707d34323ea392b87060e6cc\n\n\n\n\n8\n\n\n19\n\n\n‘Hooper’, Simon P.J. Kelly\n\n\n\n\nH1625\n\n\nS5124\n\n\nH16\n\n\n3fd8885372c23f8c74e583da91d1fd05\n\n\n\n\n9\n\n\n19\n\n\nHooper\n\n\n\n\nH16\n\n\n\n\n\n\n24ddc68ab605ee95857ad45b65ffa2d8\n\n\n\n\n10\n\n\n19\n\n\nKelly, Simon P.J.\n\n\n\n\nK4251\n\n\nS5124\n\n\nK4\n\n\n33d976f22e276b73c61513bc5f6e72a6"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#join-imdb-title-actress-2",
    "href": "slides/2024-01-10-joins.html#join-imdb-title-actress-2",
    "title": "SQL joins",
    "section": "JOIN IMDb title + actress",
    "text": "JOIN IMDb title + actress\ntitle contains id and title (of the movie)\n\nSELECT * FROM title LIMIT 0, 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\ntitle\n\n\nimdb_index\n\n\nkind_id\n\n\nproduction_year\n\n\nimdb_id\n\n\nphonetic_code\n\n\nepisode_of_id\n\n\nseason_nr\n\n\nepisode_nr\n\n\nseries_years\n\n\nmd5sum\n\n\n\n\n\n\n78460\n\n\nAdults Recat to the Simpsons (30th Anniversary)\n\n\n\n\n7\n\n\n2017\n\n\n\n\nA3432\n\n\n78406\n\n\n\n\n\n\n\n\n2ae09eed7d576cc2c24774fed5b18168\n\n\n\n\n70273\n\n\n(2016-05-18)\n\n\n\n\n7\n\n\n2016\n\n\n\n\n\n\n68058\n\n\n\n\n\n\n\n\n511dfc14cfff7589d29a95abb30cd66a\n\n\n\n\n60105\n\n\n(2014-04-11)\n\n\n\n\n7\n\n\n2014\n\n\n\n\n\n\n59138\n\n\n\n\n\n\n\n\nc6cdce7e667e07713e431805c407feed\n\n\n\n\n32120\n\n\n(2008-05-01)\n\n\n\n\n7\n\n\n2008\n\n\n\n\n\n\n32060\n\n\n\n\n\n\n\n\n100df65742caf5afd092b2e0ead67d8e\n\n\n\n\n97554\n\n\nSchmÃ¶lders Traum\n\n\n\n\n7\n\n\n2001\n\n\n\n\nS2543\n\n\n97302\n\n\n10\n\n\n1\n\n\n\n\n46862a2f96f9fb2d59e8c9a11ecfdd28\n\n\n\n\n57966\n\n\n(#1.1)\n\n\n\n\n7\n\n\n2013\n\n\n\n\n\n\n57965\n\n\n1\n\n\n1\n\n\n\n\n409c37703766c4b24f8a86162fd9cf85\n\n\n\n\n76391\n\n\nAnniversary\n\n\n\n\n7\n\n\n1971\n\n\n\n\nA5162\n\n\n76385\n\n\n4\n\n\n9\n\n\n\n\n5e12ce73fac1d1dcf94136b6e9acd8f8\n\n\n\n\n11952\n\n\nAngus Black/Lester Barrie/DC Curry\n\n\n\n\n7\n\n\n2009\n\n\n\n\nA5214\n\n\n11937\n\n\n4\n\n\n7\n\n\n\n\n9c38b9e5601dc154444b73b518034aa1\n\n\n\n\n1554\n\n\nNew Orleans\n\n\n\n\n7\n\n\n2003\n\n\n\n\nN6452\n\n\n1508\n\n\n2\n\n\n11\n\n\n\n\n621bea735740a547e862e4a3226f35d2\n\n\n\n\n58442\n\n\nKiss Me Kate\n\n\n\n\n7\n\n\n2011\n\n\n\n\nK2523\n\n\n58436\n\n\n1\n\n\n10\n\n\n\n\n293e8c75c7f35a4035abf617962be5a9"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#join-imdb-title-actress-3",
    "href": "slides/2024-01-10-joins.html#join-imdb-title-actress-3",
    "title": "SQL joins",
    "section": "JOIN IMDb title + actress",
    "text": "JOIN IMDb title + actress\nGoal: identify the actresses in those movies with the highest number of votes.\n\nSELECT t.title,\n       idx.info,\n       a.person_id,\n       n.name\nFROM title AS t\nJOIN movie_info_idx AS idx ON t.id = idx.movie_id \nJOIN cast_info AS a ON idx.movie_id = a.movie_id\nJOIN aka_name AS n ON a.person_id = n.person_id\nWHERE t.production_year = 2015 \n    AND t.kind_id = 1           # movies only\n    AND idx.info_type_id = 100  # info_type is votes\n    AND idx.info &gt; 150000       # at least 150,000 votes\n    AND a.role_id = 2           # actresses only\nORDER BY a.person_id\nLIMIT 0, 50;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\ntitle\n\n\ninfo\n\n\nperson_id\n\n\nname\n\n\n\n\n\n\nMission: Impossible - Rogue Nation\n\n\n266759\n\n\n2674172\n\n\nSofz\n\n\n\n\nMission: Impossible - Rogue Nation\n\n\n266759\n\n\n2674172\n\n\nSof\n\n\n\n\nMission: Impossible - Rogue Nation\n\n\n266759\n\n\n2674172\n\n\nSofz\n\n\n\n\nMission: Impossible - Rogue Nation\n\n\n266759\n\n\n2674172\n\n\nSof\n\n\n\n\nFocus\n\n\n172680\n\n\n2678594\n\n\nLabouisse, Kate\n\n\n\n\nMad Max: Fury Road\n\n\n666484\n\n\n2681098\n\n\nMichelle, Debra\n\n\n\n\nThe Hunger Games: Mockingjay - Part 2\n\n\n214569\n\n\n2685496\n\n\nHarris, Ahnie\n\n\n\n\nThe Hunger Games: Mockingjay - Part 2\n\n\n214569\n\n\n2685496\n\n\nHarris, Jasmine\n\n\n\n\nCreed\n\n\n183904\n\n\n2686218\n\n\nKareema, Kiana A.\n\n\n\n\nAnt-Man\n\n\n390965\n\n\n2687271\n\n\nAkana, Anna Kay\n\n\n\n\n\n\n\nConnecting the most popular movies of 2015 with the actresses in those movies requires a series of JOINs. Note that to make the code less onerous, the title table has been aliased by t, the movie_info_idx table has been aliased by idx, the cast_info table has been aliased by a, and the aka_name table has been aliased by n.\nThere is a lot of data cleaning to do as some of the person_id values are one to many!! That is, the person_id matches multiple names in the aka_name database."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#other-joins",
    "href": "slides/2024-01-10-joins.html#other-joins",
    "title": "SQL joins",
    "section": "Other JOINs",
    "text": "Other JOINs\nLet’s look at RIGHT JOIN and LEFT JOIN using two new smaller tables.\n\nThe first has seven movies in it (from 2015 with at least 400,000 IMDb votes).\nThe second consists of almost 3 million actresses (person_role_id = 2). In order to find a subset of actresses, the person_id &gt; 3900000 was set arbitrarily (in order to have a smaller group with which to work).\n\nUsing subqueries, we can JOIN the two datasets using different JOIN techniques."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#unioning",
    "href": "slides/2024-01-10-joins.html#unioning",
    "title": "SQL joins",
    "section": "UNIONing",
    "text": "UNIONing\nIn SQL a UNION clause combines two different tables by their rows (whereas JOIN combines two tables by columns). Think about UNION similarly to the bind_rows() command in R.\n\nFigure 3: UNION binds rows while JOIN appends columns, image credit: Jane Williams https://blog.devart.com/mysql-union-tutorial-html.html"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#best-practice",
    "href": "slides/2024-01-10-joins.html#best-practice",
    "title": "SQL joins",
    "section": "Best practice",
    "text": "Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\nDBI::dbDisconnect(con_imdb, shutdown = TRUE)"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#imdb-1",
    "href": "slides/2024-01-10-joins.html#imdb-1",
    "title": "SQL joins",
    "section": "IMDb",
    "text": "IMDb\n21 tables in the imdb database! Lots of details on movies, TV series, video games, and more. Today interest is in movies (and details within, like actors and ratings).\n\nSHOW TABLES;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nTables_in_imdb\n\n\n\n\n\n\naka_name\n\n\n\n\naka_title\n\n\n\n\ncast_info\n\n\n\n\nchar_name\n\n\n\n\ncomp_cast_type\n\n\n\n\ncompany_name\n\n\n\n\ncompany_type\n\n\n\n\ncomplete_cast\n\n\n\n\ninfo_type\n\n\n\n\nkeyword"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#imdb---glance-through-tables",
    "href": "slides/2024-01-10-joins.html#imdb---glance-through-tables",
    "title": "SQL joins",
    "section": "IMDb - glance through tables",
    "text": "IMDb - glance through tables\n\nSELECT * FROM kind_type\nLIMIT 0, 10;\n\n\n\n\n7 records\n\n\n\n\nid\n\n\nkind\n\n\n\n\n\n\n1\n\n\nmovie\n\n\n\n\n2\n\n\ntv series\n\n\n\n\n3\n\n\ntv movie\n\n\n\n\n4\n\n\nvideo movie\n\n\n\n\n5\n\n\ntv mini series\n\n\n\n\n6\n\n\nvideo game\n\n\n\n\n7\n\n\nepisode"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#all-the-joins",
    "href": "slides/2024-01-10-joins.html#all-the-joins",
    "title": "SQL joins",
    "section": "All the JOINs",
    "text": "All the JOINs\n\nJOIN (aka INNER JOIN): include all of the rows that exist in both tables\nLEFT JOIN: include all of the rows in the first table.\n\nRIGHT JOIN: include all of the rows in the second table.\nFULL OUTER JOIN: include all rows in either table. (The functionality doesn’t exist in MySQL but can be created using joins and UNION.)\nCROSS JOIN: match each row of the first table with each row in the second table."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#all-the-joins-1",
    "href": "slides/2024-01-10-joins.html#all-the-joins-1",
    "title": "SQL joins",
    "section": "All the JOINs",
    "text": "All the JOINs\nVenn diagrams of the different types of joins.\n\nFigure 1: Venn diagrams describing different JOINs, image credit: phoenixNAP https://phoenixnap.com/kb/mysql-join"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#all-the-joins-2",
    "href": "slides/2024-01-10-joins.html#all-the-joins-2",
    "title": "SQL joins",
    "section": "All the JOINs",
    "text": "All the JOINs\nMini data tables of the different types of JOIN. (In SQL the missing values will be labeled as NULL (not NA).)\n\nFigure 2: Mini data tables describing different JOINs, image credit: Statistics Globe blog, https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#all-the-joins-3",
    "href": "slides/2024-01-10-joins.html#all-the-joins-3",
    "title": "SQL joins",
    "section": "All the JOINs",
    "text": "All the JOINs\nEach JOIN clause needs four specific pieces of information:\n\nThe name of the first table you want to JOIN.\nThe type of JOIN being used.\nThe name of the second table you want to JOIN.\nThe condition(s) under which you want the records in the first table to match records in the second table."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#a-toy-example",
    "href": "slides/2024-01-10-joins.html#a-toy-example",
    "title": "SQL joins",
    "section": "A toy example",
    "text": "A toy example\nRock bands from the 60s.\n\nband_members\n\n# A tibble: 3 × 2\n  name  band   \n  &lt;chr&gt; &lt;chr&gt;  \n1 Mick  Stones \n2 John  Beatles\n3 Paul  Beatles\n\nband_instruments\n\n# A tibble: 3 × 2\n  name  plays \n  &lt;chr&gt; &lt;chr&gt; \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n\n\nThe function sqldf() in the sqldf R package allows for SQL commands on R objects."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#rock-bands---inner-join",
    "href": "slides/2024-01-10-joins.html#rock-bands---inner-join",
    "title": "SQL joins",
    "section": "Rock bands - INNER JOIN",
    "text": "Rock bands - INNER JOIN\nAn inner join combines two datasets returning only the observations that exist in both of the original datasets.\n\nsqldf::sqldf(\"SELECT star.name,\n                     star.band,\n                     inst.plays\n              FROM band_members AS star\n              JOIN band_instruments AS inst ON star.name = inst.name\")\n\n  name    band  plays\n1 John Beatles guitar\n2 Paul Beatles   bass"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#rock-bands---full-join",
    "href": "slides/2024-01-10-joins.html#rock-bands---full-join",
    "title": "SQL joins",
    "section": "Rock bands - FULL JOIN",
    "text": "Rock bands - FULL JOIN\nA full join combines two datasets returning every observation that exists in either one of the original datasets.\n\nband_members |&gt;\n  full_join(band_instruments)\n\n# A tibble: 4 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 Mick  Stones  &lt;NA&gt;  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n4 Keith &lt;NA&gt;    guitar\n\n\nThe full_join() function does not have an equivalent in MySQL. See notes for using JOINs and UNIONs to produce a full join."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#rock-bands---left-join",
    "href": "slides/2024-01-10-joins.html#rock-bands---left-join",
    "title": "SQL joins",
    "section": "Rock bands - LEFT JOIN",
    "text": "Rock bands - LEFT JOIN\nA left join combines two datasets returning every observation that exists in the left (or first) original dataset.\n\nsqldf::sqldf(\"SELECT star.name,\n                     star.band,\n                      inst.plays\n              FROM band_members AS star\n              LEFT JOIN band_instruments AS inst \n              ON star.name = inst.name\")\n\n  name    band  plays\n1 Mick  Stones   &lt;NA&gt;\n2 John Beatles guitar\n3 Paul Beatles   bass"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#rock-bands---right-join",
    "href": "slides/2024-01-10-joins.html#rock-bands---right-join",
    "title": "SQL joins",
    "section": "Rock bands - RIGHT JOIN",
    "text": "Rock bands - RIGHT JOIN\nA right join combines two datasets returning every observation that exists in the right (or second) original dataset.\n\nsqldf::sqldf(\"SELECT inst.name,\n                     star.band,\n                      inst.plays\n              FROM band_members AS star\n              RIGHT JOIN band_instruments AS inst \n              ON star.name = inst.name\")\n\n   name    band  plays\n1  John Beatles guitar\n2  Paul Beatles   bass\n3 Keith    &lt;NA&gt; guitar"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#rock-bands---cross-join",
    "href": "slides/2024-01-10-joins.html#rock-bands---cross-join",
    "title": "SQL joins",
    "section": "Rock bands - CROSS JOIN",
    "text": "Rock bands - CROSS JOIN\nA right join combines two datasets returning every observation that exists in the right (or second) original dataset.\n\nsqldf::sqldf(\"SELECT *\n              FROM band_members AS star\n              CROSS JOIN band_instruments AS inst\")\n\n  name    band  name  plays\n1 Mick  Stones  John guitar\n2 Mick  Stones  Paul   bass\n3 Mick  Stones Keith guitar\n4 John Beatles  John guitar\n5 John Beatles  Paul   bass\n6 John Beatles Keith guitar\n7 Paul Beatles  John guitar\n8 Paul Beatles  Paul   bass\n9 Paul Beatles Keith guitar"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#movies",
    "href": "slides/2024-01-10-joins.html#movies",
    "title": "SQL joins",
    "section": "movies:",
    "text": "movies:\n\nSELECT t.id,\n       t.title,\n       idx.info,\n       (SELECT COUNT(*)\n       FROM title AS t\n       JOIN movie_info_idx AS idx ON idx.movie_id = t.id\n       WHERE t.production_year = 2015  \n             AND t.kind_id = 1\n             AND idx.info_type_id = 100\n             AND idx.info &gt; 400000) AS row_count\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1             # movies only\n    AND idx.info_type_id = 100    # info_type is votes\n    AND idx.info &gt; 400000         # at least 400,000 votes\nORDER BY idx.info DESC;\n\n\n\n\n7 records\n\n\n\n\nid\n\n\ntitle\n\n\ninfo\n\n\nrow_count\n\n\n\n\n\n\n4260166\n\n\nStar Wars: Episode VII - The Force Awakens\n\n\n691691\n\n\n7\n\n\n\n\n3915213\n\n\nMad Max: Fury Road\n\n\n666484\n\n\n7\n\n\n\n\n4389619\n\n\nThe Martian\n\n\n583987\n\n\n7\n\n\n\n\n3313672\n\n\nAvengers: Age of Ultron\n\n\n540606\n\n\n7\n\n\n\n\n4414139\n\n\nThe Revenant\n\n\n526189\n\n\n7\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n471237\n\n\n7\n\n\n\n\n3752999\n\n\nInside Out\n\n\n443051\n\n\n7"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#actresses",
    "href": "slides/2024-01-10-joins.html#actresses",
    "title": "SQL joins",
    "section": "actresses:",
    "text": "actresses:\n\n\nSELECT a.person_id,\n       a.movie_id,\n       n.name,\n       (SELECT COUNT(*)\n       FROM cast_info AS a\n       JOIN aka_name AS n ON a.person_id = n.person_id\n       WHERE a.person_role_id = 2  \n             AND a.person_id &gt; 390000) AS row_count\nFROM cast_info AS a\nJOIN aka_name AS n ON a.person_id = n.person_id\n       WHERE a.person_role_id = 2  \n             AND a.person_id &gt; 3900000\nLIMIT 0, 20;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nperson_id\n\n\nmovie_id\n\n\nname\n\n\nrow_count\n\n\n\n\n\n\n3900141\n\n\n759802\n\n\nSimons, Rita Joanne\n\n\n2904759\n\n\n\n\n3902258\n\n\n4365829\n\n\nSinger, Rabbi Tovia\n\n\n2904759\n\n\n\n\n3902699\n\n\n3109788\n\n\nSingh, Sabine Erika\n\n\n2904759\n\n\n\n\n3903035\n\n\n3215866\n\n\nVal\n\n\n2904759\n\n\n\n\n3904831\n\n\n2468067\n\n\nMasha\n\n\n2904759\n\n\n\n\n3904928\n\n\n3654347\n\n\nFei, Siu Yin\n\n\n2904759\n\n\n\n\n3904928\n\n\n3654347\n\n\nHsiao, Yen-fei\n\n\n2904759\n\n\n\n\n3904928\n\n\n3654347\n\n\nSiu, Yinfei\n\n\n2904759\n\n\n\n\n3904928\n\n\n3654347\n\n\nXiao, Yanfei\n\n\n2904759\n\n\n\n\n3904928\n\n\n3654347\n\n\nYin-Fai, Siu\n\n\n2904759"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#inner-join",
    "href": "slides/2024-01-10-joins.html#inner-join",
    "title": "SQL joins",
    "section": "Inner JOIN",
    "text": "Inner JOIN\nWith an inner JOIN, there are 32 rows corresponding to all the actresses in the seven 2015 films with the most votes. Because the JOIN is an intersection of the two tables, only the actresses with person_id above 3900000 are included.\n\nSELECT * FROM\n(SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes     \nINNER JOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nLIMIT 0, 300;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\ntitle\n\n\nperson_id\n\n\nmovie_id\n\n\nname\n\n\n\n\n\n\n3313672\n\n\nAvengers: Age of Ultron\n\n\n3916648\n\n\n3313672\n\n\nSmulders, Jacoba Francisca Maria\n\n\n\n\n3752999\n\n\nInside Out\n\n\n4122876\n\n\n3752999\n\n\nKuzniar, Lennon Wynn\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n3938423\n\n\n3787790\n\n\nNorvell, Ingrid\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n3938423\n\n\n3787790\n\n\nNorvell, Ingrid\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n3950111\n\n\n3787790\n\n\nSallaway, Seannon Jane\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4079047\n\n\n3787790\n\n\nWashington, Kelly Lynn\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4079047\n\n\n3787790\n\n\nWashington, Kelly Lynn\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4084626\n\n\n3787790\n\n\nWeeks, Jency\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4084626\n\n\n3787790\n\n\nJenc\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4084626\n\n\n3787790\n\n\nLittle J"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#right-join",
    "href": "slides/2024-01-10-joins.html#right-join",
    "title": "SQL joins",
    "section": "RIGHT JOIN",
    "text": "RIGHT JOIN\nWith a RIGHT JOIN, there are more than 300 rows (the LIMIT clause keeps us from knowing how many rows, but there are a LOT!) corresponding to all the actresses whose person_id above 3900000 are included. Those actresses who acted in one of the seven top 2015 films are also included in the full results table, but they don’t happen to be in the truncated output here.\n\nSELECT * FROM\n(SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes     \nRIGHT JOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nLIMIT 0, 300;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\ntitle\n\n\nperson_id\n\n\nmovie_id\n\n\nname\n\n\n\n\n\n\n\n\n\n\n3900001\n\n\n3355298\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n3509490\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n3739780\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n3943329\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n165963\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n268249\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n268370\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n268406\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n268475\n\n\nSimonis, Heidi\n\n\n\n\n\n\n\n\n3900001\n\n\n279082\n\n\nSimonis, Heidi"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#left-join",
    "href": "slides/2024-01-10-joins.html#left-join",
    "title": "SQL joins",
    "section": "LEFT JOIN",
    "text": "LEFT JOIN\nWith a LEFT JOIN, there are 33 rows corresponding to the actresses in the seven top 2015 movies. Only The Revenant did not have any actresses whose person_id is greater than 3900000.\n\nSELECT * FROM\n(SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes     \nLEFT JOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nLIMIT 0, 300;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nid\n\n\ntitle\n\n\nperson_id\n\n\nmovie_id\n\n\nname\n\n\n\n\n\n\n3313672\n\n\nAvengers: Age of Ultron\n\n\n3916648\n\n\n3313672\n\n\nSmulders, Jacoba Francisca Maria\n\n\n\n\n3752999\n\n\nInside Out\n\n\n4122876\n\n\n3752999\n\n\nKuzniar, Lennon Wynn\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n3938423\n\n\n3787790\n\n\nNorvell, Ingrid\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n3938423\n\n\n3787790\n\n\nNorvell, Ingrid\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n3950111\n\n\n3787790\n\n\nSallaway, Seannon Jane\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4079047\n\n\n3787790\n\n\nWashington, Kelly Lynn\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4079047\n\n\n3787790\n\n\nWashington, Kelly Lynn\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4084626\n\n\n3787790\n\n\nWeeks, Jency\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4084626\n\n\n3787790\n\n\nJenc\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n4084626\n\n\n3787790\n\n\nLittle J"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#counting-repeat-actresses",
    "href": "slides/2024-01-10-joins.html#counting-repeat-actresses",
    "title": "SQL joins",
    "section": "Counting repeat actresses",
    "text": "Counting repeat actresses\nWe might, for example, want to know how many names / spellings of a name with a specific person_id (above 3900000) exist for each person_id in each of the top voted seven films of 2015.\n\nSELECT acts.person_id, \n       COUNT(*) AS num_repeat_names\nFROM (SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes\nJOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nGROUP BY acts.person_id;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nperson_id\n\n\nnum_repeat_names\n\n\n\n\n\n\n3916648\n\n\n1\n\n\n\n\n4122876\n\n\n1\n\n\n\n\n3938423\n\n\n2\n\n\n\n\n3950111\n\n\n1\n\n\n\n\n4079047\n\n\n2\n\n\n\n\n4084626\n\n\n3\n\n\n\n\n4099458\n\n\n1\n\n\n\n\n3958614\n\n\n1\n\n\n\n\n3990819\n\n\n2\n\n\n\n\n4081131\n\n\n2"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#counting-number-of-actresses-per-film",
    "href": "slides/2024-01-10-joins.html#counting-number-of-actresses-per-film",
    "title": "SQL joins",
    "section": "Counting number of actresses per film",
    "text": "Counting number of actresses per film\nWe might, for example, want to know how many actresses with a specific person_id (above 3900000) are in each of the top voted seven films of 2015.\n\nSELECT movs.id, \n       movs.title,\n       COUNT(*) AS num_actress\nFROM (SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes\nJOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nGROUP BY movs.id;\n\n\n\n\n6 records\n\n\n\n\nid\n\n\ntitle\n\n\nnum_actress\n\n\n\n\n\n\n3313672\n\n\nAvengers: Age of Ultron\n\n\n1\n\n\n\n\n3752999\n\n\nInside Out\n\n\n1\n\n\n\n\n3787790\n\n\nJurassic World\n\n\n9\n\n\n\n\n3915213\n\n\nMad Max: Fury Road\n\n\n5\n\n\n\n\n4260166\n\n\nStar Wars: Episode VII - The Force Awakens\n\n\n15\n\n\n\n\n4389619\n\n\nThe Martian\n\n\n1"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#unions",
    "href": "slides/2024-01-10-joins.html#unions",
    "title": "SQL joins",
    "section": "UNIONs",
    "text": "UNIONs\nSilly example where the column names are ignored.\n\nSELECT \n    1 AS bar,\n    2 AS foo\n\nUNION\n\nSELECT \n    10 AS foo,\n    20 AS bar;\n\n\n\n\n2 records\n\n\n\n\nbar\n\n\nfoo\n\n\n\n\n\n\n1\n\n\n2\n\n\n\n\n10\n\n\n20"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#union",
    "href": "slides/2024-01-10-joins.html#union",
    "title": "SQL joins",
    "section": "UNION",
    "text": "UNION\nUNION is specifically designed to bind rows from two different SELECT queries where the variables have been selected in the same order.\nCombine the top voted movies from 2015 with the top voted movies from 2019.\nHowever, to account for time, we require the movies from 2015 to have more votes (400,000) than the movies from 2017 (200,000).\nThat is, the WHERE clause is different for the two subqueries."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#union-1",
    "href": "slides/2024-01-10-joins.html#union-1",
    "title": "SQL joins",
    "section": "UNION",
    "text": "UNION\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 400000)\n\nUNION\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2017  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 200000)\nLIMIT 0, 100;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\ntitle\n\n\nproduction_year\n\n\nnum_votes\n\n\n\n\n\n\nAvengers: Age of Ultron\n\n\n2015\n\n\n540606\n\n\n\n\nInside Out\n\n\n2015\n\n\n443051\n\n\n\n\nJurassic World\n\n\n2015\n\n\n471237\n\n\n\n\nMad Max: Fury Road\n\n\n2015\n\n\n666484\n\n\n\n\nStar Wars: Episode VII - The Force Awakens\n\n\n2015\n\n\n691691\n\n\n\n\nThe Martian\n\n\n2015\n\n\n583987\n\n\n\n\nThe Revenant\n\n\n2015\n\n\n526189\n\n\n\n\nDunkirk\n\n\n2017\n\n\n229089\n\n\n\n\nGuardians of the Galaxy Vol. 2\n\n\n2017\n\n\n281845\n\n\n\n\nLogan\n\n\n2017\n\n\n397056"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#union-all",
    "href": "slides/2024-01-10-joins.html#union-all",
    "title": "SQL joins",
    "section": "UNION ALL",
    "text": "UNION ALL\nIf the goal is to include duplicates across two tables, use UNION ALL instead of UNION.\nLet’s say that the first table is all movies with production year after 2012 and number of votes greater than 500,000. The second table is movies with production year equal to 2015 and number of votes greater than 400,000.\nThe Martian would be in both tables."
  },
  {
    "objectID": "slides/2024-01-10-joins.html#union-all-1",
    "href": "slides/2024-01-10-joins.html#union-all-1",
    "title": "SQL joins",
    "section": "UNION ALL",
    "text": "UNION ALL\nWith just UNION\n\n(SELECT t.title,\n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year &gt; 2012  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 500000)\n\nUNION\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 400000)\nORDER BY production_year DESC, num_votes;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\ntitle\n\n\nproduction_year\n\n\nnum_votes\n\n\n\n\n\n\nBatman v Superman: Dawn of Justice\n\n\n2016\n\n\n500037\n\n\n\n\nDeadpool\n\n\n2016\n\n\n673887\n\n\n\n\nInside Out\n\n\n2015\n\n\n443051\n\n\n\n\nJurassic World\n\n\n2015\n\n\n471237\n\n\n\n\nThe Revenant\n\n\n2015\n\n\n526189\n\n\n\n\nAvengers: Age of Ultron\n\n\n2015\n\n\n540606\n\n\n\n\nThe Martian\n\n\n2015\n\n\n583987\n\n\n\n\nMad Max: Fury Road\n\n\n2015\n\n\n666484\n\n\n\n\nStar Wars: Episode VII - The Force Awakens\n\n\n2015\n\n\n691691\n\n\n\n\nInterstellar\n\n\n2014\n\n\n1102826"
  },
  {
    "objectID": "slides/2024-01-10-joins.html#union-all-2",
    "href": "slides/2024-01-10-joins.html#union-all-2",
    "title": "SQL joins",
    "section": "UNION ALL",
    "text": "UNION ALL\nWhen UNION ALL is applied, The Martian is listed twice in the results table.\n\n(SELECT t.title,\n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year &gt; 2012  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 500000)\n\nUNION ALL\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 400000)\nORDER BY production_year DESC, num_votes;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\ntitle\n\n\nproduction_year\n\n\nnum_votes\n\n\n\n\n\n\nBatman v Superman: Dawn of Justice\n\n\n2016\n\n\n500037\n\n\n\n\nDeadpool\n\n\n2016\n\n\n673887\n\n\n\n\nInside Out\n\n\n2015\n\n\n443051\n\n\n\n\nJurassic World\n\n\n2015\n\n\n471237\n\n\n\n\nThe Revenant\n\n\n2015\n\n\n526189\n\n\n\n\nThe Revenant\n\n\n2015\n\n\n526189\n\n\n\n\nAvengers: Age of Ultron\n\n\n2015\n\n\n540606\n\n\n\n\nAvengers: Age of Ultron\n\n\n2015\n\n\n540606\n\n\n\n\nThe Martian\n\n\n2015\n\n\n583987\n\n\n\n\nThe Martian\n\n\n2015\n\n\n583987"
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab3_joins_sds261_j24.html#advice-for-turning-in-the-assignment",
    "title": "Lab 3 - SQL joins",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .sql file) which problem is being answered with which SQL code. Use the following syntax to comment within a .sql file: /* here is where comments go */. Indeed, feel free to copy the question into the .sql file so that you have it for your own records.\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe SQL document should be saved in the R Project as lab3-sds261-yourlastname-yourfirstname.sql. You will have to navigate to the R Project to save the DBeaver file in the correct place.\nConnect to the yelp database, which contains the businesses, reviews, and users tables. See README file for connection details.\n\n\nSHOW TABLES;\n\n\n3 records\n\n\nTables_in_yelp\n\n\n\n\nbusinesses\n\n\nreviews\n\n\nusers"
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24.html#assignment",
    "href": "handout/lab3_joins_sds261_j24.html#assignment",
    "title": "Lab 3 - SQL joins",
    "section": "Assignment",
    "text": "Assignment\n\nFor each of the three tables in the yelp database, identify the number of records and the variables. (That means, write at least a sentence for each table.)\n\n\nFind the user with the most reviews. What is the person’s name, and how many reviews did they make?\n\n\nWhat cities are represented in the businesses table? Find out by querying the number of businesses per city. Use LIMIT to start, just in case there are hundreds of cities. Write down a few of the city names. Do you notice anything interesting?\n\n\nFind the businesses in “Carefree” (a city in Arizona). Write down the names of a few of the businesses.\n\n\nCount the number of records resulting when the query connects the users with the reviews using a JOIN. How many records are there? What does that tell you about the two tables?\n\n\nHow many users wrote reviews in the reviews table but do not exist in the users table. Hint: use a RIGHT JOIN to keep all the reviews, and then look for the rows where the user_id from the users table IS NULL.\n\n\nWrite a query to ask a question that you think is interesting and uses at least one join. Provide both the question (in words) as well as the SQL code and results."
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#proper-times-and-dates",
    "href": "slides/2024-01-11-regex1.html#proper-times-and-dates",
    "title": "Regular Expressions I",
    "section": "Proper times and dates",
    "text": "Proper times and dates\n\nMatch dates like 01/15/24 and also like 01.15.24 and like 01-15-24.\n\n\nstring &lt;- c(\"01/15/24\", \"01.15.24\", \"01-15-24\", \"011524\", \n            \"January 15, 2024\")"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#proper-times-and-dates-1",
    "href": "slides/2024-01-11-regex1.html#proper-times-and-dates-1",
    "title": "Regular Expressions I",
    "section": "Proper times and dates",
    "text": "Proper times and dates\n\nMatch dates like 01/15/24 and also like 01.15.24 and like 01-15-24.\n\n\nstring &lt;- c(\"01/15/24\", \"01.15.24\", \"01-15-24\", \"01 15 24\", \n            \"011524\", \"January 15, 2024\")\n\nstr_extract(string, \"\\\\d\\\\d.\\\\d\\\\d.\\\\d\\\\d\")\n\n[1] \"01/15/24\" \"01.15.24\" \"01-15-24\" \"01 15 24\" NA         NA        \n\nstr_extract(string, \"\\\\d\\\\d[/.\\\\-]\\\\d\\\\d[/.\\\\-]\\\\d\\\\d\")\n\n[1] \"01/15/24\" \"01.15.24\" \"01-15-24\" NA         NA         NA        \n\nstr_extract(string, \"\\\\d{2}[/.\\\\-]\\\\d{2}[/.\\\\-]\\\\d{2}\")\n\n[1] \"01/15/24\" \"01.15.24\" \"01-15-24\" NA         NA         NA"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#proper-times-and-dates-2",
    "href": "slides/2024-01-11-regex1.html#proper-times-and-dates-2",
    "title": "Regular Expressions I",
    "section": "Proper times and dates",
    "text": "Proper times and dates\n\nMatch a time of day such as “9:17 am” or “12:30 pm”. Require that the time be a valid time (not “99:99 pm”). Assume no leading zeros (i.e., “09:17 am”).\n\n\nstring &lt;- c(\"9:17 am\", \"12:30 pm\", \"99:99 pm\", \"09:17 am\")"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#proper-times-and-dates-3",
    "href": "slides/2024-01-11-regex1.html#proper-times-and-dates-3",
    "title": "Regular Expressions I",
    "section": "Proper times and dates",
    "text": "Proper times and dates\n\nMatch a time of day such as “9:17 am” or “12:30 pm”. Require that the time be a valid time (not “99:99 pm”). Assume no leading zeros (i.e., “09:17 am”).\n\n^(1[012]|[1-9]):[0-5][0-9] (am|pm)$\n\nstring &lt;- c(\"9:17 am\", \"12:30 pm\", \"99:99 pm\", \"09:17 am\")\n\nstr_extract(string, \"(1[012]|[1-9]):[0-5][0-9] (am|pm)\")\n\n[1] \"9:17 am\"  \"12:30 pm\" NA         \"9:17 am\" \n\nstr_extract(string, \"^(1[012]|[1-9]):[0-5][0-9] (am|pm)$\")\n\n[1] \"9:17 am\"  \"12:30 pm\" NA         NA"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#alternation-operator",
    "href": "slides/2024-01-11-regex1.html#alternation-operator",
    "title": "Regular Expressions I",
    "section": "Alternation operator",
    "text": "Alternation operator\nThe “or” operator, | has the lowest precedence and parentheses have the highest precedence, which means that parentheses get evaluated before “or”.\n\nWhat is the difference between \\bMary|Jane|Sue\\b and \\b(Mary|Jane|Sue)\\b?\n\n\nstring &lt;- c(\"Mary\", \"Mar\", \"Janet\", \"jane\", \"Susan\", \"Sue\")\n\nstr_extract(string, \"\\\\bMary|Jane|Sue\\\\b\")\nstr_extract(string, \"\\\\b(Mary|Jane|Sue)\\\\b\")"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#alternation-operator-1",
    "href": "slides/2024-01-11-regex1.html#alternation-operator-1",
    "title": "Regular Expressions I",
    "section": "Alternation operator",
    "text": "Alternation operator\nThe “or” operator, | has the lowest precedence and parentheses have the highest precedence, which means that parentheses get evaluated before “or”.\n\nWhat is the difference between \\bMary|Jane|Sue\\b and \\b(Mary|Jane|Sue)\\b?\n\n\nstring &lt;- c(\"Mary\", \"Mar\", \"Janet\", \"jane\", \"Susan\", \"Sue\")\n\nstr_extract(string, \"\\\\bMary|Jane|Sue\\\\b\")\n\n[1] \"Mary\" NA     \"Jane\" NA     NA     \"Sue\" \n\nstr_extract(string, \"\\\\b(Mary|Jane|Sue)\\\\b\")\n\n[1] \"Mary\" NA     NA     NA     NA     \"Sue\""
  },
  {
    "objectID": "handout/lab4_regex_sds261_j24.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab4_regex_sds261_j24.html#advice-for-turning-in-the-assignment",
    "title": "Lab 4 - regular expressions",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .qmd file) which problem is being answered with which code. A sentence or two with each response goes a long way toward your understanding!\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe .qmd document should be saved in the R Project as lab4-sds261-yourlastname-yourfirstname.qmd.\n\n\nExample: Let’s say that I want to test whether the string contains a US zip code (of the format: xxxxx or xxxxx-xxxx). I might want to test it against a particular string.\n\nstring_zip &lt;- c(\"01063-6302\", \"91711\", \"6302\", \"01063\", \"zip 01063\")\n\nI would use the str_extract() function (in the stringr package) to test whether my regular expression is correct.\n\nstr_extract(string_zip, \"^\\\\d{5}(-\\\\d{4})?$\")\n\n[1] \"01063-6302\" \"91711\"      NA           \"01063\"      NA          \n\n\nDepending on how strict I was being, I might have kept the last one by leaving out the starting and ending positioning.\n\nstr_extract(string_zip, \"\\\\d{5}(-\\\\d{4})?\")\n\n[1] \"01063-6302\" \"91711\"      NA           \"01063\"      \"01063\"     \n\n\nNote that in R, \\d needs to be escaped to \\\\d. That’s true with any metacharacter which uses a backslash."
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab3_joins_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "title": "Lab 3 - SQL joins",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .sql file) which problem is being answered with which SQL code. Use the following syntax to comment within a .sql file: /* here is where comments go */. Indeed, feel free to copy the question into the .sql file so that you have it for your own records.\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe SQL document should be saved in the R Project as lab3-sds261-yourlastname-yourfirstname.sql. You will have to navigate to the R Project to save the DBeaver file in the correct place.\nConnect to the yelp database, which contains the businesses, reviews, and users tables. See README file for connection details.\n\n\nSHOW TABLES;\n\n\n3 records\n\n\nTables_in_yelp\n\n\n\n\nbusinesses\n\n\nreviews\n\n\nusers"
  },
  {
    "objectID": "handout/lab3_joins_sds261_j24_sol.html#assignment",
    "href": "handout/lab3_joins_sds261_j24_sol.html#assignment",
    "title": "Lab 3 - SQL joins",
    "section": "Assignment",
    "text": "Assignment\n\nFor each of the three tables in the yelp database, identify the number of records and the variables. (That means, write at least a sentence for each table.)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM businesses LIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\nid\nname\nstars\nopen\nreview_count\ncity\nlongitude\nlatitude\n\n\n\n\nrncjoVoEFUJGCUoC1JgnUA\nPeoria Income Tax Service\n5\nTRUE\n3\nPeoria\n-112.2416\n33.58187\n\n\n0FNFSzCFP_rGUoJx8W7tJg\nBike Doctor\n5\nTRUE\n5\nPhoenix\n-112.1059\n33.60405\n\n\n3f_lyB6vFK48ukH6ScvLHg\nValley Permaculture Alliance\n5\nTRUE\n4\nPhoenix\n-112.0739\n33.46053\n\n\nusAsSV36QmUej8–yvN-dg\nFood City\n4\nTRUE\n5\nPhoenix\n-112.0854\n33.39221\n\n\nPzOqRohWw7F7YEPBz6AubA\nHot Bagels & Deli\n4\nTRUE\n14\nGlendale Az\n-112.2003\n33.71280\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM reviews LIMIT 0, 5;\n\n\n5 records\n\n\nbusiness_id\nuser_id\nstars\n\n\n\n\n9yKzy9PApeiPPOUJEtnvkg\nrLtl8ZkDX5vH5nAx9C3q5Q\n5\n\n\nZRJwVLyzEJq1VAihDhYiow\n0a2KyEL0d3Yb1V6aivbIuQ\n5\n\n\n6oRAC4uyJCsJl1X0WZpVSA\n0hT2KtfLiobPvh6cDC8JQg\n4\n\n\n_1QQZuf4zZOyFCvXc0o6Vg\nuZetl9T0NcROGOyFfughhg\n5\n\n\n6ozycU1RpktNG2-1BroVtw\nvYmM4KTsC8ZfQBg-j5MWkw\n5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM users LIMIT 0, 5;\n\n\n5 records\n\n\nuser_id\nname\naverage_stars\nreview_count\n\n\n\n\nCR2y7yEm4X035ZMzrTtN9Q\nJim\n5\n6\n\n\n_9GXoHhdxc30ujPaQwh6Ew\nKelle\n1\n2\n\n\n8mM-nqxjg6pT04kwcjMbsw\nStephanie\n5\n2\n\n\nCh6CdTR2IVaVANr-RglMOg\nT\n5\n2\n\n\nNZrLmHRyiHmyT1JrfzkCOA\nBeth\n1\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) FROM businesses;\n\n\n1 records\n\n\nCOUNT(*)\n\n\n\n\n11537\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) FROM reviews;\n\n\n1 records\n\n\nCOUNT(*)\n\n\n\n\n229907\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) FROM users;\n\n\n1 records\n\n\nCOUNT(*)\n\n\n\n\n43873\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbusinesses: 11,537 records with variables of id, name, stars, open, review_count, city, longitude, latitude\nreviews: 229,907 records with variables of business_id, user_id, stars\nusers: 43,873 records with variables of user_id, name, average_stars, review_count\n\n\n\n\n\nFind the user with the most reviews. What is the person’s name, and how many reviews did they make?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT user_id, name, average_stars, review_count\nFROM users\nORDER BY review_count DESC\nLIMIT 0, 5;\n\n\n5 records\n\n\nuser_id\nname\naverage_stars\nreview_count\n\n\n\n\nAIVQg9enGug5woxehjmlGg\nKim\n3.77\n5807\n\n\n6HBnx7fTfFlpWyez_P55xA\nKaren\n3.63\n2848\n\n\n7FuLnS_-b79GG-33mwLaMg\nAndrew\n3.64\n2810\n\n\nlxZSVeJz6KEBW1nlA3JKJg\nShiho\n3.84\n2760\n\n\nqbfQRHLvZk5WSkKY0l_lMw\nStephy\n3.87\n2587\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nKim has the most reviews (5,807 reviews!) with an average rating of 3.77 stars.\n\n\n\n\n\nWhat cities are represented in the businesses table? Find out by querying the number of businesses per city. Use LIMIT to start, just in case there are hundreds of cities. Write down a few of the city names. Do you notice anything interesting?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*), city\nFROM businesses\nGROUP BY city\nORDER BY city\nLIMIT 0, 100;\n\n\nDisplaying records 1 - 10\n\n\nCOUNT(*)\ncity\n\n\n\n\n4\nAhwatukee\n\n\n34\nAnthem\n\n\n46\nApache Junction\n\n\n129\nAvondale\n\n\n31\nBuckeye\n\n\n20\nCarefree\n\n\n48\nCasa Grande\n\n\n65\nCave Creek\n\n\n865\nChandler\n\n\n1\nCharleston\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere appear to be cities in Phoenix as well as in Pheonix (??). And a few of the city names include the AZ to indicate that they are in Arizona. Before really working with the data, we would want to clean up the city names.\n\n\n\n\n\nFind the businesses in “Carefree” (a city in Arizona). Write down the names of a few of the businesses.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT id, name, stars, open, review_count, city\nFROM businesses\nWHERE city = \"Carefree\"\nLIMIT 0, 50;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\nid\nname\nstars\nopen\nreview_count\ncity\n\n\n\n\nK0v87iFgB3sXSzw6e-BJ5w\nAZ Wine Company\n5\nTRUE\n8\nCarefree\n\n\nnZ0mUQEdez-CHrykD2nNLA\nCarefree Resort & Conference Center\n3\nTRUE\n30\nCarefree\n\n\nc4FLMLP7hMnAbSiW2o_o3A\nSaguaro Grille\n3\nFALSE\n5\nCarefree\n\n\nQygMZmPO8A6OaJYO2a0pnw\nStudio C Hair Salon\n5\nTRUE\n3\nCarefree\n\n\nZ85BGr-jnEWvoI4xAnoh3g\nLowe’s Home Improvement Warehouse of Phoenix\n4\nTRUE\n6\nCarefree\n\n\nSahvCnFp3OvUVZIAYCyckw\n34 Easy St\n4\nFALSE\n3\nCarefree\n\n\njdStuaC_1leN_DNGcQ0yEw\nLatilla\n5\nFALSE\n5\nCarefree\n\n\nAwUMl0PT3mdkPS7huzEUYQ\nBalloon Festival\n1\nTRUE\n4\nCarefree\n\n\nMHPXDXVE_cUYodfPhkadeQ\nBlack Mountain Coffee Shop\n4\nTRUE\n11\nCarefree\n\n\nOvlAlAkiyyCILkq-TylBWg\nThe Sundial Cafe\n3\nTRUE\n7\nCarefree\n\n\n\n\n\n\n\n\n\nCount the number of records resulting when the query connects the users with the reviews using a JOIN. How many records are there? What does that tell you about the two tables?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*)\nFROM users\nJOIN reviews ON users.user_id = reviews.user_id\nLIMIT 0, 100;\n\n\n1 records\n\n\nCOUNT(*)\n\n\n\n\n215879\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nBecause there are fewer records in the join, we know that some reviews were done by users that are not in the users table.\n\n\n\n\n\nHow many users wrote reviews in the reviews table but do not exist in the users table. Hint: use a RIGHT JOIN to keep all the reviews, and then look for the rows where the user_id from the users table IS NULL.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(DISTINCT reviews.user_id)\nFROM users\nRIGHT JOIN reviews ON users.user_id = reviews.user_id\nWHERE users.user_id IS NULL;\n\n\n1 records\n\n\nCOUNT(DISTINCT reviews.user_id)\n\n\n\n\n2108\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere are 2,108 users who wrote 14,028 reviews and who are not in the users table.\n\n\n\n\n\nWrite a query to ask a question that you think is interesting and uses at least one join. Provide both the question (in words) as well as the SQL code and results."
  },
  {
    "objectID": "handout/lab4_regex_sds261_j24.html#assignment",
    "href": "handout/lab4_regex_sds261_j24.html#assignment",
    "title": "Lab 4 - regular expressions",
    "section": "Assignment",
    "text": "Assignment\n\nGo through the lessons in https://regexone.com/. Nothing to turn in.\nCatch all of the instances of the words color or colour, case insensitive. Test on the given string.\n\n\nstring &lt;- c(\"color\", \"colour\", \"Color\", \"Colour\", \"Colr\", \"cols\")\n\n\n\nMatch any number (including zero) of o’s, as in: ggle, gogle, google, gooogle, …\nMatch at least one o, as in: gogle, google, gooogle, …\n\n\nTest on the given string.\n\nstring &lt;- c(\"ggle\", \"gogle\", \"google\", \"gooogle\", \"goooogle\", \"gooooogle\")\n\n\nValidate dates which are in the format mm/dd/yy or mm/dd/yyyy. Allow for any digits for the values (e.g., month could be 47). As an extra challenge, try to make the numerical values realistic (e.g., months only between 01 and 12). Test on the given string.\n\n\nstring_date &lt;- c(\"01/11/2024\", \"1/11/2024\", \"1/1/24\", \"01/11/24\", \"24/01/4700\" )\n\n\nCheck a command line response so that true, t, yes, y, okay, ok, and 1 are all accepted in any combination of uppercase and lowercase. Test on the given string.\n\n\nstr_affirm &lt;- c(\"true\", \"t\", \"yes\", \"y\", \"okay\", \"ok\", \"1\", \"tRUe\", \"TRUE\", \"T\",\n               \"YES!\", \"yeS\", \"okay...\", \"sure\", \"maybe\")\n\n\nMatch numbers that use the comma as the thousands separator and the dot as the decimal separator. Test on the given string.\n\n\nstring_number &lt;- c(\"12345\", \"12,345\", \"123.45\", \"1,234,567.890\", \"12,345.\")\n\n\nDetermine whether a user entered a North American phone number in a common format, including the local area code. Common formats include 1234567890, 123-456-7890, 123.456.7890, 123 456 7890, (123) 456 7890, and all related combinations. Test on the given string.\n\n\nstring_phone &lt;- c(\"1234567890\", \"1234\", \"456-7890\", \"123-456-7890\", \"123.456.7890\", \"123 456 7890\", \"(123) 456 7890\", \"+1 (123) 456 789\")\n\n\nFind all words that occur inside an html emphasis tag (&lt;em&gt; and &lt;/em&gt;). Test on the given string. (After Friday’s class.)\n\n\nstring_emph &lt;- c(\"&lt;p&gt;&lt;strong&gt;Pellentesque habitant morbi tristique&lt;/strong&gt; senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. &lt;em&gt;Aenean ultricies mi vitae est.&lt;/em&gt; Mauris placerat eleifend leo. Quisque sit amet est et sapien ullamcorper pharetra. Vestibulum erat wisi, condimentum sed, &lt;code&gt;commodo vitae&lt;/code&gt;, ornare sit amet, wisi. Aenean fermentum, elit eget tincidunt condimentum, eros ipsum rutrum orci, sagittis tempus lacus enim ac dui. &lt;a href='#'&gt;Donec non enim&lt;/a&gt; in turpis pulvinar facilisis. Ut felis.&lt;/p&gt;\")"
  },
  {
    "objectID": "handout/lab4_regex_sds261_j24_sol.html",
    "href": "handout/lab4_regex_sds261_j24_sol.html",
    "title": "Lab 4 - regular expressions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(stringr)\nToday’s lab will provide practice working with regular expressions in R.\nThe goals for lab 4 include:"
  },
  {
    "objectID": "handout/lab4_regex_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab4_regex_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "title": "Lab 4 - regular expressions",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .qmd file) which problem is being answered with which code. A sentence or two with each response goes a long way toward your understanding!\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe .qmd document should be saved in the R Project as lab4-sds261-yourlastname-yourfirstname.qmd.\n\n\nExample: Let’s say that I want to test whether the string contains a US zip code (of the format: xxxxx or xxxxx-xxxx). I might want to test it against a particular string.\n\nstring_zip &lt;- c(\"01063-6302\", \"91711\", \"6302\", \"01063\", \"zip 01063\")\n\nI would use the str_extract() function (in the stringr package) to test whether my regular expression is correct.\n\nstr_extract(string_zip, \"^\\\\d{5}(-\\\\d{4})?$\")\n\n[1] \"01063-6302\" \"91711\"      NA           \"01063\"      NA          \n\n\nDepending on how strict I was being, I might have kept the last one by leaving out the starting and ending positioning.\n\nstr_extract(string_zip, \"\\\\d{5}(-\\\\d{4})?\")\n\n[1] \"01063-6302\" \"91711\"      NA           \"01063\"      \"01063\"     \n\n\nNote that in R, \\d needs to be escaped to \\\\d. That’s true with any metacharacter which uses a backslash."
  },
  {
    "objectID": "handout/lab4_regex_sds261_j24_sol.html#assignment",
    "href": "handout/lab4_regex_sds261_j24_sol.html#assignment",
    "title": "Lab 4 - regular expressions",
    "section": "Assignment",
    "text": "Assignment\n\nGo through the lessons in https://regexone.com/. Nothing to turn in.\nCatch all of the instances of the words color or colour, case insensitive. Test on the given string.\n\n\nstring &lt;- c(\"color\", \"colour\", \"Color\", \"Colour\", \"Colr\", \"cols\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Solution\n\nstr_extract(string, \"(?i)colou?r\")\n\n[1] \"color\"  \"colour\" \"Color\"  \"Colour\" NA       NA      \n\n\n\n\n\n\n\nMatch any number (including zero) of o’s, as in: ggle, gogle, google, gooogle, …\nMatch at least one o, as in: gogle, google, gooogle, …\n\n\nTest on the given string.\n\nstring &lt;- c(\"ggle\", \"gogle\", \"google\", \"gooogle\", \"goooogle\", \"gooooogle\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Solution (a)\n\nstr_extract(string, \"go*gle\")\n\n[1] \"ggle\"      \"gogle\"     \"google\"    \"gooogle\"   \"goooogle\"  \"gooooogle\"\n\n# Solution (b)\n\nstr_extract(string, \"go+gle\")\n\n[1] NA          \"gogle\"     \"google\"    \"gooogle\"   \"goooogle\"  \"gooooogle\"\n\n\n\n\n\n\nValidate dates which are in the format mm/dd/yy or mm/dd/yyyy. Allow for any digits for the values (e.g., month could be 47). As an extra challenge, try to make the numerical values realistic (e.g., months only between 01 and 12). Test on the given string.\n\n\nstring_date &lt;- c(\"01/11/2024\", \"1/11/2024\", \"1/1/24\", \"01/11/24\", \"24/01/4700\" )\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Solution: \n\nstr_extract(string_date, \"^[0-1][0-9]/[0-3][0-9]/([0-9]{2})?[0-9]{2}\")\n\n[1] \"01/11/2024\" NA           NA           \"01/11/24\"   NA          \n\n# Another solution\n\nstr_extract(string_date, \"\\\\d{2}/\\\\d{2}/(\\\\d{2}|\\\\d{4})\")\n\n[1] \"01/11/20\" NA         NA         \"01/11/24\" \"24/01/47\"\n\n\n\n\n\n\nCheck a command line response so that true, t, yes, y, okay, ok, and 1 are all accepted in any combination of uppercase and lowercase. Test on the given string.\n\n\nstr_affirm &lt;- c(\"true\", \"t\", \"yes\", \"y\", \"okay\", \"ok\", \"1\", \"tRUe\", \"TRUE\", \"T\",\n               \"YES!\", \"yeS\", \"okay...\", \"sure\", \"maybe\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Solution: \n\nstr_extract(str_affirm, \"(?i)^(1|t(rue)?|y(es)?|ok(ay)?)$\")\n\n [1] \"true\" \"t\"    \"yes\"  \"y\"    \"okay\" \"ok\"   \"1\"    \"tRUe\" \"TRUE\" \"T\"   \n[11] NA     \"yeS\"  NA     NA     NA    \n\n\n\n\n\n\nMatch numbers that use the comma as the thousands separator and the dot as the decimal separator. Test on the given string.\n\n\nstring_number &lt;- c(\"12345\", \"12,345\", \"123.45\", \"1,234,567.890\", \"12,345.\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Solution: \n\nstr_extract(string_number, \"^[0-9]{1,3}(,[0-9]{3})*(\\\\.[0-9]*)?$\")\n\n[1] NA              \"12,345\"        \"123.45\"        \"1,234,567.890\"\n[5] \"12,345.\"      \n\n# or if you don't want the last number\n\nstr_extract(string_number, \"^[0-9]{1,3}(,[0-9]{3})*(\\\\.[0-9]+)?$\")\n\n[1] NA              \"12,345\"        \"123.45\"        \"1,234,567.890\"\n[5] NA             \n\n\n\n\n\n\nDetermine whether a user entered a North American phone number in a common format, including the local area code. Common formats include 1234567890, 123-456-7890, 123.456.7890, 123 456 7890, (123) 456 7890, and all related combinations. Test on the given string.\n\n\nstring_phone &lt;- c(\"1234567890\", \"1234\", \"456-7890\", \"123-456-7890\", \"123.456.7890\", \"123 456 7890\", \"(123) 456 7890\", \"+1 (123) 456 789\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Solution: \n\nstr_extract(string_phone, \"^\\\\(?([0-9]{3})\\\\)?[-. ]?([0-9]{3})[-. ]?([0-9]{4})$\")\n\n[1] \"1234567890\"     NA               NA               \"123-456-7890\"  \n[5] \"123.456.7890\"   \"123 456 7890\"   \"(123) 456 7890\" NA              \n\n\n\n\n\n\nFind all words that occur inside an html emphasis tag (&lt;em&gt; and &lt;/em&gt;). Test on the given string. (After Friday’s class.)\n\n\nstring_emph &lt;- c(\"&lt;p&gt;&lt;strong&gt;Pellentesque habitant morbi tristique&lt;/strong&gt; senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. &lt;em&gt;Aenean ultricies mi vitae est.&lt;/em&gt; Mauris placerat eleifend leo. Quisque sit amet est et sapien ullamcorper pharetra. Vestibulum erat wisi, condimentum sed, &lt;code&gt;commodo vitae&lt;/code&gt;, ornare sit amet, wisi. Aenean fermentum, elit eget tincidunt condimentum, eros ipsum rutrum orci, sagittis tempus lacus enim ac dui. &lt;a href='#'&gt;Donec non enim&lt;/a&gt; in turpis pulvinar facilisis. Ut felis.&lt;/p&gt;\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Solution: \n\nstr_extract(string_emph, \"(?&lt;=&lt;em&gt;)[\\\\w\\\\s.]+(?=&lt;/em&gt;)\")\n\n[1] \"Aenean ultricies mi vitae est.\""
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#case-insenstive",
    "href": "slides/2024-01-11-regex1.html#case-insenstive",
    "title": "Regular Expressions I",
    "section": "Case insenstive",
    "text": "Case insenstive\n\nMatch only the word meter in “The cemetery is 1 meter from the stop sign.” Also match Meter in “The cemetery is 1 Meter from the stop sign.”"
  },
  {
    "objectID": "slides/2024-01-11-regex1.html#case-insenstive-1",
    "href": "slides/2024-01-11-regex1.html#case-insenstive-1",
    "title": "Regular Expressions I",
    "section": "Case insenstive",
    "text": "Case insenstive\n\nMatch only the word meter in “The cemetery is 1 meter from the stop sign.” Also match Meter in “The cemetery is 1 Meter from the stop sign.”\n\n\nstring &lt;- c(\"The cemetery is 1 meter from the stop sign.\", \n            \"The cemetery is 1 Meter from the stop sign.\")\n\nstr_extract(string, \"(?i)\\\\bmeter\\\\b\")\n\n[1] \"meter\" \"Meter\""
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#regular-expressions-and-sql",
    "href": "slides/2024-01-12-regex2.html#regular-expressions-and-sql",
    "title": "Regular Expressions II",
    "section": "Regular expressions and SQL",
    "text": "Regular expressions and SQL\nBack to the IMDb database…\n\nSELECT production_year, title\n  FROM title\n  WHERE kind_id = 1 AND\n        title REGEXP '(?i)star'\n  LIMIT 0, 20;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nproduction_year\n\n\ntitle\n\n\n\n\n\n\n2005\n\n\n\"Dancing with the Stars\" (I)\n\n\n\n\n2005\n\n\n\"Dancing with the Stars\" (II)\n\n\n\n\n2005\n\n\n\"Dancing with the Stars\" (III)\n\n\n\n\n2017\n\n\n\"Girl Starter\" (II)\n\n\n\n\n2001\n\n\n\"Popstars\" (I)\n\n\n\n\n2001\n\n\n\"Popstars\" (II)\n\n\n\n\n2002\n\n\n\"Popstars\" (I)\n\n\n\n\n2000\n\n\n\"Popstars\" (I)\n\n\n\n\n1959\n\n\n\"Startime\" (II)\n\n\n\n\n1959\n\n\n\"Startime\" (I)"
  },
  {
    "objectID": "slides/2024-01-12-regex2.html#course-project",
    "href": "slides/2024-01-12-regex2.html#course-project",
    "title": "Regular Expressions II",
    "section": "Course project",
    "text": "Course project\nDon’t forget, next week, each person will be working on their own mini project!\n\nUsing SQL queries and joins to wrangle complicated data tables.\nWriting regular expressions to parse observations.\nCreating a SQL database.\n\n\nemail jo.hardin@pomona.edu by Tuesday, Jan 16 with an idea of what you plan to do.\n\nQuestion of interest that you hope to address.\nHolistic description of the dataset(s) (a few sentences).\nDescription of the observational units and columns in each data table.\nFull reference for data citation.\nLink to the resources."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#duckdb",
    "href": "slides/2024-01-16-creating-db.html#duckdb",
    "title": "Creating Databases",
    "section": "DuckDB",
    "text": "DuckDB\nDuckDB\n\nin-process database management system that runs entirely on your own computer.\nthe data live in your storage (instead of your memory).\nyou don’t have to transfer queries or results over the internet."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#duckdb-caveat",
    "href": "slides/2024-01-16-creating-db.html#duckdb-caveat",
    "title": "Creating Databases",
    "section": "DuckDB caveat",
    "text": "DuckDB caveat\n\nthe SQL dialect used in DuckDB is slightly different from MySQL\nwrite SELECT * FROM table 10; instead of SELECT * FROM table 0, 10;\nlots of different dialects, depending on the SQL server. Always be aware of the dialect you are using."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#duckdb-via-r",
    "href": "slides/2024-01-16-creating-db.html#duckdb-via-r",
    "title": "Creating Databases",
    "section": "DuckDB via R",
    "text": "DuckDB via R\n\ninstall.packages(\"duckdb\")  # only once, in the Console, not in the .qmd or .Rmd file\nlibrary(duckdb)             # at the top of the .qmd or .Rmd file\n\nlibrary(DBI)                # we also still need the DBI package\n\n\ncon_duckdb &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"duck_datab\")\n\n\nthe database has been stored to a database directory called duck_datab which lives in the current R project.\ncan’t open it like a standard folder, but it is where DuckDB stores the database files."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#preparing-to-load-data",
    "href": "slides/2024-01-16-creating-db.html#preparing-to-load-data",
    "title": "Creating Databases",
    "section": "Preparing to load data",
    "text": "Preparing to load data\nUnlike R, when creating a new data table, SQL requires that you communicate each future variable (column) and that variable’s type. Variable types are not automatically generated!"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#saturday-night-live",
    "href": "slides/2024-01-16-creating-db.html#saturday-night-live",
    "title": "Creating Databases",
    "section": "Saturday Night Live",
    "text": "Saturday Night Live\n\nFigure 1: image credit: NBCConsider the Saturday Night Live datasets available on the snldb GitHub repo."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#casts-table",
    "href": "slides/2024-01-16-creating-db.html#casts-table",
    "title": "Creating Databases",
    "section": "casts table",
    "text": "casts table\nUse R to understand the data from casts.csv.\n\nglimpse(casts)\n\nRows: 614\nColumns: 8\n$ aid             &lt;chr&gt; \"A. Whitney Brown\", \"A. Whitney Brown\", \"A. Whitney Br…\n$ sid             &lt;dbl&gt; 11, 12, 13, 14, 15, 16, 5, 39, 40, 41, 42, 45, 46, 21,…\n$ featured        &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ first_epid      &lt;dbl&gt; 19860222, NA, NA, NA, NA, NA, 19800409, 20140118, NA, …\n$ last_epid       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ update_anchor   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ n_episodes      &lt;dbl&gt; 8, 20, 13, 20, 20, 20, 5, 11, 21, 21, 21, 18, 17, 20, …\n$ season_fraction &lt;dbl&gt; 0.444, 1.000, 1.000, 1.000, 1.000, 1.000, 0.250, 0.524…"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#loading-data",
    "href": "slides/2024-01-16-creating-db.html#loading-data",
    "title": "Creating Databases",
    "section": "Loading data",
    "text": "Loading data\nImporting .csv files as tables, a series of steps:1\n\na USE statement that ensures we are in the right schema/database.\na series of DROP TABLE statements that drop any old tables with the same names as the ones we are going to create.\na series of CREATE TABLE statements that specify the table structures.\na series of COPY statements that read the data from the .csv files into the appropriate tables.\n\ntaken from MDSR."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#loading-step-1-use",
    "href": "slides/2024-01-16-creating-db.html#loading-step-1-use",
    "title": "Creating Databases",
    "section": "Loading step 1, USE",
    "text": "Loading step 1, USE\nUse the (local) database that we’ve called duck_datab.\n\n```{sql}\n#| connection: con_duckdb\n\nUSE duck_datab;\n```"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#loading-step-2-refresh",
    "href": "slides/2024-01-16-creating-db.html#loading-step-2-refresh",
    "title": "Creating Databases",
    "section": "Loading step 2, refresh",
    "text": "Loading step 2, refresh\nMake sure to “refresh” the table, in case it already exists. However, be very careful with the DROP TABLE statement, as it removes the casts table.\n\nDROP TABLE IF EXISTS casts;"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#loading-step-3-create-table",
    "href": "slides/2024-01-16-creating-db.html#loading-step-3-create-table",
    "title": "Creating Databases",
    "section": "Loading step 3, CREATE TABLE",
    "text": "Loading step 3, CREATE TABLE\nCarefully define the variable types, whether or not they allow missing values, and what a default value is for that variable. Additionally, identify the key for accessing information.\n\nCREATE TABLE casts (\n  aid VARCHAR(255) NOT NULL DEFAULT '',\n  sid INTEGER NOT NULL DEFAULT 0,\n  featured BOOLEAN NOT NULL DEFAULT 'false',\n  first_epid INTEGER DEFAULT 0,\n  last_epid INTEGER DEFAULT 0,\n  update_anchor BOOLEAN NOT NULL DEFAULT 0,\n  n_episodes INTEGER NOT NULL DEFAULT 0,\n  season_fraction DECIMAL(21,20) NOT NULL DEFAULT 0,\n  PRIMARY KEY (sid, aid)\n);"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#loading-step-4-copy",
    "href": "slides/2024-01-16-creating-db.html#loading-step-4-copy",
    "title": "Creating Databases",
    "section": "Loading step 4, COPY",
    "text": "Loading step 4, COPY\nThe .csv file lives on my computer, so I load it in directly. [n.b., the statement to load in data is different in MySQL.]\n\nCOPY casts FROM 'data/casts.csv' HEADER;"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#checking-the-loading-select",
    "href": "slides/2024-01-16-creating-db.html#checking-the-loading-select",
    "title": "Creating Databases",
    "section": "Checking the loading, SELECT",
    "text": "Checking the loading, SELECT\n\nSELECT * FROM casts LIMIT 8;\n\n\n\n\n\nTable 1: After CREATE TABLE where variable types are set, the COPY command pulls the data into the table. SELECT shows us that the table is as expected.\n\n\naid\nsid\nfeatured\nfirst_epid\nlast_epid\nupdate_anchor\nn_episodes\nseason_fraction\n\n\n\n\nA. Whitney Brown\n11\nTRUE\n19860222\n\nFALSE\n8\n0.444\n\n\nA. Whitney Brown\n12\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n13\nTRUE\n\n\nFALSE\n13\n1.000\n\n\nA. Whitney Brown\n14\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n15\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n16\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nAlan Zweibel\n5\nTRUE\n19800409\n\nFALSE\n5\n0.250\n\n\nSasheer Zamata\n39\nTRUE\n20140118\n\nFALSE\n11\n0.524"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#check-the-database",
    "href": "slides/2024-01-16-creating-db.html#check-the-database",
    "title": "Creating Databases",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nSHOW DATABASES;\n\n\n\n\n1 records\n\n\n\n\ndatabase_name\n\n\n\n\n\n\nduck_datab"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#efficiencies",
    "href": "slides/2024-01-16-creating-db.html#efficiencies",
    "title": "Creating Databases",
    "section": "Efficiencies",
    "text": "Efficiencies\n\nEach library (database) has books (tables). Each book (table) has pages (rows). Each page (row) has a unique page number to identify it (key value); to find a particular page, you sort through the page numbers (key values). But it isn’t immediately obvious where the particular page of interest is, you might have to page through the book a little bit to find the page of interest. It would be easier if you had several bookmarks throughout the book to anchor some of the page numbers. For example, if you want page 1047 and you have a bookmark on page 1050, you only have to turn back three pages. The bookmark is an index, it helps you find the desired rows much more quickly.1\n\nAnalogy taken from: https://www.quora.com/profile/Lara-Mazilu"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#key",
    "href": "slides/2024-01-16-creating-db.html#key",
    "title": "Creating Databases",
    "section": "Key",
    "text": "Key\nKeys are unique identifiers for each row, used primarily for connecting tables. Keys are generally not helpful for efficiency, but they are important for data integrity and relationships between tables.\n\nPRIMARY KEY is a column or set of columns that uniquely identify each row. Primary keys cannot be NULL.\nFOREIGN KEY is a column or set of columns that reference a primary key in a different table. A foreign key can be NULL."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#index",
    "href": "slides/2024-01-16-creating-db.html#index",
    "title": "Creating Databases",
    "section": "Index",
    "text": "Index\n\nEach library (database) has books (tables). Each book (table) has pages (rows). Each page (row) has a unique page number to identify it (key value); to find a particular page, you sort through the page numbers (key values). But it isn’t immediately obvious where the particular page of interest is, you might have to page through the book a little bit to find the page of interest. It would be easier if you had several bookmarks throughout the book to anchor some of the page numbers. For example, if you want page 1047 and you have a bookmark on page 1050, you only have to turn back three pages. The bookmark is an index, it helps you find the desired rows much more quickly.1\n\nAnalogy taken from: https://www.quora.com/profile/Lara-Mazilu"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#find-keys-and-indices",
    "href": "slides/2024-01-16-creating-db.html#find-keys-and-indices",
    "title": "Creating Databases",
    "section": "Find keys and indices",
    "text": "Find keys and indices\nIn MySQL the commands SHOW KEYS and SHOW INDEXES provide information about the keys and indices for each table."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#best-practice",
    "href": "slides/2024-01-16-creating-db.html#best-practice",
    "title": "Creating Databases",
    "section": "Best practice",
    "text": "Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_duckdb, shutdown = TRUE)"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#check-the-database-1",
    "href": "slides/2024-01-16-creating-db.html#check-the-database-1",
    "title": "Creating Databases",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nSHOW TABLES;\n\n\n\n\n1 records\n\n\n\n\nname\n\n\n\n\n\n\ncasts"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#check-the-database-2",
    "href": "slides/2024-01-16-creating-db.html#check-the-database-2",
    "title": "Creating Databases",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nDESCRIBE casts;\n\n\n\n\n\nTable 2: DESCRIBE variables in the casts table.\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\naid\nVARCHAR\nNO\nPRI\n''\n\n\n\nsid\nINTEGER\nNO\nPRI\n0\n\n\n\nfeatured\nBOOLEAN\nNO\n\n'false'\n\n\n\nfirst_epid\nINTEGER\nYES\n\n0\n\n\n\nlast_epid\nINTEGER\nYES\n\n0\n\n\n\nupdate_anchor\nBOOLEAN\nNO\n\n0\n\n\n\nn_episodes\nINTEGER\nNO\n\n0\n\n\n\nseason_fraction\nDECIMAL(21,20)\nNO\n\n0"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#partitioning",
    "href": "slides/2024-01-16-creating-db.html#partitioning",
    "title": "Creating Databases",
    "section": "Partitioning",
    "text": "Partitioning\nAnother way to speed up query retrievals is to partition the data tables. If, for example, the SNL queries were always done by year, then the episodes table could be partitioned such that they are stored as separate tables (one per year). The partitioning functions as an index on year. The user would not be able to tell the difference between the unpartitioned episodes table and the partitioned one. Queries done by year would be faster. Queries done grouped in another way would be slower."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#a-null-example",
    "href": "slides/2024-01-09-clauses.html#a-null-example",
    "title": "SQL clauses",
    "section": "A NULL example",
    "text": "A NULL example\nThe logic of NULL:1\n\nIf you do anything with NULL, you’ll just get NULL. For instance if \\(x\\) is NULL, then \\(x &gt; 3\\), \\(1 = x\\), and \\(x + 4\\) all evaluate to NULL. Even \\(x =\\) NULL evaluates to NULL! if you want to check whether \\(x\\) is NULL, use x IS NULL or x IS NOT NULL.\nNULL short-circuits with boolean operators. That means a boolean expression involving NULL will evaluate to:\n\nTRUE, if it’d evaluate to TRUE regardless of whether the NULL value is really TRUE or FALSE.\nFALSE, if it’d evaluate to FALSE regardless of whether the NULL value is really TRUE or FALSE.\nOr NULL, if it depends on the NULL value.\n\n\ntaken from: https://cs186berkeley.net/notes/note1/#filtering-null-values"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#a-null-example-1",
    "href": "slides/2024-01-09-clauses.html#a-null-example-1",
    "title": "SQL clauses",
    "section": "A NULL example",
    "text": "A NULL example\nConsider the following table and SQL query to evaluate WHERE age &lt;= 20 OR num_dogs = 3:\n\nSELECT * FROM (\n   SELECT 'Ace' AS name, 20 AS age, 4 as num_dogs\n   UNION\n   SELECT 'Ada' AS name, NULL AS age, 3 as num_dogs   \n   UNION\n   SELECT 'Ben' AS name, NULL AS age, NULL as num_dogs\n   UNION\n   SELECT 'Cho' AS name, 27 AS age, NULL as num_dogs\n   ) AS temptable;\n\n\n\n\n4 records\n\n\n\n\nname\n\n\nage\n\n\nnum_dogs\n\n\n\n\n\n\nAce\n\n\n20\n\n\n4\n\n\n\n\nAda\n\n\n\n\n3\n\n\n\n\nBen\n\n\n\n\n\n\n\n\nCho\n\n\n27"
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#a-null-example-2",
    "href": "slides/2024-01-09-clauses.html#a-null-example-2",
    "title": "SQL clauses",
    "section": "A NULL example",
    "text": "A NULL example\nWhere does the WHERE clause do? It tells us that we only want to keep the rows satisfying the age &lt;= 20 OR num_dogs = 3. Let’s consider each row one at a time:\n\nFor Ace, age &lt;= 20 evaluates to TRUE so the claim is satisfied.\nFor Ada, age &lt;= 20 evaluates to NULL but num_dogs = 3 evaluates to TRUE so the claim is satisfied.\nFor Ben, age &lt;= 20 evaluates to NULL and num_dogs = 3 evaluates to NULL so the overall expression is NULL which has a FALSE value.\nFor Cho, age &lt;= 20 evaluates to FALSE and num_dogs = 3 evaluates to NULL so the overall expression evaluates to NULL (because it depends on the value of the NULL).\n\nThus we keep only Ace and Ada."
  },
  {
    "objectID": "slides/2024-01-09-clauses.html#a-null-example-3",
    "href": "slides/2024-01-09-clauses.html#a-null-example-3",
    "title": "SQL clauses",
    "section": "A NULL example",
    "text": "A NULL example\n\nSELECT * FROM (\n   SELECT 'Ace' AS name, 20 AS age, 4 as num_dogs\n   UNION\n   SELECT 'Ada' AS name, NULL AS age, 3 as num_dogs   \n   UNION\n   SELECT 'Ben' AS name, NULL AS age, NULL as num_dogs\n   UNION\n   SELECT 'Cho' AS name, 27 AS age, NULL as num_dogs\n   ) AS temptable\nWHERE age &lt;= 20 OR num_dogs = 3;\n\n\n\n\n2 records\n\n\n\n\nname\n\n\nage\n\n\nnum_dogs\n\n\n\n\n\n\nAce\n\n\n20\n\n\n4\n\n\n\n\nAda\n\n\n\n\n3"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24.html",
    "href": "handout/lab5_creating_db_sds261_j24.html",
    "title": "Lab 5 - creating databases",
    "section": "",
    "text": "Today’s lab will provide practice working with creating SQL databases using DuckDB.\nThe goals for lab 5 include:"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab5_creating_db_sds261_j24.html#advice-for-turning-in-the-assignment",
    "title": "Lab 5 - creating databases",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .qmd file) which problem is being answered with which code. A sentence or two with each response goes a long way toward your understanding!\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe .qmd document should be saved in the R Project as lab5-sds261-yourlastname-yourfirstname.qmd.\nSet up a connection to a database of your naming using DuckDB.\n\n\ncon_college &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"you_name_the_db\")"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24.html#assignment",
    "href": "handout/lab5_creating_db_sds261_j24.html#assignment",
    "title": "Lab 5 - creating databases",
    "section": "Assignment",
    "text": "Assignment\nThe data we will work with today is on college tuition, pay, and diversity. The original data source is the US Department of Education, but it has been compiled as part of TidyTuesday on March 10, 2020. Tuition and fees are for 2018-19. Diversity is for 2014.\n\nDownload the data onto your own computer. In the interest of time, let’s only use three tables: tuition_cost and salary_potential and diversity_school.\n\n\nFollow the first two steps in the notes: USE and DROP TABLE.\n\n\nFor each of the three tables, in the CREATE TABLE operation, carefully define variable types and identify any key variables. Unfortunately, FOREIGN KEYs don’t work here because there is not referential integrity across the tables.\n\n\nUse COPY to load the data from your computer. (Hint: if there is an NA value, SQL doesn’t know that it is actually NULL and wants the variable to be loaded as a character string.)\n\n\nUse SELECT * (with a LIMIT!) to make sure all three tables loaded correctly.\n\n\nAdd an INDEX to the tuition table on state. We won’t discuss until Thursday, but state is better than state_code because state allows you to join with other tables. state is better than type or degree_length because state has a much higher cardinality."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html",
    "href": "slides/2024-01-16-creating-db.html",
    "title": "Creating Databases",
    "section": "",
    "text": "DuckDB\n\nin-process database management system that runs entirely on your own computer.\nthe data live in your storage (instead of your memory).\nyou don’t have to transfer queries or results over the internet."
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#footnotes",
    "href": "slides/2024-01-16-creating-db.html#footnotes",
    "title": "Creating Databases",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ntaken from MDSR.↩︎"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html",
    "href": "slides/2024-01-17-editing-db.html",
    "title": "Editing Databases",
    "section": "",
    "text": "We will continue to use DuckDB so that we have write access to the files we want to edit.\n\ncon_duckdb &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"duck_datab\")\n\n\n\n\n\n\n\n\nFigure 1: image credit: NBC\n\n\n\n\nConsider the Saturday Night Live datasets available on the snldb GitHub repo.\n\n\n\nThe UPDATE function allows you to change a value in a table across all rows that match a certain criteria.\n\nSELECT * FROM impressions \n   WHERE name LIKE 'Ivanka%';\n\n\n\n\n5 records\n\n\n\n\nimpid\n\n\naid\n\n\nname\n\n\n\n\n\n\n2598\n\n\nScarlett Johansson\n\n\nIvanka Trump\n\n\n\n\n3716\n\n\nEmily Blunt\n\n\nIvanka Trump\n\n\n\n\n3694\n\n\nMargot Robbie\n\n\nIvanka Trump\n\n\n\n\n3679\n\n\nVanessa Bayer\n\n\nIvanka Trump\n\n\n\n\n2340\n\n\nMaya Rudolph\n\n\nIvanka Trump\n\n\n\n\n\n\n\n\n\n\nFor funsies, let’s change Ivanka Trump to Ivanka Kushner.\n\nUPDATE impressions\n   SET name = 'Ivanka Kushner'\n   WHERE name LIKE 'Ivanka%';\n\n\nSELECT * FROM impressions \n   WHERE name LIKE 'Ivanka%';\n\n\n\n\n5 records\n\n\n\n\nimpid\n\n\naid\n\n\nname\n\n\n\n\n\n\n2598\n\n\nScarlett Johansson\n\n\nIvanka Kushner\n\n\n\n\n3716\n\n\nEmily Blunt\n\n\nIvanka Kushner\n\n\n\n\n3694\n\n\nMargot Robbie\n\n\nIvanka Kushner\n\n\n\n\n3679\n\n\nVanessa Bayer\n\n\nIvanka Kushner\n\n\n\n\n2340\n\n\nMaya Rudolph\n\n\nIvanka Kushner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Watch out!\n\n\n\nBe careful with UPDATE. A careless UPDATE could write over all of the data in your table. There is no undo function.\n\n\n\n\n\nTask: include recent hosts in the hosts table.\nBy searching the SNL archives, we can see that the next host, chronologically was Elon Musk on May 8, 2021.\n\n\n\n\n\nFigure 2: Hosts information from snlarchives.net\n\n\n\n\n\n\n\nTask: include recent hosts in the hosts table.\nBy searching the SNL archives, we can see that the next host, chronologically was Elon Musk on May 8, 2021.\n\nSELECT * FROM hosts\n    ORDER BY epid DESC\n    LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20210410\n\n\nCarey Mulligan\n\n\n\n\n20210403\n\n\nDaniel Kaluuya\n\n\n\n\n20210327\n\n\nMaya Rudolph\n\n\n\n\n20210227\n\n\nNick Jonas\n\n\n\n\n20210220\n\n\nRege-Jean Page\n\n\n\n\n20210213\n\n\nRegina King\n\n\n\n\n20210206\n\n\nDan Levy\n\n\n\n\n20210130\n\n\nJohn Krasinski\n\n\n\n\n20201219\n\n\nKristen Wiig\n\n\n\n\n20201212\n\n\nTimothee Chalamet\n\n\n\n\n\n\n\n\n\n\nINSERT allows us to add the relevant information associated with the episode of SNL that Elon Musk hosted.\n\nINSERT INTO hosts (epid, aid)\n   VALUES ('20210508', 'Elon Musk');\n\n\nSELECT * FROM hosts\n    ORDER BY epid DESC\n    LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20210508\n\n\nElon Musk\n\n\n\n\n20210410\n\n\nCarey Mulligan\n\n\n\n\n20210403\n\n\nDaniel Kaluuya\n\n\n\n\n20210327\n\n\nMaya Rudolph\n\n\n\n\n20210227\n\n\nNick Jonas\n\n\n\n\n20210220\n\n\nRege-Jean Page\n\n\n\n\n20210213\n\n\nRegina King\n\n\n\n\n20210206\n\n\nDan Levy\n\n\n\n\n20210130\n\n\nJohn Krasinski\n\n\n\n\n20201219\n\n\nKristen Wiig\n\n\n\n\n\n\n\n\n\n\nIt would be tedious to INSERT all of the most recent host information by hand. Instead, we’ll scrape the SNL archives using the R package rvest, which allows us to pull out the appropriate html elements. The epid and aid are joined together in a tibble, and filtered to only include episodes which are not already in the episodes table.\n\nlibrary(rvest)\n\nrecent_hosts &lt;- read_html(\"http://www.snlarchives.net/Episodes/\") |&gt;\n  html_nodes(\"tr\") |&gt;\n  purrr::map_df( ~ tibble(\n    epid = .x |&gt; html_node(\"a.ms-2.me-2\") |&gt;\n      html_attr(\"href\") |&gt;\n      str_extract(\"\\\\d+\"),\n    aid = .x |&gt; html_node(\"td:nth-child(2)\") |&gt;\n      html_text2() |&gt;\n      str_extract(\"[\\\\w\\\\. \\\\w\\\\.]+(?=/|$)\")\n  )) |&gt;\n  filter(epid &gt; 20210508)\n\n\nwrite_csv(recent_hosts, \"data/recent_hosts.csv\")\n\n\n\n\n\nINSERT INTO hosts\n   SELECT *\n   FROM READ_CSV('data/recent_hosts.csv', AUTO_DETECT = TRUE);\n\n\nSELECT * FROM hosts\n  ORDER BY epid DESC\n  LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20231216\n\n\nKate McKinnon\n\n\n\n\n20231209\n\n\nAdam Driver\n\n\n\n\n20231202\n\n\nEmma Stone\n\n\n\n\n20231118\n\n\nJason Momoa\n\n\n\n\n20231111\n\n\nTimothée Chalamet\n\n\n\n\n20231028\n\n\nNate Bargatze\n\n\n\n\n20231021\n\n\nBad Bunny\n\n\n\n\n20231014\n\n\nPete Davidson\n\n\n\n\n20230415\n\n\nAna de Armas\n\n\n\n\n20230408\n\n\nMolly Shannon\n\n\n\n\n\n\n\n\n\n\nYou might change your mind and decide that you really only want hosts from years up to 2022. The DELETE function deletes any rows specified by the WHERE clause.\n\nDELETE FROM hosts\n   WHERE epid &gt; 20221231;\n\n\nSELECT * FROM hosts\n  ORDER BY epid DESC\n  LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20221217\n\n\nAustin Butler\n\n\n\n\n20221210\n\n\nMartin Short\n\n\n\n\n20221203\n\n\nKeke Palmer\n\n\n\n\n20221112\n\n\nDave Chappelle\n\n\n\n\n20221105\n\n\nAmy Schumer\n\n\n\n\n20221029\n\n\nJack Harlow\n\n\n\n\n20221015\n\n\nMegan Thee Stallion\n\n\n\n\n20221008\n\n\nBrendan Gleeson\n\n\n\n\n20221001\n\n\nMiles Teller\n\n\n\n\n20220521\n\n\nNatasha Lyonne\n\n\n\n\n\n\n\n\n\n\nALTER TABLE changes the structure of a table. For example, you can add or delete columns, create or destroy indexes, change the type of existing columns, or rename columns or the table itself.\nMultiple ADD, ALTER, DROP, and CHANGE clauses are permitted in a single ALTER TABLE statement, separated by commas.\nCaveat: I have found DuckDB to be slightly finicky in some of the operations…\n\n\n\n\nALTER TABLE t1\nDROP COLUMN col1,\nDROP COLUMN col2;\n\n\n\n\n\nrename an INT NOT NULL column from a to b and change its definition to use the BIGINT data type while retaining the NOT NULL attribute.\n\n\nALTER TABLE t1 CHANGE a b BIGINT NOT NULL;\n\n\n\n\n\nCHANGE, the syntax requires two column names, so you must specify the same name twice to leave the name unchanged. For example, to change the definition of column b.\n\n\nALTER TABLE t1 CHANGE b b INT NOT NULL;\n\n\n\n\n\nMODIFY is more convenient to change the definition without changing the name because it requires the column name only once.\n\n\nALTER TABLE t1 MODIFY b INT NOT NULL;\n\n\n\n\n\nCHANGE, the syntax requires a column definition, so to leave the definition unchanged, you must respecify the definition the column currently has. For example, to rename an INT NOT NULL column from b to a.\n\n\nALTER TABLE t1 CHANGE b a INT NOT NULL;\n\n\n\n\n\nRENAME COLUMN is more convenient to change the name without changing the definition because it requires only the old and new names.\n\n\nALTER TABLE t1 RENAME COLUMN b TO a;\n\n\n\n\n\ncannot RENAME COLUMN to a column name that already exists. The following are valid.\n\n\n/* swap a and b */\nALTER TABLE t1 RENAME COLUMN a TO b,\n               RENAME COLUMN b TO a;\n\n/* \"rotate\" a, b, c through a cycle */\nALTER TABLE t1 RENAME COLUMN a TO b,\n               RENAME COLUMN b TO c,\n               RENAME COLUMN c TO a;\n\n\n\n\nTemporary tables are used to break down complex queries into smaller, more manageable steps. For example, let’s say we want to JOIN two tables after each has been filtered using different WHERE clauses. The filtered tables can each be saved into their own temporary tables and then the temporary tables can be merged.\nTables in DuckDB are saved (to disk), even when the connection is closed. However, temporary tables are saved in memory (instead of on disk) and are deleted when the connection is closed.\n\n\n\n\nSELECT * FROM episodes LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nsid\n\n\nepid\n\n\naired\n\n\nepno\n\n\n\n\n\n\n46\n\n\n20210410\n\n\nApril 10, 2021\n\n\n17\n\n\n\n\n46\n\n\n20210403\n\n\nApril 3, 2021\n\n\n16\n\n\n\n\n46\n\n\n20210327\n\n\nMarch 27, 2021\n\n\n15\n\n\n\n\n46\n\n\n20210227\n\n\nFebruary 27, 2021\n\n\n14\n\n\n\n\n46\n\n\n20210220\n\n\nFebruary 20, 2021\n\n\n13\n\n\n\n\n46\n\n\n20210213\n\n\nFebruary 13, 2021\n\n\n12\n\n\n\n\n46\n\n\n20210206\n\n\nFebruary 6, 2021\n\n\n11\n\n\n\n\n46\n\n\n20210130\n\n\nJanuary 30, 2021\n\n\n10\n\n\n\n\n46\n\n\n20201219\n\n\nDecember 19, 2020\n\n\n9\n\n\n\n\n46\n\n\n20201212\n\n\nDecember 12, 2020\n\n\n8\n\n\n\n\n\n\n\n\n\n\nWe wouldn’t want to wrangle the date every single time we used the data.\n\nCREATE TEMP TABLE episodes_date AS\n    SELECT *, CASE\n             WHEN POSITION(',' IN aired) &gt; 0 THEN\n    EXTRACT(YEAR FROM CAST(\n                SUBSTRING(aired, POSITION(',' IN aired) + 2) || '-' ||\n                CASE\n                    WHEN POSITION('January' IN aired) &gt; 0 THEN '01'\n                    WHEN POSITION('February' IN aired) &gt; 0 THEN '02'\n                    WHEN POSITION('March' IN aired) &gt; 0 THEN '03'\n                    WHEN POSITION('April' IN aired) &gt; 0 THEN '04'\n                    WHEN POSITION('May' IN aired) &gt; 0 THEN '05'\n                    WHEN POSITION('June' IN aired) &gt; 0 THEN '06'\n                    WHEN POSITION('July' IN aired) &gt; 0 THEN '07'\n                    WHEN POSITION('August' IN aired) &gt; 0 THEN '08'\n                    WHEN POSITION('September' IN aired) &gt; 0 THEN '09'\n                    WHEN POSITION('October' IN aired) &gt; 0 THEN '10'\n                    WHEN POSITION('November' IN aired) &gt; 0 THEN '11'\n                    WHEN POSITION('December' IN aired) &gt; 0 THEN '12'\n                    ELSE '01' -- Default to January if no month is found\n                END || '-' ||\n                SUBSTRING(aired, POSITION(' ' IN aired) + 1, 2) AS DATE\n            ))\n            END AS year FROM episodes;\n\n\n\n\nIn case you are curious about the date wrangling code… consider SUBSTRING(aired, POSITION(',' IN aired) + 2)\n\nPOSITION(',' IN aired): This part of the expression uses the POSITION function to find the position of the first occurrence of the comma (,) in the string aired. The result is the index (position) of the comma within the string.\nPOSITION(',' IN aired) + 2: This adds 2 to the index of the comma. The + 2 is used to move the starting point of the substring two positions to the right of the comma. This is done to exclude the comma itself and any following spaces.\nSUBSTRING(aired, POSITION(',' IN aired) + 2): This part uses the SUBSTRING function to extract a substring from the string aired. The starting position of the substring is determined by POSITION(',' IN aired) + 2, and it goes until the end of the string. This effectively removes the part of the string that comes before and including the first comma.\n\nIn summary, the entire expression is extracting a substring from the original string aired, starting from two positions to the right of the first comma and continuing until the end of the string. This can be useful in scenarios where you want to remove or isolate part of a string based on the position of a specific character (in this case, the comma).\n\n\n\n\nSELECT * FROM episodes_date LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nsid\n\n\nepid\n\n\naired\n\n\nepno\n\n\nyear\n\n\n\n\n\n\n46\n\n\n20210410\n\n\nApril 10, 2021\n\n\n17\n\n\n2021\n\n\n\n\n46\n\n\n20210403\n\n\nApril 3, 2021\n\n\n16\n\n\n2021\n\n\n\n\n46\n\n\n20210327\n\n\nMarch 27, 2021\n\n\n15\n\n\n2021\n\n\n\n\n46\n\n\n20210227\n\n\nFebruary 27, 2021\n\n\n14\n\n\n2021\n\n\n\n\n46\n\n\n20210220\n\n\nFebruary 20, 2021\n\n\n13\n\n\n2021\n\n\n\n\n46\n\n\n20210213\n\n\nFebruary 13, 2021\n\n\n12\n\n\n2021\n\n\n\n\n46\n\n\n20210206\n\n\nFebruary 6, 2021\n\n\n11\n\n\n2021\n\n\n\n\n46\n\n\n20210130\n\n\nJanuary 30, 2021\n\n\n10\n\n\n2021\n\n\n\n\n46\n\n\n20201219\n\n\nDecember 19, 2020\n\n\n9\n\n\n2020\n\n\n\n\n46\n\n\n20201212\n\n\nDecember 12, 2020\n\n\n8\n\n\n2020\n\n\n\n\n\n\n\n\n\n\nNow that the year variable has been created in the new temporary table called episodes_date, we can use episode_date to query and find, for example, all of the hosts in 2019.\n\nSELECT hosts.aid, ep.aired, ep.year FROM hosts \nJOIN episodes_date AS ep ON hosts.epid = ep.epid\nWHERE year = 2019\nLIMIT 25;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\naid\n\n\naired\n\n\nyear\n\n\n\n\n\n\nEddie Murphy\n\n\nDecember 21, 2019\n\n\n2019\n\n\n\n\nScarlett Johansson\n\n\nDecember 14, 2019\n\n\n2019\n\n\n\n\nJennifer Lopez\n\n\nDecember 7, 2019\n\n\n2019\n\n\n\n\nWill Ferrell\n\n\nNovember 23, 2019\n\n\n2019\n\n\n\n\nHarry Styles\n\n\nNovember 16, 2019\n\n\n2019\n\n\n\n\nKristen Stewart\n\n\nNovember 2, 2019\n\n\n2019\n\n\n\n\nChance the Rapper\n\n\nOctober 26, 2019\n\n\n2019\n\n\n\n\nDavid Harbour\n\n\nOctober 12, 2019\n\n\n2019\n\n\n\n\nPhoebe Waller-Bridge\n\n\nOctober 5, 2019\n\n\n2019\n\n\n\n\nWoody Harrelson\n\n\nSeptember 28, 2019\n\n\n2019\n\n\n\n\n\n\n\n\n\n\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_duckdb, shutdown = TRUE)"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#duckdb",
    "href": "slides/2024-01-17-editing-db.html#duckdb",
    "title": "Editing Databases",
    "section": "",
    "text": "DuckDB\n\nin-process database management system that runs entirely on your own computer.\nthe data live in your storage (instead of your memory).\nyou don’t have to transfer queries or results over the internet."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#duckdb-caveat",
    "href": "slides/2024-01-17-editing-db.html#duckdb-caveat",
    "title": "Editing Databases",
    "section": "DuckDB caveat",
    "text": "DuckDB caveat\n\nthe SQL dialect used in DuckDB is slightly different from MySQL\nwrite SELECT * FROM table 10; instead of SELECT * FROM table 0, 10;\nlots of different dialects, depending on the SQL server. Always be aware of the dialect you are using."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#duckdb-via-r",
    "href": "slides/2024-01-17-editing-db.html#duckdb-via-r",
    "title": "Editing Databases",
    "section": "DuckDB via R",
    "text": "DuckDB via R\n\ninstall.packages(\"duckdb\")  # only once, in the Console, not in the .qmd or .Rmd file\nlibrary(duckdb)             # at the top of the .qmd or .Rmd file\n\nlibrary(DBI)                # we also still need the DBI package\n\n\ncon_duckdb &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"duck_datab\")\n\n\nthe database has been stored to a database directory called duck_datab which lives in the current R project.\ncan’t open it like a standard folder, but it is where DuckDB stores the database files."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#preparing-to-load-data",
    "href": "slides/2024-01-17-editing-db.html#preparing-to-load-data",
    "title": "Editing Databases",
    "section": "Preparing to load data",
    "text": "Preparing to load data\nThe duckdb database is currently empty, so we need to load in some data. The duckdb_read_csv() function in the duckdb R package allows us to load the .csv file (available on GitHub) directly into the database without being loaded as an R object first.\nRecall that in ?@tbl-select-describe we used DESCRIBE to display the variable types of the database table(s). The list includes the variable name (Field), its Type, whether there are NULL values allowed, and whether there are keys or indices defined on the variable. See Table 2 for the DESCRIBE output on the table we are about to import.\nUnlike R, when creating a new data table, SQL requires that you communicate each future variable (column) and that variable’s type. Variable types are not automatically generated!"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#saturday-night-live",
    "href": "slides/2024-01-17-editing-db.html#saturday-night-live",
    "title": "Editing Databases",
    "section": "Saturday Night Live",
    "text": "Saturday Night Live\n\nFigure 1: image credit: NBCConsider the Saturday Night Live datasets available on the snldb GitHub repo."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#casts-table",
    "href": "slides/2024-01-17-editing-db.html#casts-table",
    "title": "Editing Databases",
    "section": "casts table",
    "text": "casts table\nUse R to understand the data from casts.csv.\n\ncasts &lt;- readr::read_csv(\"https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv\")\nglimpse(casts)\n\nRows: 614\nColumns: 8\n$ aid             &lt;chr&gt; \"A. Whitney Brown\", \"A. Whitney Brown\", \"A. Whitney Br…\n$ sid             &lt;dbl&gt; 11, 12, 13, 14, 15, 16, 5, 39, 40, 41, 42, 45, 46, 21,…\n$ featured        &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ first_epid      &lt;dbl&gt; 19860222, NA, NA, NA, NA, NA, 19800409, 20140118, NA, …\n$ last_epid       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ update_anchor   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ n_episodes      &lt;dbl&gt; 8, 20, 13, 20, 20, 20, 5, 11, 21, 21, 21, 18, 17, 20, …\n$ season_fraction &lt;dbl&gt; 0.444, 1.000, 1.000, 1.000, 1.000, 1.000, 0.250, 0.524…"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#loading-data",
    "href": "slides/2024-01-17-editing-db.html#loading-data",
    "title": "Editing Databases",
    "section": "Loading data",
    "text": "Loading data\nImporting .csv files as tables, a series of steps:1\n\na USE statement that ensures we are in the right schema/database.\na series of DROP TABLE statements that drop any old tables with the same names as the ones we are going to create.\na series of CREATE TABLE statements that specify the table structures.\na series of COPY statements that read the data from the .csv files into the appropriate tables."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#loading-step-1-use",
    "href": "slides/2024-01-17-editing-db.html#loading-step-1-use",
    "title": "Editing Databases",
    "section": "Loading step 1, USE",
    "text": "Loading step 1, USE\nUse the (local) database that we’ve called duck_datab.\n\n```{sql}\n#| connection: con_duckdb\n\nUSE duck_datab;\n```"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#loading-step-2-refresh",
    "href": "slides/2024-01-17-editing-db.html#loading-step-2-refresh",
    "title": "Editing Databases",
    "section": "Loading step 2, refresh",
    "text": "Loading step 2, refresh\nMake sure to “refresh” the table, in case it already exists. However, be very careful with the DROP TABLE statement, as it removes the casts table.\n\nDROP TABLE IF EXISTS casts;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#loading-step-3-create-table",
    "href": "slides/2024-01-17-editing-db.html#loading-step-3-create-table",
    "title": "Editing Databases",
    "section": "Loading step 3, CREATE TABLE",
    "text": "Loading step 3, CREATE TABLE\nCarefully define the variable types, whether or not they allow missing values, and what a default value is for that variable. Additionally, identify the key for accessing information.\n\nCREATE TABLE casts (\n  aid VARCHAR(255) NOT NULL DEFAULT '',\n  sid INTEGER NOT NULL DEFAULT 0,\n  featured BOOLEAN NOT NULL DEFAULT 'false',\n  first_epid INTEGER DEFAULT 0,\n  last_epid INTEGER DEFAULT 0,\n  update_anchor BOOLEAN NOT NULL DEFAULT 0,\n  n_episodes INTEGER NOT NULL DEFAULT 0,\n  season_fraction DECIMAL(21,20) NOT NULL DEFAULT 0,\n  PRIMARY KEY (sid, aid)\n);"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#loading-step-4-copy",
    "href": "slides/2024-01-17-editing-db.html#loading-step-4-copy",
    "title": "Editing Databases",
    "section": "Loading step 4, COPY",
    "text": "Loading step 4, COPY\nThe .csv file lives on my computer, so I load it in directly. [n.b., the statement to load in data is different in MySQL.]\n\nCOPY casts FROM 'data/casts.csv' HEADER;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#checking-the-loading-select",
    "href": "slides/2024-01-17-editing-db.html#checking-the-loading-select",
    "title": "Editing Databases",
    "section": "Checking the loading, SELECT",
    "text": "Checking the loading, SELECT\n\nSELECT * FROM casts LIMIT 8;\n\n\n\n\n\nTable 1: After CREATE TABLE where variable types are set, the COPY command pulls the data into the table. SELECT shows us that the table is as expected.\n\n\naid\nsid\nfeatured\nfirst_epid\nlast_epid\nupdate_anchor\nn_episodes\nseason_fraction\n\n\n\n\nA. Whitney Brown\n11\nTRUE\n19860222\n\nFALSE\n8\n0.444\n\n\nA. Whitney Brown\n12\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n13\nTRUE\n\n\nFALSE\n13\n1.000\n\n\nA. Whitney Brown\n14\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n15\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n16\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nAlan Zweibel\n5\nTRUE\n19800409\n\nFALSE\n5\n0.250\n\n\nSasheer Zamata\n39\nTRUE\n20140118\n\nFALSE\n11\n0.524"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#check-the-database",
    "href": "slides/2024-01-17-editing-db.html#check-the-database",
    "title": "Editing Databases",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nSHOW DATABASES;\n\n\n\n\n1 records\n\n\n\n\ndatabase_name\n\n\n\n\n\n\nduck_datab"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#check-the-database-1",
    "href": "slides/2024-01-17-editing-db.html#check-the-database-1",
    "title": "Editing Databases",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nSHOW TABLES;\n\n\n\n\n1 records\n\n\n\n\nname\n\n\n\n\n\n\ncasts"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#check-the-database-2",
    "href": "slides/2024-01-17-editing-db.html#check-the-database-2",
    "title": "Editing Databases",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nDESCRIBE casts;\n\n\n\n\n\nTable 2: DESCRIBE variables in the casts table.\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\naid\nVARCHAR\nNO\nPRI\n''\n\n\n\nsid\nINTEGER\nNO\nPRI\n0\n\n\n\nfeatured\nBOOLEAN\nNO\n\n'false'\n\n\n\nfirst_epid\nINTEGER\nYES\n\n0\n\n\n\nlast_epid\nINTEGER\nYES\n\n0\n\n\n\nupdate_anchor\nBOOLEAN\nNO\n\n0\n\n\n\nn_episodes\nINTEGER\nNO\n\n0\n\n\n\nseason_fraction\nDECIMAL(21,20)\nNO\n\n0"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#efficiencies",
    "href": "slides/2024-01-17-editing-db.html#efficiencies",
    "title": "Editing Databases",
    "section": "Efficiencies",
    "text": "Efficiencies\nIt is worth pointing out a few aspects to loading data into SQL: keys, indices, and partitioning."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#key",
    "href": "slides/2024-01-17-editing-db.html#key",
    "title": "Editing Databases",
    "section": "Key",
    "text": "Key\nKeys are unique identifiers for each row, used primarily for connecting tables. Keys are generally not helpful for efficiency, but they are important for data integrity and relationships between tables.\n\nPRIMARY KEY is a column or set of columns that uniquely identify each row. Primary keys cannot be NULL.\nFOREIGN KEY is a column or set of columns that reference a primary key in a different table. A foreign key can be NULL."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#index",
    "href": "slides/2024-01-17-editing-db.html#index",
    "title": "Editing Databases",
    "section": "Index",
    "text": "Index\nIndices are the crux of why SQL is so much more efficient than, say, R. An index is a lookup table that helps SQL keep track of which records contain certain values. By indexing the rows, SQL is able to optimize sorting and joining tables. The index is created in advance (when the table is created) and saved to disk, which can take up substantial space on the disk. Sometimes more than one variable is used to index the table. There are trade-offs to having a lot of indices (disk space but fast wrangling) versus a few indices (slow wrangling but less space)."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#find-keys-and-indices",
    "href": "slides/2024-01-17-editing-db.html#find-keys-and-indices",
    "title": "Editing Databases",
    "section": "Find keys and indices",
    "text": "Find keys and indices\nIn MySQL the commands SHOW KEYS and SHOW INDEXES provide information about the keys and indices for each table."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#partitioning",
    "href": "slides/2024-01-17-editing-db.html#partitioning",
    "title": "Editing Databases",
    "section": "Partitioning",
    "text": "Partitioning\nAnother way to speed up query retrievals is to partition the data tables. If, for example, the SNL queries were always done by year, then the episodes table could be partitioned such that they are stored as separate tables (one per year). The partitioning functions as an index on year. The user would not be able to tell the difference between the unpartitioned episodes table and the partitioned one. Queries done by year would be faster. Queries done grouped in another way would be slower."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#best-practice",
    "href": "slides/2024-01-17-editing-db.html#best-practice",
    "title": "Editing Databases",
    "section": "Best practice",
    "text": "Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_duckdb, shutdown = TRUE)"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#footnotes",
    "href": "slides/2024-01-17-editing-db.html#footnotes",
    "title": "Editing Databases",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ntaken from MDSR.↩︎"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24_sol.html",
    "href": "handout/lab5_creating_db_sds261_j24_sol.html",
    "title": "Lab 5 - creating databases",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(mdsr)\nToday’s lab will provide practice working with creating SQL databases using DuckDB.\nThe goals for lab 5 include:"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab5_creating_db_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "title": "Lab 5 - creating databases",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .qmd file) which problem is being answered with which code. A sentence or two with each response goes a long way toward your understanding!\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe .qmd document should be saved in the R Project as lab5-sds261-yourlastname-yourfirstname.qmd.\nSet up a connection to a database of your naming using DuckDB.\n\n\ncon_college &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"you_name_the_db\")"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24_sol.html#assignment",
    "href": "handout/lab5_creating_db_sds261_j24_sol.html#assignment",
    "title": "Lab 5 - creating databases",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncon_college &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"collegeDB\")\n\n\n\n\nThe data we will work with today is on college tuition, pay, and diversity. The original data source is the US Department of Education, but it has been compiled as part of TidyTuesday on March 10, 2020. Tuition and fees are for 2018-19. Diversity is for 2014.\n\nDownload the data onto your own computer. In the interest of time, let’s only use three tables: tuition_cost and salary_potential and diversity_school.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntuition_cost &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-10/tuition_cost.csv')\n\nsalary_potential &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-10/salary_potential.csv')\n\ndiversity_school &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-10/diversity_school.csv')\n\n\n\n\n\nFollow the first two steps in the notes: USE and DROP TABLE.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nUSE collegeDB;\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDROP TABLE IF EXISTS salary;\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDROP TABLE IF EXISTS diversity;\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDROP TABLE IF EXISTS tuition;\n\n\n\n\n\nFor each of the three tables, in the CREATE TABLE operation, carefully define variable types and identify any key variables. Unfortunately, FOREIGN KEYs don’t work here because there is not referential integrity across the tables.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCREATE TABLE tuition (\n  name VARCHAR(255) NOT NULL DEFAULT '',\n  state VARCHAR(255),\n  state_code VARCHAR(255),\n  type VARCHAR(255),\n  degree_length VARCHAR(255),\n  room_and_board VARCHAR(255),\n  in_state_tuition DOUBLE,\n  in_state_total DOUBLE,\n  out_of_state_tuition DOUBLE,\n  out_of_state_total DOUBLE,\n  PRIMARY KEY (name, state)\n);\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCREATE TABLE salary (\n  rank DOUBLE,\n  name VARCHAR(255),\n  state_name VARCHAR(255),\n  early_career_pay DOUBLE,\n  mid_career_pay DOUBLE,\n  make_world_better_percent VARCHAR(255),\n  stem_percent DOUBLE\n);\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCREATE TABLE diversity (\n  name VARCHAR(255),\n  total_enrollment DOUBLE,\n  state VARCHAR(255),\n  category VARCHAR(255),\n  enrollment DOUBLE\n);\n\n\n\n\n\nUse COPY to load the data from your computer. (Hint: if there is an NA value, SQL doesn’t know that it is actually NULL and wants the variable to be loaded as a character string.)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCOPY tuition FROM 'data/tuition_cost.csv' HEADER;\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCOPY salary FROM 'data/salary_potential.csv' HEADER;\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCOPY diversity FROM 'data/diversity_school.csv' HEADER;\n\n\n\n\n\nUse SELECT * (with a LIMIT!) to make sure all three tables loaded correctly.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM tuition LIMIT 10;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nstate\nstate_code\ntype\ndegree_length\nroom_and_board\nin_state_tuition\nin_state_total\nout_of_state_tuition\nout_of_state_total\n\n\n\n\nAaniiih Nakoda College\nMontana\nMT\nPublic\n2 Year\nNA\n2380\n2380\n2380\n2380\n\n\nAbilene Christian University\nTexas\nTX\nPrivate\n4 Year\n10350\n34850\n45200\n34850\n45200\n\n\nAbraham Baldwin Agricultural College\nGeorgia\nGA\nPublic\n2 Year\n8474\n4128\n12602\n12550\n21024\n\n\nAcademy College\nMinnesota\nMN\nFor Profit\n2 Year\nNA\n17661\n17661\n17661\n17661\n\n\nAcademy of Art University\nCalifornia\nCA\nFor Profit\n4 Year\n16648\n27810\n44458\n27810\n44458\n\n\nAdams State University\nColorado\nCO\nPublic\n4 Year\n8782\n9440\n18222\n20456\n29238\n\n\nAdelphi University\nNew York\nNY\nPrivate\n4 Year\n16030\n38660\n54690\n38660\n54690\n\n\nAdirondack Community College\nNew York\nNY\nPublic\n2 Year\n11660\n5375\n17035\n9935\n21595\n\n\nAdrian College\nMichigan\nMI\nPrivate\n4 Year\n11318\n37087\n48405\n37087\n48405\n\n\nAdvanced Technology Institute\nVirginia\nVA\nFor Profit\n2 Year\nNA\n13680\n13680\n13680\n13680\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM salary LIMIT 10;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\nrank\nname\nstate_name\nearly_career_pay\nmid_career_pay\nmake_world_better_percent\nstem_percent\n\n\n\n\n1\nAuburn University\nAlabama\n54400\n104500\n51\n31\n\n\n2\nUniversity of Alabama in Huntsville\nAlabama\n57500\n103900\n59\n45\n\n\n3\nThe University of Alabama\nAlabama\n52300\n97400\n50\n15\n\n\n4\nTuskegee University\nAlabama\n54500\n93500\n61\n30\n\n\n5\nSamford University\nAlabama\n48400\n90500\n52\n3\n\n\n6\nSpring Hill College\nAlabama\n46600\n89100\n53\n12\n\n\n7\nBirmingham Southern College\nAlabama\n49100\n88300\n48\n27\n\n\n8\nUniversity of Alabama at Birmingham\nAlabama\n48600\n87200\n57\n17\n\n\n9\nUniversity of South Alabama\nAlabama\n47700\n86400\n56\n17\n\n\n10\nAlabama A&M University\nAlabama\n48700\n83500\n58\n20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM diversity LIMIT 10;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nname\ntotal_enrollment\nstate\ncategory\nenrollment\n\n\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nWomen\n134722\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nAmerican Indian / Alaska Native\n876\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nAsian\n1959\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nBlack\n31455\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nHispanic\n13984\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nNative Hawaiian / Pacific Islander\n1019\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nWhite\n58209\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nTwo Or More Races\n19039\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nUnknown\n65163\n\n\nUniversity of Phoenix-Arizona\n195059\nArizona\nNon-Resident Foreign\n3355\n\n\n\n\n\n\n\n\n\nAdd an INDEX to the tuition table on state. We won’t discuss until Thursday, but state is better than state_code because state allows you to join with other tables. state is better than type or degree_length because state has a much higher cardinality.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCREATE INDEX state_idx ON tuition (state);"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24.html",
    "href": "handout/lab6_editing_db_sds261_j24.html",
    "title": "Lab 6 - editing databases",
    "section": "",
    "text": "Today’s lab will provide practice working with editing SQL databases using DuckDB.\nThe goals for lab 6 include:"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab6_editing_db_sds261_j24.html#advice-for-turning-in-the-assignment",
    "title": "Lab 6 - editing databases",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .qmd file) which problem is being answered with which code. A sentence or two with each response goes a long way toward your understanding!\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe .qmd document should be saved in the R Project as lab6-sds261-yourlastname-yourfirstname.qmd.\nSet up a connection to a database of your naming using DuckDB.\n\n\ncon_college &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"samenameaslab5\")"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24.html#assignment",
    "href": "handout/lab6_editing_db_sds261_j24.html#assignment",
    "title": "Lab 6 - editing databases",
    "section": "Assignment",
    "text": "Assignment\nThe data we will work with today is on college tuition, pay, and diversity. The original data source is the US Department of Education, but it has been compiled as part of TidyTuesday on March 10, 2020. Tuition and fees are for 2018-19. Diversity is for 2014.\n\nUse the same database from Lab 5. If the database somehow got deleted or corrupted, go back and re-run your code from Lab 5.\n\n\nUse UPDATE to change the NA values to NULL (for room_and_board in the tuition table and make_world_better_percent in the salary table). (Originally I had a follow up task to convert the data type from VARCHAR to DOUBLE as well. However, DuckDB is particularly finicky with those conversions, and so we aren’t going to do it. If/when you work on a SQL server, you might adjust the data type using something like: ALTER TABLE tuition MODIFY room_and_board DOUBLE;.)1\n\n\nUsing INSERT INTO add records to the diversity table. Add ‘Barden University’ in ‘Louisiana’ that has a total enrollment of 10,000 students, half of whom are female. Add an additional value to indicate, if the Bellas are representative of the student population, that Barden University has 1667 Black students.\n\n\n\nCheck to see that the values inserted into the diversity table are correct. In order to tell, use a SELECT clause where you only look at schools from ‘Louisiana’ and sort by the name of the school.\n\n\nUsing the diversty table, DELETE all the records that don’t record race or ethnicity. That is, delete the records that have a category of ‘Total Minority’, ‘Women’, or ‘Non-Resident Foreign’. Again, use a SELECT command to confirm that your code worked.\n\n\nUse ALTER TABLE to change the variable type of make_world_better_percent in the salary table from VARCHAR to DOUBLE. Follow up by running DESCRIBE on the salary table to make sure your change worked. (Note: for some reason, the same code doesn’t seem to work on the tuition table with room_and_board. It says that tuition depends on something. You are welcome to try to make it work on your own computers!)\n\n\nCreate a temporary table (e.g., to use in a follow up SELECT query) that contains only the ‘Private’ universities from the tuition table.\n\n\nCreate a temporary table consisting of the JOIN of all three tables but including only the Smith College data."
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24.html#footnotes",
    "href": "handout/lab6_editing_db_sds261_j24.html#footnotes",
    "title": "Lab 6 - editing databases",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo change the data type only during a query, use SELECT CAST(room_and_board AS DOUBLE) FROM tuition.↩︎"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24_sol.html",
    "href": "handout/lab6_editing_db_sds261_j24_sol.html",
    "title": "Lab 6 - editing databases",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dbplyr)\nlibrary(mdsr)\nToday’s lab will provide practice working with editing SQL databases using DuckDB.\nThe goals for lab 6 include:"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "href": "handout/lab6_editing_db_sds261_j24_sol.html#advice-for-turning-in-the-assignment",
    "title": "Lab 6 - editing databases",
    "section": "Advice for turning in the assignment",
    "text": "Advice for turning in the assignment\n\nBe sure to indicate (in the .qmd file) which problem is being answered with which code. A sentence or two with each response goes a long way toward your understanding!\nsave the .Rproj file somewhere you can find it. Don’t keep everything in your downloads folder. Maybe make a folder called SDS261 or something. That folder could live on your Desktop. Or maybe in your Dropbox.\nThe .qmd document should be saved in the R Project as lab6-sds261-yourlastname-yourfirstname.qmd.\nSet up a connection to a database of your naming using DuckDB.\n\n\ncon_college &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"samenameaslab5\")"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24_sol.html#assignment",
    "href": "handout/lab6_editing_db_sds261_j24_sol.html#assignment",
    "title": "Lab 6 - editing databases",
    "section": "Assignment",
    "text": "Assignment\nThe data we will work with today is on college tuition, pay, and diversity. The original data source is the US Department of Education, but it has been compiled as part of TidyTuesday on March 10, 2020. Tuition and fees are for 2018-19. Diversity is for 2014.\n\nUse the same database from Lab 5. If the database somehow got deleted or corrupted, go back and re-run your code from Lab 5.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncon_college &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"collegeDB\")\n\n\n\n\n\nUse UPDATE to change the NA values to NULL (for room_and_board in the tuition table and make_world_better_percent in the salary table). (Originally I had a follow up task to convert the data type from VARCHAR to DOUBLE as well. However, DuckDB is particularly finicky with those conversions, and so we aren’t going to do it. If/when you work on a SQL server, you might adjust the data type using something like: ALTER TABLE tuition MODIFY room_and_board DOUBLE;.)1\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) AS number_null\nFROM tuition\nWHERE room_and_board IS NULL;\n\n\n1 records\n\n\nnumber_null\n\n\n\n\n1094\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nUPDATE tuition\nSET room_and_board = NULL\nWHERE room_and_board = 'NA'\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) AS number_null\nFROM tuition\nWHERE room_and_board IS NULL;\n\n\n1 records\n\n\nnumber_null\n\n\n\n\n1094\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM tuition LIMIT 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nstate\nstate_code\ntype\ndegree_length\nroom_and_board\nin_state_tuition\nin_state_total\nout_of_state_tuition\nout_of_state_total\n\n\n\n\nAaniiih Nakoda College\nMontana\nMT\nPublic\n2 Year\nNA\n2380\n2380\n2380\n2380\n\n\nAbilene Christian University\nTexas\nTX\nPrivate\n4 Year\n10350\n34850\n45200\n34850\n45200\n\n\nAbraham Baldwin Agricultural College\nGeorgia\nGA\nPublic\n2 Year\n8474\n4128\n12602\n12550\n21024\n\n\nAcademy College\nMinnesota\nMN\nFor Profit\n2 Year\nNA\n17661\n17661\n17661\n17661\n\n\nAcademy of Art University\nCalifornia\nCA\nFor Profit\n4 Year\n16648\n27810\n44458\n27810\n44458\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) AS number_null\nFROM salary\nWHERE make_world_better_percent IS NULL;\n\n\n1 records\n\n\nnumber_null\n\n\n\n\n33\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nUPDATE salary\nSET make_world_better_percent = NULL\nWHERE make_world_better_percent = 'NA'\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT COUNT(*) AS number_null\nFROM salary\nWHERE make_world_better_percent IS NULL;\n\n\n1 records\n\n\nnumber_null\n\n\n\n\n33\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM salary LIMIT 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\nrank\nname\nstate_name\nearly_career_pay\nmid_career_pay\nmake_world_better_percent\nstem_percent\n\n\n\n\n1\nAuburn University\nAlabama\n54400\n104500\n51\n31\n\n\n2\nUniversity of Alabama in Huntsville\nAlabama\n57500\n103900\n59\n45\n\n\n3\nThe University of Alabama\nAlabama\n52300\n97400\n50\n15\n\n\n4\nTuskegee University\nAlabama\n54500\n93500\n61\n30\n\n\n5\nSamford University\nAlabama\n48400\n90500\n52\n3\n\n\n\n\n\n\n\n\n\nUsing INSERT INTO add records to the diversity table. Add ‘Barden University’ in ‘Louisiana’ that has a total enrollment of 10,000 students, half of whom are female. Add an additional value to indicate, if the Bellas are representative of the student population, that Barden University has 1667 Black students.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nINSERT INTO diversity (name, total_enrollment, state, category, enrollment)\n   VALUES('Barden University', 10000, 'Louisiana', 'Women', 5000),\n         ('Barden University', 10000, 'Louisiana', 'Black', 1667);\n\n\n\n\n\nCheck to see that the values inserted into the diversity table are correct. In order to tell, use a SELECT clause where you only look at schools from ‘Louisiana’ and sort by the name of the school.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM diversity\nWHERE state = 'Louisiana'\nORDER BY name\nLIMIT 50;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nname\ntotal_enrollment\nstate\ncategory\nenrollment\n\n\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBarden University\n10000\nLouisiana\nWomen\n5000\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBaton Rouge Community College\n7740\nLouisiana\nUnknown\n633\n\n\nBaton Rouge Community College\n7740\nLouisiana\nAmerican Indian / Alaska Native\n24\n\n\nBaton Rouge Community College\n7740\nLouisiana\nAsian\n149\n\n\nBaton Rouge Community College\n7740\nLouisiana\nBlack\n3263\n\n\nBaton Rouge Community College\n7740\nLouisiana\nHispanic\n241\n\n\n\n\n\n\n\n\n\nUsing the diversty table, DELETE all the records that don’t record race or ethnicity. That is, delete the records that have a category of ‘Total Minority’, ‘Women’, or ‘Non-Resident Foreign’. Again, use a SELECT command to confirm that your code worked.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDELETE FROM diversity\nWHERE category = 'Total Minority' OR category = 'Women' OR category = 'Non-Resident Foreign'\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM diversity\nWHERE state = 'Louisiana'\nORDER BY name\nLIMIT 50;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nname\ntotal_enrollment\nstate\ncategory\nenrollment\n\n\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBarden University\n10000\nLouisiana\nBlack\n1667\n\n\nBaton Rouge Community College\n7740\nLouisiana\nUnknown\n633\n\n\nBaton Rouge Community College\n7740\nLouisiana\nAmerican Indian / Alaska Native\n24\n\n\nBaton Rouge Community College\n7740\nLouisiana\nAsian\n149\n\n\nBaton Rouge Community College\n7740\nLouisiana\nBlack\n3263\n\n\nBaton Rouge Community College\n7740\nLouisiana\nHispanic\n241\n\n\nBaton Rouge Community College\n7740\nLouisiana\nNative Hawaiian / Pacific Islander\n12\n\n\n\n\n\n\n\n\n\nUse ALTER TABLE to change the variable type of make_world_better_percent in the salary table from VARCHAR to DOUBLE. Follow up by running DESCRIBE on the salary table to make sure your change worked. (Note: for some reason, the same code doesn’t seem to work on the tuition table with room_and_board. It says that tuition depends on something. You are welcome to try to make it work on your own computers!)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nALTER TABLE salary ALTER make_world_better_percent TYPE DOUBLE;\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDESCRIBE salary;\n\n\n7 records\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\nrank\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nname\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nstate_name\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nearly_career_pay\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nmid_career_pay\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nmake_world_better_percent\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nstem_percent\nDOUBLE\nYES\nNA\nNA\nNA\n\n\n\n\n\n\n\n\n\nCreate a temporary table (e.g., to use in a follow up SELECT query) that contains only the ‘Private’ universities from the tuition table.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCREATE TEMP TABLE tuition_private AS\n    SELECT * FROM tuition WHERE type = 'Private';\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM tuition_private LIMIT 10;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nstate\nstate_code\ntype\ndegree_length\nroom_and_board\nin_state_tuition\nin_state_total\nout_of_state_tuition\nout_of_state_total\n\n\n\n\nAbilene Christian University\nTexas\nTX\nPrivate\n4 Year\n10350\n34850\n45200\n34850\n45200\n\n\nAdelphi University\nNew York\nNY\nPrivate\n4 Year\n16030\n38660\n54690\n38660\n54690\n\n\nAdrian College\nMichigan\nMI\nPrivate\n4 Year\n11318\n37087\n48405\n37087\n48405\n\n\nAdventist University of Health Sciences\nFlorida\nFL\nPrivate\n4 Year\n4200\n15150\n19350\n15150\n19350\n\n\nAgnes Scott College\nGeorgia\nGA\nPrivate\n4 Year\n12330\n41160\n53490\n41160\n53490\n\n\nAlaska Bible College\nAlaska\nAK\nPrivate\n4 Year\n5700\n9300\n15000\n9300\n15000\n\n\nAlaska Pacific University\nAlaska\nAK\nPrivate\n4 Year\n7300\n20830\n28130\n20830\n28130\n\n\nAlbany College of Pharmacy and Health Sciences\nNew York\nNY\nPrivate\n4 Year\n10920\n35105\n46025\n35105\n46025\n\n\nAlbertus Magnus College\nConnecticut\nCT\nPrivate\n4 Year\n13200\n32060\n45260\n32060\n45260\n\n\nAlbion College\nMichigan\nMI\nPrivate\n4 Year\n12380\n45775\n58155\n45775\n58155\n\n\n\n\n\n\n\n\n\nCreate a temporary table consisting of the JOIN of all three tables but including only the Smith College data.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nCREATE TEMP TABLE smith_data AS\nSELECT tuition.name, category, enrollment, type, \n       degree_length, room_and_board,\n       in_state_tuition, out_of_state_tuition, in_state_total,\n       out_of_state_total, early_career_pay, mid_career_pay,\n       make_world_better_percent, stem_percent,\n       total_enrollment\nFROM tuition\nJOIN salary ON tuition.name = salary.name\nJOIN diversity ON tuition.name = diversity.name\nWHERE tuition.name = 'Smith College'\nLIMIT 20;\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSELECT * FROM smith_data;\n\n\n8 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ncategory\nenrollment\ntype\ndegree_length\nroom_and_board\nin_state_tuition\nout_of_state_tuition\nin_state_total\nout_of_state_total\nearly_career_pay\nmid_career_pay\nmake_world_better_percent\nstem_percent\ntotal_enrollment\n\n\n\n\nSmith College\nAmerican Indian / Alaska Native\n5\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989\n\n\nSmith College\nAsian\n348\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989\n\n\nSmith College\nBlack\n149\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989\n\n\nSmith College\nHispanic\n276\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989\n\n\nSmith College\nNative Hawaiian / Pacific Islander\n2\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989\n\n\nSmith College\nWhite\n1447\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989\n\n\nSmith College\nTwo Or More Races\n128\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989\n\n\nSmith College\nUnknown\n246\nPrivate\n4 Year\n17520\n52404\n52404\n69924\n69924\n52700\n98200\n51\n26\n2989"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24_sol.html#footnotes",
    "href": "handout/lab6_editing_db_sds261_j24_sol.html#footnotes",
    "title": "Lab 6 - editing databases",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo change the data type only during a query, use SELECT CAST(room_and_board AS DOUBLE) FROM tuition.↩︎"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#data-types",
    "href": "slides/2024-01-16-creating-db.html#data-types",
    "title": "Creating Databases",
    "section": "Data types",
    "text": "Data types\n\nNumbers: INTEGER, SMALLINT, NUMERIC, DECIMAL, DOUBLE(precision, scale) precision = # sig digits, scale = # digits the follow decimal.\nString: CHAR, VARCHAR, BINARY, TEXT\nDate: DATE, TIME, DATETIME, TIMESTAMP, YEAR\nBoolean: SMALLINT(1) in MySQL, BOOLEAN in DuckDB"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#check-constraints",
    "href": "slides/2024-01-16-creating-db.html#check-constraints",
    "title": "Creating Databases",
    "section": "CHECK constraints",
    "text": "CHECK constraints\nViolation will result in an error.\n\nCREATE TABLE CountryListCensus (\n    Id INT,\n    CountryName VARCHAR(255) NOT NULL,\n    CountryPopulation INT CHECK(CountryPopulation &gt; 0),\n    LastCensus DATE,\n    NextCensus DATE,\n    CHECK(LastCensus&lt;NextCensus),\n    PRIMARY KEY (Id)\n);"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#creating-keys",
    "href": "slides/2024-01-16-creating-db.html#creating-keys",
    "title": "Creating Databases",
    "section": "Creating KEYs",
    "text": "Creating KEYs\n\nCREATE TABLE table1 (\n  col1 ...,\n  col2 ...,\n  col3 ...,\n  PRIMARY KEY col1,\n  FOREIGN KEY col2 REFERENCES table2(table2col1)\n);\n\nEither or both of the KEYs could be multiple columns.\n\nCREATE TABLE table1 (\n  col1 ...,\n  col2 ...,\n  col3 ...,\n  PRIMARY KEY (col1, col3),\n  FOREIGN KEY (col1, col2) REFERENCES table2(table2col1, table2col4)\n);"
  },
  {
    "objectID": "slides/2024-01-16-creating-db.html#creating-indexes",
    "href": "slides/2024-01-16-creating-db.html#creating-indexes",
    "title": "Creating Databases",
    "section": "Creating INDEXes",
    "text": "Creating INDEXes\nIndexes can be created on one or more variable. A table does not need to have an INDEX (or a KEY).\n\nCREATE INDEX name_of_index ON table (col1);\n\n\nCREATE INDEX name_of_index ON table (col1, col2);"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html",
    "href": "slides/2024-01-18-db-etc.html",
    "title": "SQL Extras",
    "section": "",
    "text": "DuckDB\n\nin-process database management system that runs entirely on your own computer.\nthe data live in your storage (instead of your memory).\nyou don’t have to transfer queries or results over the internet."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#duckdb",
    "href": "slides/2024-01-18-db-etc.html#duckdb",
    "title": "SQL Extras",
    "section": "",
    "text": "DuckDB\n\nin-process database management system that runs entirely on your own computer.\nthe data live in your storage (instead of your memory).\nyou don’t have to transfer queries or results over the internet."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#duckdb-caveat",
    "href": "slides/2024-01-18-db-etc.html#duckdb-caveat",
    "title": "SQL Extras",
    "section": "DuckDB caveat",
    "text": "DuckDB caveat\n\nthe SQL dialect used in DuckDB is slightly different from MySQL\nwrite SELECT * FROM table 10; instead of SELECT * FROM table 0, 10;\nlots of different dialects, depending on the SQL server. Always be aware of the dialect you are using."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#duckdb-via-r",
    "href": "slides/2024-01-18-db-etc.html#duckdb-via-r",
    "title": "SQL Extras",
    "section": "DuckDB via R",
    "text": "DuckDB via R\n\ninstall.packages(\"duckdb\")  # only once, in the Console, not in the .qmd or .Rmd file\nlibrary(duckdb)             # at the top of the .qmd or .Rmd file\n\nlibrary(DBI)                # we also still need the DBI package\n\n\ncon_duckdb &lt;- DBI::dbConnect(duckdb::duckdb(),\n                             dbdir = \"duck_datab\")\n\n\nthe database has been stored to a database directory called duck_datab which lives in the current R project.\ncan’t open it like a standard folder, but it is where DuckDB stores the database files."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#preparing-to-load-data",
    "href": "slides/2024-01-18-db-etc.html#preparing-to-load-data",
    "title": "SQL Extras",
    "section": "Preparing to load data",
    "text": "Preparing to load data\nThe duckdb database is currently empty, so we need to load in some data. The duckdb_read_csv() function in the duckdb R package allows us to load the .csv file (available on GitHub) directly into the database without being loaded as an R object first.\nRecall that in ?@tbl-select-describe we used DESCRIBE to display the variable types of the database table(s). The list includes the variable name (Field), its Type, whether there are NULL values allowed, and whether there are keys or indices defined on the variable. See Table 2 for the DESCRIBE output on the table we are about to import.\nUnlike R, when creating a new data table, SQL requires that you communicate each future variable (column) and that variable’s type. Variable types are not automatically generated!"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#saturday-night-live",
    "href": "slides/2024-01-18-db-etc.html#saturday-night-live",
    "title": "SQL Extras",
    "section": "Saturday Night Live",
    "text": "Saturday Night Live\n\n\n\n\n\nFigure 1: image credit: NBC\n\n\n\n\nConsider the Saturday Night Live datasets available on the snldb GitHub repo."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#casts-table",
    "href": "slides/2024-01-18-db-etc.html#casts-table",
    "title": "SQL Extras",
    "section": "casts table",
    "text": "casts table\nUse R to understand the data from casts.csv.\n\ncasts &lt;- readr::read_csv(\"https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv\")\nglimpse(casts)\n\nRows: 614\nColumns: 8\n$ aid             &lt;chr&gt; \"A. Whitney Brown\", \"A. Whitney Brown\", \"A. Whitney Br…\n$ sid             &lt;dbl&gt; 11, 12, 13, 14, 15, 16, 5, 39, 40, 41, 42, 45, 46, 21,…\n$ featured        &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ first_epid      &lt;dbl&gt; 19860222, NA, NA, NA, NA, NA, 19800409, 20140118, NA, …\n$ last_epid       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ update_anchor   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ n_episodes      &lt;dbl&gt; 8, 20, 13, 20, 20, 20, 5, 11, 21, 21, 21, 18, 17, 20, …\n$ season_fraction &lt;dbl&gt; 0.444, 1.000, 1.000, 1.000, 1.000, 1.000, 0.250, 0.524…"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#data-types",
    "href": "slides/2024-01-18-db-etc.html#data-types",
    "title": "SQL Extras",
    "section": "Data types",
    "text": "Data types\n\nNumbers: INTEGER, SMALLINT, NUMERIC, DECIMAL, DOUBLE(precision, scale) precision = # sig digits, scale = # digits the follow decimal.\nString: CHAR, VARCHAR, BINARY, TEXT\nDate: DATE, TIME, DATETIME, TIMESTAMP, YEAR\nBoolean: SMALLINT(1) in MySQL, BOOLEAN in DuckDB"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#check-constraints",
    "href": "slides/2024-01-18-db-etc.html#check-constraints",
    "title": "SQL Extras",
    "section": "CHECK constraints",
    "text": "CHECK constraints\nViolation will result in an error.\n\nCREATE TABLE CountryListCensus (\n    Id INT,\n    CountryName VARCHAR(255) NOT NULL,\n    CountryPopulation INT CHECK(CountryPopulation &gt; 0),\n    LastCensus DATE,\n    NextCensus DATE,\n    CHECK(LastCensus&lt;NextCensus),\n    PRIMARY KEY (Id)\n);"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#loading-data",
    "href": "slides/2024-01-18-db-etc.html#loading-data",
    "title": "SQL Extras",
    "section": "Loading data",
    "text": "Loading data\nImporting .csv files as tables, a series of steps:1\n\na USE statement that ensures we are in the right schema/database.\na series of DROP TABLE statements that drop any old tables with the same names as the ones we are going to create.\na series of CREATE TABLE statements that specify the table structures.\na series of COPY statements that read the data from the .csv files into the appropriate tables."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#loading-step-1-use",
    "href": "slides/2024-01-18-db-etc.html#loading-step-1-use",
    "title": "SQL Extras",
    "section": "Loading step 1, USE",
    "text": "Loading step 1, USE\nUse the (local) database that we’ve called duck_datab.\n\n```{sql}\n#| connection: con_duckdb\n\nUSE duck_datab;\n```"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#loading-step-2-refresh",
    "href": "slides/2024-01-18-db-etc.html#loading-step-2-refresh",
    "title": "SQL Extras",
    "section": "Loading step 2, refresh",
    "text": "Loading step 2, refresh\nMake sure to “refresh” the table, in case it already exists. However, be very careful with the DROP TABLE statement, as it removes the casts table.\n\nDROP TABLE IF EXISTS casts;"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#loading-step-3-create-table",
    "href": "slides/2024-01-18-db-etc.html#loading-step-3-create-table",
    "title": "SQL Extras",
    "section": "Loading step 3, CREATE TABLE",
    "text": "Loading step 3, CREATE TABLE\nCarefully define the variable types, whether or not they allow missing values, and what a default value is for that variable. Additionally, identify the key for accessing information.\n\nCREATE TABLE casts (\n  aid VARCHAR(255) NOT NULL DEFAULT '',\n  sid INTEGER NOT NULL DEFAULT 0,\n  featured BOOLEAN NOT NULL DEFAULT 'false',\n  first_epid INTEGER DEFAULT 0,\n  last_epid INTEGER DEFAULT 0,\n  update_anchor BOOLEAN NOT NULL DEFAULT 0,\n  n_episodes INTEGER NOT NULL DEFAULT 0,\n  season_fraction DECIMAL(21,20) NOT NULL DEFAULT 0,\n  PRIMARY KEY (sid, aid)\n);"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#loading-step-4-copy",
    "href": "slides/2024-01-18-db-etc.html#loading-step-4-copy",
    "title": "SQL Extras",
    "section": "Loading step 4, COPY",
    "text": "Loading step 4, COPY\nThe .csv file lives on my computer, so I load it in directly. [n.b., the statement to load in data is different in MySQL.]\n\nCOPY casts FROM 'data/casts.csv' HEADER;"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#checking-the-loading-select",
    "href": "slides/2024-01-18-db-etc.html#checking-the-loading-select",
    "title": "SQL Extras",
    "section": "Checking the loading, SELECT",
    "text": "Checking the loading, SELECT\n\nSELECT * FROM casts LIMIT 8;\n\n\n\n\n\nTable 1: After CREATE TABLE where variable types are set, the COPY command pulls the data into the table. SELECT shows us that the table is as expected.\n\n\naid\nsid\nfeatured\nfirst_epid\nlast_epid\nupdate_anchor\nn_episodes\nseason_fraction\n\n\n\n\nA. Whitney Brown\n11\nTRUE\n19860222\n\nFALSE\n8\n0.444\n\n\nA. Whitney Brown\n12\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n13\nTRUE\n\n\nFALSE\n13\n1.000\n\n\nA. Whitney Brown\n14\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n15\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nA. Whitney Brown\n16\nTRUE\n\n\nFALSE\n20\n1.000\n\n\nAlan Zweibel\n5\nTRUE\n19800409\n\nFALSE\n5\n0.250\n\n\nSasheer Zamata\n39\nTRUE\n20140118\n\nFALSE\n11\n0.524"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#check-the-database",
    "href": "slides/2024-01-18-db-etc.html#check-the-database",
    "title": "SQL Extras",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nSHOW DATABASES;\n\n\n\n\n1 records\n\n\n\n\ndatabase_name\n\n\n\n\n\n\nduck_datab"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#check-the-database-1",
    "href": "slides/2024-01-18-db-etc.html#check-the-database-1",
    "title": "SQL Extras",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nSHOW TABLES;\n\n\n\n\n1 records\n\n\n\n\nname\n\n\n\n\n\n\ncasts"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#check-the-database-2",
    "href": "slides/2024-01-18-db-etc.html#check-the-database-2",
    "title": "SQL Extras",
    "section": "Check the database",
    "text": "Check the database\nLet’s make sure that the database exists and that the table in the database exists.\n\nDESCRIBE casts;\n\n\n\n\n\nTable 2: DESCRIBE variables in the casts table.\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\naid\nVARCHAR\nNO\nPRI\n''\n\n\n\nsid\nINTEGER\nNO\nPRI\n0\n\n\n\nfeatured\nBOOLEAN\nNO\n\n'false'\n\n\n\nfirst_epid\nINTEGER\nYES\n\n0\n\n\n\nlast_epid\nINTEGER\nYES\n\n0\n\n\n\nupdate_anchor\nBOOLEAN\nNO\n\n0\n\n\n\nn_episodes\nINTEGER\nNO\n\n0\n\n\n\nseason_fraction\nDECIMAL(21,20)\nNO\n\n0"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#efficiencies",
    "href": "slides/2024-01-18-db-etc.html#efficiencies",
    "title": "SQL Extras",
    "section": "Efficiencies",
    "text": "Efficiencies\nReconsider this analogy:\n\nEach library (database) has books (tables). Each book (table) has pages (rows). Each page (row) has a unique page number to identify it (key value); to find a particular page, you sort through the page numbers (key values). But it isn’t immediately obvious where the particular page of interest is, you might have to page through the book a little bit to find the page of interest. It would be easier if you had several bookmarks throughout the book to anchor some of the page numbers. For example, if you want page 1047 and you have a bookmark on page 1050, you only have to turn back three pages. The bookmark is an index, it helps you find the desired rows much more quickly.1\n\nAnalogy taken from: https://www.quora.com/profile/Lara-Mazilu"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#key",
    "href": "slides/2024-01-18-db-etc.html#key",
    "title": "SQL Extras",
    "section": "Key",
    "text": "Key\nKeys are unique identifiers for each row, used primarily for connecting tables. Keys are generally not helpful for efficiency, but they are important for data integrity and relationships between tables.\n\nPRIMARY KEY is a column or set of columns that uniquely identify each row. Primary keys cannot be NULL.\nFOREIGN KEY is a column or set of columns that reference a primary key in a different table. A foreign key can be NULL."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#index",
    "href": "slides/2024-01-18-db-etc.html#index",
    "title": "SQL Extras",
    "section": "Index",
    "text": "Index\nIndices are the crux of why SQL is so much more efficient than, say, R. An index is a lookup table that helps SQL keep track of which records contain certain values. By indexing the rows, SQL is able to optimize sorting and joining tables. The index is created in advance (when the table is created) and saved to disk, which can take up substantial space on the disk. Sometimes more than one variable is used to index the table. There are trade-offs to having a lot of indices (disk space but fast wrangling) versus a few indices (slow wrangling but less space)."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#find-keys-and-indices",
    "href": "slides/2024-01-18-db-etc.html#find-keys-and-indices",
    "title": "SQL Extras",
    "section": "Find keys and indices",
    "text": "Find keys and indices\nIn MySQL the commands SHOW KEYS and SHOW INDEXES provide information about the keys and indices for each table."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#partitioning",
    "href": "slides/2024-01-18-db-etc.html#partitioning",
    "title": "SQL Extras",
    "section": "Partitioning",
    "text": "Partitioning\nAnother way to speed up query retrievals is to partition the data tables. If, for example, the SNL queries were always done by year, then the episodes table could be partitioned such that they are stored as separate tables (one per year). The partitioning functions as an index on year. The user would not be able to tell the difference between the unpartitioned episodes table and the partitioned one. However, queries done by year would be faster. Queries done grouped in another way would be slower."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#best-practice",
    "href": "slides/2024-01-18-db-etc.html#best-practice",
    "title": "SQL Extras",
    "section": "Best practice",
    "text": "Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_air, shutdown = TRUE)"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#footnotes",
    "href": "slides/2024-01-18-db-etc.html#footnotes",
    "title": "SQL Extras",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ntaken from MDSR.↩︎"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24.html#disconnect-from-the-server",
    "href": "handout/lab5_creating_db_sds261_j24.html#disconnect-from-the-server",
    "title": "Lab 5 - creating databases",
    "section": "Disconnect from the server",
    "text": "Disconnect from the server"
  },
  {
    "objectID": "handout/lab5_creating_db_sds261_j24_sol.html#disconnect-from-the-server",
    "href": "handout/lab5_creating_db_sds261_j24_sol.html#disconnect-from-the-server",
    "title": "Lab 5 - creating databases",
    "section": "Disconnect from the server",
    "text": "Disconnect from the server"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24.html#disconnect-from-the-server",
    "href": "handout/lab6_editing_db_sds261_j24.html#disconnect-from-the-server",
    "title": "Lab 6 - editing databases",
    "section": "Disconnect from the server",
    "text": "Disconnect from the server\n\ndbDisconnect(con_college, shutdown = TRUE)"
  },
  {
    "objectID": "handout/lab6_editing_db_sds261_j24_sol.html#disconnect-from-the-server",
    "href": "handout/lab6_editing_db_sds261_j24_sol.html#disconnect-from-the-server",
    "title": "Lab 6 - editing databases",
    "section": "Disconnect from the server",
    "text": "Disconnect from the server\n\ndbDisconnect(con_college, shutdown = TRUE)"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#changing-data",
    "href": "slides/2024-01-17-editing-db.html#changing-data",
    "title": "Editing Databases",
    "section": "Changing data",
    "text": "Changing data\nThe UPDATE function allows you to change a value in a table across all rows that match a certain criteria.\n\nSELECT * FROM impressions \n   WHERE name LIKE 'Ivanka%';\n\n\n\n\n5 records\n\n\n\n\nimpid\n\n\naid\n\n\nname\n\n\n\n\n\n\n2598\n\n\nScarlett Johansson\n\n\nIvanka Trump\n\n\n\n\n3716\n\n\nEmily Blunt\n\n\nIvanka Trump\n\n\n\n\n3694\n\n\nMargot Robbie\n\n\nIvanka Trump\n\n\n\n\n3679\n\n\nVanessa Bayer\n\n\nIvanka Trump\n\n\n\n\n2340\n\n\nMaya Rudolph\n\n\nIvanka Trump"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#update",
    "href": "slides/2024-01-17-editing-db.html#update",
    "title": "Editing Databases",
    "section": "UPDATE",
    "text": "UPDATE\nFor funsies, let’s change Ivanka Trump to Ivanka Kushner.\n\nUPDATE impressions\n   SET name = 'Ivanka Kushner'\n   WHERE name LIKE 'Ivanka%';\n\n\nSELECT * FROM impressions \n   WHERE name LIKE 'Ivanka%';\n\n\n\n\n5 records\n\n\n\n\nimpid\n\n\naid\n\n\nname\n\n\n\n\n\n\n2598\n\n\nScarlett Johansson\n\n\nIvanka Kushner\n\n\n\n\n3716\n\n\nEmily Blunt\n\n\nIvanka Kushner\n\n\n\n\n3694\n\n\nMargot Robbie\n\n\nIvanka Kushner\n\n\n\n\n3679\n\n\nVanessa Bayer\n\n\nIvanka Kushner\n\n\n\n\n2340\n\n\nMaya Rudolph\n\n\nIvanka Kushner"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#update-1",
    "href": "slides/2024-01-17-editing-db.html#update-1",
    "title": "Editing Databases",
    "section": "UPDATE",
    "text": "UPDATE\n\n\n\n Watch out!\n\n\nBe careful with UPDATE. A careless UPDATE could write over all of the data in your table. There is no undo function."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#inserting-data",
    "href": "slides/2024-01-17-editing-db.html#inserting-data",
    "title": "Editing Databases",
    "section": "Inserting data",
    "text": "Inserting data\nTask: include recent hosts in the hosts table.\nBy searching the SNL archives, we can see that the next host, chronologically was Elon Musk on May 8, 2021.\n\nFigure 2: Hosts information from snlarchives.net"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#inserting-data-1",
    "href": "slides/2024-01-17-editing-db.html#inserting-data-1",
    "title": "Editing Databases",
    "section": "Inserting data",
    "text": "Inserting data\nTask: include recent hosts in the hosts table.\nBy searching the SNL archives, we can see that the next host, chronologically was Elon Musk on May 8, 2021.\n\nSELECT * FROM hosts\n    ORDER BY epid DESC\n    LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20210410\n\n\nCarey Mulligan\n\n\n\n\n20210403\n\n\nDaniel Kaluuya\n\n\n\n\n20210327\n\n\nMaya Rudolph\n\n\n\n\n20210227\n\n\nNick Jonas\n\n\n\n\n20210220\n\n\nRege-Jean Page\n\n\n\n\n20210213\n\n\nRegina King\n\n\n\n\n20210206\n\n\nDan Levy\n\n\n\n\n20210130\n\n\nJohn Krasinski\n\n\n\n\n20201219\n\n\nKristen Wiig\n\n\n\n\n20201212\n\n\nTimothee Chalamet"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#inserting-data-2",
    "href": "slides/2024-01-17-editing-db.html#inserting-data-2",
    "title": "Editing Databases",
    "section": "Inserting data",
    "text": "Inserting data\nINSERT allows us to add the relevant information associated with the episode of SNL that Elon Musk hosted.\n\nINSERT INTO hosts (epid, aid)\n   VALUES ('20210508', 'Elon Musk');\n\n\nSELECT * FROM hosts\n    ORDER BY epid DESC\n    LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20210508\n\n\nElon Musk\n\n\n\n\n20210410\n\n\nCarey Mulligan\n\n\n\n\n20210403\n\n\nDaniel Kaluuya\n\n\n\n\n20210327\n\n\nMaya Rudolph\n\n\n\n\n20210227\n\n\nNick Jonas\n\n\n\n\n20210220\n\n\nRege-Jean Page\n\n\n\n\n20210213\n\n\nRegina King\n\n\n\n\n20210206\n\n\nDan Levy\n\n\n\n\n20210130\n\n\nJohn Krasinski\n\n\n\n\n20201219\n\n\nKristen Wiig"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#inserting-data-3",
    "href": "slides/2024-01-17-editing-db.html#inserting-data-3",
    "title": "Editing Databases",
    "section": "Inserting data",
    "text": "Inserting data\nIt would be tedious to INSERT all of the most recent host information by hand. Instead, we’ll scrape the SNL archives using the R package rvest, which allows us to pull out the appropriate html elements. The epid and aid are joined together in a tibble, and filtered to only include episodes which are not already in the episodes table.\n\nlibrary(rvest)\n\nrecent_hosts &lt;- read_html(\"http://www.snlarchives.net/Episodes/\") |&gt;\n  html_nodes(\"tr\") |&gt;\n  purrr::map_df( ~ tibble(\n    epid = .x |&gt; html_node(\"a.ms-2.me-2\") |&gt;\n      html_attr(\"href\") |&gt;\n      str_extract(\"\\\\d+\"),\n    aid = .x |&gt; html_node(\"td:nth-child(2)\") |&gt;\n      html_text2() |&gt;\n      str_extract(\"[\\\\w\\\\. \\\\w\\\\.]+(?=/|$)\")\n  )) |&gt;\n  filter(epid &gt; 20210508)\n\n\nwrite_csv(recent_hosts, \"data/recent_hosts.csv\")"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#deleting-data",
    "href": "slides/2024-01-17-editing-db.html#deleting-data",
    "title": "Editing Databases",
    "section": "Deleting data",
    "text": "Deleting data\nYou might change your mind and decide that you really only want hosts from years up to 2022. The DELETE function deletes any rows specified by the WHERE clause.\n\nDELETE FROM hosts\n   WHERE epid &gt; 20221231;\n\n\nSELECT * FROM hosts\n  ORDER BY epid DESC\n  LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20221217\n\n\nAustin Butler\n\n\n\n\n20221210\n\n\nMartin Short\n\n\n\n\n20221203\n\n\nKeke Palmer\n\n\n\n\n20221112\n\n\nDave Chappelle\n\n\n\n\n20221105\n\n\nAmy Schumer\n\n\n\n\n20221029\n\n\nJack Harlow\n\n\n\n\n20221015\n\n\nMegan Thee Stallion\n\n\n\n\n20221008\n\n\nBrendan Gleeson\n\n\n\n\n20221001\n\n\nMiles Teller\n\n\n\n\n20220521\n\n\nNatasha Lyonne"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table",
    "title": "Editing Databases",
    "section": "Altering the table",
    "text": "Altering the table\nALTER TABLE changes the structure of a table. For example, you can add or delete columns, create or destroy indexes, change the type of existing columns, or rename columns or the table itself.\nMultiple ADD, ALTER, DROP, and CHANGE clauses are permitted in a single ALTER TABLE statement, separated by commas.\nCaveat: I have found DuckDB to be slightly finicky in some of the operations…"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#inserting-data-4",
    "href": "slides/2024-01-17-editing-db.html#inserting-data-4",
    "title": "Editing Databases",
    "section": "Inserting data",
    "text": "Inserting data\n\nINSERT INTO hosts\n   SELECT *\n   FROM READ_CSV('data/recent_hosts.csv', AUTO_DETECT = TRUE);\n\n\nSELECT * FROM hosts\n  ORDER BY epid DESC\n  LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20231216\n\n\nKate McKinnon\n\n\n\n\n20231209\n\n\nAdam Driver\n\n\n\n\n20231202\n\n\nEmma Stone\n\n\n\n\n20231118\n\n\nJason Momoa\n\n\n\n\n20231111\n\n\nTimothée Chalamet\n\n\n\n\n20231028\n\n\nNate Bargatze\n\n\n\n\n20231021\n\n\nBad Bunny\n\n\n\n\n20231014\n\n\nPete Davidson\n\n\n\n\n20230415\n\n\nAna de Armas\n\n\n\n\n20230408\n\n\nMolly Shannon"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table-drop-columns",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table-drop-columns",
    "title": "Editing Databases",
    "section": "Altering the table (DROP columns)",
    "text": "Altering the table (DROP columns)\n\nALTER TABLE t1\nDROP COLUMN col1,\nDROP COLUMN col2;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table-change-name-and-definition",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table-change-name-and-definition",
    "title": "Editing Databases",
    "section": "Altering the table (CHANGE name and definition)",
    "text": "Altering the table (CHANGE name and definition)\n\nrename an INT NOT NULL column from a to b and change its definition to use the BIGINT data type while retaining the NOT NULL attribute.\n\n\nALTER TABLE t1 CHANGE a b BIGINT NOT NULL;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table-change-definition-not-name",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table-change-definition-not-name",
    "title": "Editing Databases",
    "section": "Altering the table (CHANGE definition not name)",
    "text": "Altering the table (CHANGE definition not name)\n\nCHANGE, the syntax requires two column names, so you must specify the same name twice to leave the name unchanged. For example, to change the definition of column b.\n\n\nALTER TABLE t1 CHANGE b b INT NOT NULL;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table-modify-definition",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table-modify-definition",
    "title": "Editing Databases",
    "section": "Altering the table (MODIFY definition)",
    "text": "Altering the table (MODIFY definition)\n\nMODIFY is more convenient to change the definition without changing the name because it requires the column name only once.\n\n\nALTER TABLE t1 MODIFY b INT NOT NULL;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table-change-name-not-definition",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table-change-name-not-definition",
    "title": "Editing Databases",
    "section": "Altering the table (CHANGE name not definition)",
    "text": "Altering the table (CHANGE name not definition)\n\nCHANGE, the syntax requires a column definition, so to leave the definition unchanged, you must respecify the definition the column currently has. For example, to rename an INT NOT NULL column from b to a.\n\n\nALTER TABLE t1 CHANGE b a INT NOT NULL;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table-rename-column-name-not-definition",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table-rename-column-name-not-definition",
    "title": "Editing Databases",
    "section": "Altering the table (RENAME COLUMN name not definition)",
    "text": "Altering the table (RENAME COLUMN name not definition)\n\nRENAME COLUMN is more convenient to change the name without changing the definition because it requires only the old and new names.\n\n\nALTER TABLE t1 RENAME COLUMN b TO a;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#altering-the-table-rename-column-multiple-columns",
    "href": "slides/2024-01-17-editing-db.html#altering-the-table-rename-column-multiple-columns",
    "title": "Editing Databases",
    "section": "Altering the table (RENAME COLUMN multiple columns)",
    "text": "Altering the table (RENAME COLUMN multiple columns)\n\ncannot RENAME COLUMN to a column name that already exists. The following are valid.\n\n\n/* swap a and b */\nALTER TABLE t1 RENAME COLUMN a TO b,\n               RENAME COLUMN b TO a;\n\n/* \"rotate\" a, b, c through a cycle */\nALTER TABLE t1 RENAME COLUMN a TO b,\n               RENAME COLUMN b TO c,\n               RENAME COLUMN c TO a;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#temporary-tables",
    "href": "slides/2024-01-17-editing-db.html#temporary-tables",
    "title": "Editing Databases",
    "section": "Temporary Tables",
    "text": "Temporary Tables\nTemporary tables are used to break down complex queries into smaller, more manageable steps. For example, let’s say we want to JOIN two tables after each has been filtered using different WHERE clauses. The filtered tables can each be saved into their own temporary tables and then the temporary tables can be merged.\nTables in DuckDB are saved (to disk), even when the connection is closed. However, temporary tables are saved in memory (instead of on disk) and are deleted when the connection is closed."
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#temporary-tables-1",
    "href": "slides/2024-01-17-editing-db.html#temporary-tables-1",
    "title": "Editing Databases",
    "section": "Temporary Tables",
    "text": "Temporary Tables\nWe wouldn’t want to wrangle the date every single time we used the data.\n\nCREATE TEMP TABLE episodes_date AS\n    SELECT *, CASE\n             WHEN POSITION(',' IN aired) &gt; 0 THEN\n    EXTRACT(YEAR FROM CAST(\n                SUBSTRING(aired, POSITION(',' IN aired) + 2) || '-' ||\n                CASE\n                    WHEN POSITION('January' IN aired) &gt; 0 THEN '01'\n                    WHEN POSITION('February' IN aired) &gt; 0 THEN '02'\n                    WHEN POSITION('March' IN aired) &gt; 0 THEN '03'\n                    WHEN POSITION('April' IN aired) &gt; 0 THEN '04'\n                    WHEN POSITION('May' IN aired) &gt; 0 THEN '05'\n                    WHEN POSITION('June' IN aired) &gt; 0 THEN '06'\n                    WHEN POSITION('July' IN aired) &gt; 0 THEN '07'\n                    WHEN POSITION('August' IN aired) &gt; 0 THEN '08'\n                    WHEN POSITION('September' IN aired) &gt; 0 THEN '09'\n                    WHEN POSITION('October' IN aired) &gt; 0 THEN '10'\n                    WHEN POSITION('November' IN aired) &gt; 0 THEN '11'\n                    WHEN POSITION('December' IN aired) &gt; 0 THEN '12'\n                    ELSE '01' -- Default to January if no month is found\n                END || '-' ||\n                SUBSTRING(aired, POSITION(' ' IN aired) + 1, 2) AS DATE\n            ))\n            END AS year FROM episodes;"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#temporary-tables-hosts",
    "href": "slides/2024-01-17-editing-db.html#temporary-tables-hosts",
    "title": "Editing Databases",
    "section": "Temporary Tables (hosts)",
    "text": "Temporary Tables (hosts)\n\nSELECT * FROM hosts LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nepid\n\n\naid\n\n\n\n\n\n\n20210410\n\n\nCarey Mulligan\n\n\n\n\n20210403\n\n\nDaniel Kaluuya\n\n\n\n\n20210327\n\n\nMaya Rudolph\n\n\n\n\n20210227\n\n\nNick Jonas\n\n\n\n\n20210220\n\n\nRege-Jean Page\n\n\n\n\n20210213\n\n\nRegina King\n\n\n\n\n20210206\n\n\nDan Levy\n\n\n\n\n20210130\n\n\nJohn Krasinski\n\n\n\n\n20201219\n\n\nKristen Wiig\n\n\n\n\n20201212\n\n\nTimothee Chalamet"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#temporary-tables-episodes",
    "href": "slides/2024-01-17-editing-db.html#temporary-tables-episodes",
    "title": "Editing Databases",
    "section": "Temporary Tables (episodes)",
    "text": "Temporary Tables (episodes)\n\nSELECT * FROM episodes LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nsid\n\n\nepid\n\n\naired\n\n\nepno\n\n\n\n\n\n\n46\n\n\n20210410\n\n\nApril 10, 2021\n\n\n17\n\n\n\n\n46\n\n\n20210403\n\n\nApril 3, 2021\n\n\n16\n\n\n\n\n46\n\n\n20210327\n\n\nMarch 27, 2021\n\n\n15\n\n\n\n\n46\n\n\n20210227\n\n\nFebruary 27, 2021\n\n\n14\n\n\n\n\n46\n\n\n20210220\n\n\nFebruary 20, 2021\n\n\n13\n\n\n\n\n46\n\n\n20210213\n\n\nFebruary 13, 2021\n\n\n12\n\n\n\n\n46\n\n\n20210206\n\n\nFebruary 6, 2021\n\n\n11\n\n\n\n\n46\n\n\n20210130\n\n\nJanuary 30, 2021\n\n\n10\n\n\n\n\n46\n\n\n20201219\n\n\nDecember 19, 2020\n\n\n9\n\n\n\n\n46\n\n\n20201212\n\n\nDecember 12, 2020\n\n\n8"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#temporary-table-exists",
    "href": "slides/2024-01-17-editing-db.html#temporary-table-exists",
    "title": "Editing Databases",
    "section": "Temporary Table exists!",
    "text": "Temporary Table exists!\n\nSELECT * FROM episodes_date LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nsid\n\n\nepid\n\n\naired\n\n\nepno\n\n\nyear\n\n\n\n\n\n\n46\n\n\n20210410\n\n\nApril 10, 2021\n\n\n17\n\n\n2021\n\n\n\n\n46\n\n\n20210403\n\n\nApril 3, 2021\n\n\n16\n\n\n2021\n\n\n\n\n46\n\n\n20210327\n\n\nMarch 27, 2021\n\n\n15\n\n\n2021\n\n\n\n\n46\n\n\n20210227\n\n\nFebruary 27, 2021\n\n\n14\n\n\n2021\n\n\n\n\n46\n\n\n20210220\n\n\nFebruary 20, 2021\n\n\n13\n\n\n2021\n\n\n\n\n46\n\n\n20210213\n\n\nFebruary 13, 2021\n\n\n12\n\n\n2021\n\n\n\n\n46\n\n\n20210206\n\n\nFebruary 6, 2021\n\n\n11\n\n\n2021\n\n\n\n\n46\n\n\n20210130\n\n\nJanuary 30, 2021\n\n\n10\n\n\n2021\n\n\n\n\n46\n\n\n20201219\n\n\nDecember 19, 2020\n\n\n9\n\n\n2020\n\n\n\n\n46\n\n\n20201212\n\n\nDecember 12, 2020\n\n\n8\n\n\n2020"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#using-a-temporary-table",
    "href": "slides/2024-01-17-editing-db.html#using-a-temporary-table",
    "title": "Editing Databases",
    "section": "Using a temporary table",
    "text": "Using a temporary table\nNow that the year variable has been created in the new temporary table called episodes_date, we can use episode_date to query and find, for example, all of the hosts in 2019.\n\nSELECT hosts.aid, ep.aired, ep.year FROM hosts \nJOIN episodes_date AS ep ON hosts.epid = ep.epid\nWHERE year = 2019\nLIMIT 25;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\naid\n\n\naired\n\n\nyear\n\n\n\n\n\n\nEddie Murphy\n\n\nDecember 21, 2019\n\n\n2019\n\n\n\n\nScarlett Johansson\n\n\nDecember 14, 2019\n\n\n2019\n\n\n\n\nJennifer Lopez\n\n\nDecember 7, 2019\n\n\n2019\n\n\n\n\nWill Ferrell\n\n\nNovember 23, 2019\n\n\n2019\n\n\n\n\nHarry Styles\n\n\nNovember 16, 2019\n\n\n2019\n\n\n\n\nKristen Stewart\n\n\nNovember 2, 2019\n\n\n2019\n\n\n\n\nChance the Rapper\n\n\nOctober 26, 2019\n\n\n2019\n\n\n\n\nDavid Harbour\n\n\nOctober 12, 2019\n\n\n2019\n\n\n\n\nPhoebe Waller-Bridge\n\n\nOctober 5, 2019\n\n\n2019\n\n\n\n\nWoody Harrelson\n\n\nSeptember 28, 2019\n\n\n2019"
  },
  {
    "objectID": "slides/2024-01-17-editing-db.html#what-does-position-do",
    "href": "slides/2024-01-17-editing-db.html#what-does-position-do",
    "title": "Editing Databases",
    "section": "What does POSITION do?",
    "text": "What does POSITION do?\nIn case you are curious about the date wrangling code… consider SUBSTRING(aired, POSITION(',' IN aired) + 2)\n\nPOSITION(',' IN aired): This part of the expression uses the POSITION function to find the position of the first occurrence of the comma (,) in the string aired. The result is the index (position) of the comma within the string.\nPOSITION(',' IN aired) + 2: This adds 2 to the index of the comma. The + 2 is used to move the starting point of the substring two positions to the right of the comma. This is done to exclude the comma itself and any following spaces.\nSUBSTRING(aired, POSITION(',' IN aired) + 2): This part uses the SUBSTRING function to extract a substring from the string aired. The starting position of the substring is determined by POSITION(',' IN aired) + 2, and it goes until the end of the string. This effectively removes the part of the string that comes before and including the first comma.\n\nIn summary, the entire expression is extracting a substring from the original string aired, starting from two positions to the right of the first comma and continuing until the end of the string. This can be useful in scenarios where you want to remove or isolate part of a string based on the position of a specific character (in this case, the comma)."
  },
  {
    "objectID": "handout/tempqmd.html",
    "href": "handout/tempqmd.html",
    "title": "Untitled",
    "section": "",
    "text": "words here are perfect\n\nrnorm(10)\n\n [1]  0.32076290 -0.27356519  1.32280634 -0.53182529 -0.36214646  0.30805779\n [7]  0.53618050 -0.66224235 -0.04290013  0.07816006\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#back-to-the-flights",
    "href": "slides/2024-01-18-db-etc.html#back-to-the-flights",
    "title": "SQL Extras",
    "section": "Back to the flights",
    "text": "Back to the flights\nThe examples below use the airlines database, including the flights, carriers, airports, and planes tables."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#keys",
    "href": "slides/2024-01-18-db-etc.html#keys",
    "title": "SQL Extras",
    "section": "KEYs",
    "text": "KEYs\nKeys are unique identifiers for each row, used primarily for connecting tables. Keys are generally not helpful for efficiency, but they are important for data integrity and relationships between tables. A key is a pointer that identifies a record. In practice, a key is one or more columns that are earmarked to uniquely identify a record in a table. Keys serve two main purposes:\n\nThey provide constraints on the column such as that it can’t store duplicate or null values.\nThey are also used to generate relationships among different tables."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#indexes",
    "href": "slides/2024-01-18-db-etc.html#indexes",
    "title": "SQL Extras",
    "section": "INDEXes",
    "text": "INDEXes\n\nBy indexing the rows, SQL is able to optimize sorting and joining tables.\nThe index is created in advance (when the table is created) and saved to disk, which can take up substantial space on the disk.\nSometimes more than one variable is used to index the table.\nThere are trade-offs to having a lot of indexes (disk space but fast wrangling) versus a few indexes (slow wrangling but less space).\nA table may have more than one index but you shouldn’t add indexes to every column in a table, as these have to be updated for every addition/update/delete to the column.\nIndexes should be added to columns that are frequently included in queries."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#show-indexes",
    "href": "slides/2024-01-18-db-etc.html#show-indexes",
    "title": "SQL Extras",
    "section": "SHOW INDEXES",
    "text": "SHOW INDEXES\nNotice that the planes table has a single PRIMARY key. That primary key is used to index the table. The flights table has no PRIMARY key, but it does have six different indexes: Year, Date, Origin, Dest, Carrier, and tailNum.\n\nSHOW INDEXES FROM planes;\n\n\n\n\n1 records\n\n\n\n\nTable\n\n\nNon_unique\n\n\nKey_name\n\n\nSeq_in_index\n\n\nColumn_name\n\n\nCollation\n\n\nCardinality\n\n\nSub_part\n\n\nPacked\n\n\nNull\n\n\nIndex_type\n\n\nComment\n\n\nIndex_comment\n\n\n\n\n\n\nplanes\n\n\n0\n\n\nPRIMARY\n\n\n1\n\n\ntailnum\n\n\nA\n\n\n3322\n\n\n\n\n\n\n\n\nBTREE\n\n\n\n\n\n\n\n\n\n\n\n\nSHOW INDEXES FROM flights;\n\n\n\n\n8 records\n\n\n\n\nTable\n\n\nNon_unique\n\n\nKey_name\n\n\nSeq_in_index\n\n\nColumn_name\n\n\nCollation\n\n\nCardinality\n\n\nSub_part\n\n\nPacked\n\n\nNull\n\n\nIndex_type\n\n\nComment\n\n\nIndex_comment\n\n\n\n\n\n\nflights\n\n\n1\n\n\nYear\n\n\n1\n\n\nyear\n\n\nA\n\n\n7\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDate\n\n\n1\n\n\nyear\n\n\nA\n\n\n7\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDate\n\n\n2\n\n\nmonth\n\n\nA\n\n\n89\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDate\n\n\n3\n\n\nday\n\n\nA\n\n\n2712\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nOrigin\n\n\n1\n\n\norigin\n\n\nA\n\n\n2267\n\n\n\n\n\n\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDest\n\n\n1\n\n\ndest\n\n\nA\n\n\n2267\n\n\n\n\n\n\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nCarrier\n\n\n1\n\n\ncarrier\n\n\nA\n\n\n134\n\n\n\n\n\n\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\ntailNum\n\n\n1\n\n\ntailnum\n\n\nA\n\n\n37862\n\n\n\n\n\n\nYES\n\n\nBTREE"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#show-indexes-1",
    "href": "slides/2024-01-18-db-etc.html#show-indexes-1",
    "title": "SQL Extras",
    "section": "SHOW INDEXES",
    "text": "SHOW INDEXES\nThe values output by SHOW INDEXES are:1\n\nTable: The name of the table.\nNon_unique: 0 if the index cannot contain duplicates, 1 if it can.\nKey_name: The name of the index. If the index is the primary key, the name is always PRIMARY.\nSeq_in_index: The column sequence number in the index, starting with 1.\nColumn_name: The column name. See also the description for the Expression column.\nCollation: How the column is sorted in the index. This can have values A (ascending), D (descending), or NULL (not sorted).\nCardinality: An estimate of the number of unique values in the index.\nSub_part: The index prefix. That is, the number of indexed characters if the column is only partly indexed, NULL if the entire column is indexed.\nPacked: Indicates how the key is packed. NULL if it is not.\nNull: Contains YES if the column may contain NULL values and ’’ if not.\nIndex_type: The index method used (BTREE, FULLTEXT, HASH, RTREE).\nComment: Information about the index not described in its own column, such as disabled if the index is disabled.\nIndex_comment: Any comment provided for the index with a COMMENT attribute when the index was created.\n\nTaken from: https://dev.mysql.com/doc/refman/8.0/en/show-index.html"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#querying-quickly",
    "href": "slides/2024-01-18-db-etc.html#querying-quickly",
    "title": "SQL Extras",
    "section": "Querying quickly",
    "text": "Querying quickly\nIndexes are built to accommodate the specific queries that are most likely to be run. However, you might not know which queries are going to be run, so it isn’t always obviously how to index a table.\n\nSHOW INDEXES FROM flights;\n\n\n\n\n8 records\n\n\n\n\nTable\n\n\nNon_unique\n\n\nKey_name\n\n\nSeq_in_index\n\n\nColumn_name\n\n\nCollation\n\n\nCardinality\n\n\nSub_part\n\n\nPacked\n\n\nNull\n\n\nIndex_type\n\n\nComment\n\n\nIndex_comment\n\n\n\n\n\n\nflights\n\n\n1\n\n\nYear\n\n\n1\n\n\nyear\n\n\nA\n\n\n7\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDate\n\n\n1\n\n\nyear\n\n\nA\n\n\n7\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDate\n\n\n2\n\n\nmonth\n\n\nA\n\n\n89\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDate\n\n\n3\n\n\nday\n\n\nA\n\n\n2712\n\n\n\n\n\n\nYES\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nOrigin\n\n\n1\n\n\norigin\n\n\nA\n\n\n2267\n\n\n\n\n\n\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nDest\n\n\n1\n\n\ndest\n\n\nA\n\n\n2267\n\n\n\n\n\n\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\nCarrier\n\n\n1\n\n\ncarrier\n\n\nA\n\n\n134\n\n\n\n\n\n\n\n\nBTREE\n\n\n\n\n\n\n\n\nflights\n\n\n1\n\n\ntailNum\n\n\n1\n\n\ntailnum\n\n\nA\n\n\n37862\n\n\n\n\n\n\nYES\n\n\nBTREE"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#explain-with-distance",
    "href": "slides/2024-01-18-db-etc.html#explain-with-distance",
    "title": "SQL Extras",
    "section": "EXPLAIN with distance",
    "text": "EXPLAIN with distance\nEXPLAIN communicates how onerous the query is, without actually running it—saving you the time of having to wait for it to execute.\n\nEXPLAIN SELECT * FROM flights WHERE distance &gt; 3000;\n\n\n\n\n1 records\n\n\n\n\nid\n\n\nselect_type\n\n\ntable\n\n\npartitions\n\n\ntype\n\n\npossible_keys\n\n\nkey\n\n\nkey_len\n\n\nref\n\n\nrows\n\n\nfiltered\n\n\nExtra\n\n\n\n\n\n\n1\n\n\nSIMPLE\n\n\nflights\n\n\np1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18,p19,p20,p21,p22,p23,p24,p25,p26,p27,p28,p29,p30,p31,p32\n\n\nALL\n\n\n\n\n\n\n\n\n\n\n47932811\n\n\n33.3\n\n\nUsing where\n\n\n\n\n\n\n\nIf we were to run a query for long flights using the distance column the server will have to inspect each of the 48 million rows, because distance is not indexed. A query on a non-indexed variable is the slowest possible search and is often called a table scan. The 48 million number that you see in the rows column is an estimate of the number of rows that MySQL will have to consult in order to process your query. In general, more rows mean a slower query."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#explain-with-year",
    "href": "slides/2024-01-18-db-etc.html#explain-with-year",
    "title": "SQL Extras",
    "section": "EXPLAIN with year",
    "text": "EXPLAIN with year\nA search for recent flights using the year column, which has an index built on it, considers many fewer rows (about 6.3 million, those flights in 2013).\n\nEXPLAIN SELECT * FROM flights WHERE year = 2013;\n\n\n\n\n1 records\n\n\n\n\nid\n\n\nselect_type\n\n\ntable\n\n\npartitions\n\n\ntype\n\n\npossible_keys\n\n\nkey\n\n\nkey_len\n\n\nref\n\n\nrows\n\n\nfiltered\n\n\nExtra\n\n\n\n\n\n\n1\n\n\nSIMPLE\n\n\nflights\n\n\np27\n\n\nALL\n\n\nYear,Date\n\n\n\n\n\n\n\n\n6369482\n\n\n100\n\n\nUsing where"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#explain-with-year-and-month",
    "href": "slides/2024-01-18-db-etc.html#explain-with-year-and-month",
    "title": "SQL Extras",
    "section": "EXPLAIN with year and month",
    "text": "EXPLAIN with year and month\nIn a search by year and month, SQL uses the Date index. Only 700,000 rows are searched, those in June of 2013.\n\nEXPLAIN SELECT * FROM flights WHERE year = 2013 AND month = 6;\n\n\n\n\n1 records\n\n\n\n\nid\n\n\nselect_type\n\n\ntable\n\n\npartitions\n\n\ntype\n\n\npossible_keys\n\n\nkey\n\n\nkey_len\n\n\nref\n\n\nrows\n\n\nfiltered\n\n\nExtra\n\n\n\n\n\n\n1\n\n\nSIMPLE\n\n\nflights\n\n\np27\n\n\nref\n\n\nYear,Date\n\n\nDate\n\n\n6\n\n\nconst,const\n\n\n714535\n\n\n100"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#explain-with-month",
    "href": "slides/2024-01-18-db-etc.html#explain-with-month",
    "title": "SQL Extras",
    "section": "EXPLAIN with month",
    "text": "EXPLAIN with month\nIf we search for particular months across all years, the indexing does not help at all. The query results in a table scan.\n\nEXPLAIN SELECT * FROM flights WHERE month = 6;\n\n\n\n\n1 records\n\n\n\n\nid\n\n\nselect_type\n\n\ntable\n\n\npartitions\n\n\ntype\n\n\npossible_keys\n\n\nkey\n\n\nkey_len\n\n\nref\n\n\nrows\n\n\nfiltered\n\n\nExtra\n\n\n\n\n\n\n1\n\n\nSIMPLE\n\n\nflights\n\n\np1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18,p19,p20,p21,p22,p23,p24,p25,p26,p27,p28,p29,p30,p31,p32\n\n\nALL\n\n\n\n\n\n\n\n\n\n\n47932811\n\n\n10\n\n\nUsing where\n\n\n\n\n\n\n\nAlthough month is part of the Date index, it is the second column in the index, and thus it doesn’t help us when we aren’t filtering on year. Thus, if it were common for our users to search on month without year, it would probably be worth building an index on month. Were we to actually run these queries, there would be a significant difference in computational time."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#explain-with-join---faster",
    "href": "slides/2024-01-18-db-etc.html#explain-with-join---faster",
    "title": "SQL Extras",
    "section": "EXPLAIN with JOIN - faster",
    "text": "EXPLAIN with JOIN - faster\nThe cardinality of the index on tailnum is large (the number of rows in flights associated with each unique value of tailnum is small).\n\nEXPLAIN \n  SELECT * FROM planes p \n  LEFT JOIN flights o ON p.tailnum = o.TailNum\n  WHERE manufacturer = 'BOEING';\n\n\n\n\n2 records\n\n\n\n\nid\n\n\nselect_type\n\n\ntable\n\n\npartitions\n\n\ntype\n\n\npossible_keys\n\n\nkey\n\n\nkey_len\n\n\nref\n\n\nrows\n\n\nfiltered\n\n\nExtra\n\n\n\n\n\n\n1\n\n\nSIMPLE\n\n\np\n\n\n\n\nALL\n\n\n\n\n\n\n\n\n\n\n3322\n\n\n10\n\n\nUsing where\n\n\n\n\n1\n\n\nSIMPLE\n\n\no\n\n\np1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18,p19,p20,p21,p22,p23,p24,p25,p26,p27,p28,p29,p30,p31,p32\n\n\nref\n\n\ntailNum\n\n\ntailNum\n\n\n9\n\n\nairlines.p.tailnum\n\n\n1266\n\n\n100"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#explain-with-join---slower",
    "href": "slides/2024-01-18-db-etc.html#explain-with-join---slower",
    "title": "SQL Extras",
    "section": "EXPLAIN with JOIN - slower",
    "text": "EXPLAIN with JOIN - slower\n\nThe cardinality of the index on year is small (the number of rows in flights associated with each unique year is large).\n\n\nEXPLAIN \n  SELECT * FROM planes p \n  LEFT JOIN flights o ON p.Year = o.Year\n  WHERE manufacturer = 'BOEING';\n\n\n\n\n2 records\n\n\n\n\nid\n\n\nselect_type\n\n\ntable\n\n\npartitions\n\n\ntype\n\n\npossible_keys\n\n\nkey\n\n\nkey_len\n\n\nref\n\n\nrows\n\n\nfiltered\n\n\nExtra\n\n\n\n\n\n\n1\n\n\nSIMPLE\n\n\np\n\n\n\n\nALL\n\n\n\n\n\n\n\n\n\n\n3322\n\n\n10\n\n\nUsing where\n\n\n\n\n1\n\n\nSIMPLE\n\n\no\n\n\np1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18,p19,p20,p21,p22,p23,p24,p25,p26,p27,p28,p29,p30,p31,p32\n\n\nref\n\n\nYear,Date\n\n\nYear\n\n\n3\n\n\nairlines.p.year\n\n\n6450117\n\n\n100\n\n\nUsing where"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#sql-in-dbplyr",
    "href": "slides/2024-01-18-db-etc.html#sql-in-dbplyr",
    "title": "SQL Extras",
    "section": "SQL in dbplyr",
    "text": "SQL in dbplyr\nAs mentioned previously, dbplyr doesn’t translate every R command into SQL. After all, SQL is not a statistical software and doesn’t, for example, have a mechanism for creating data visualizations. To track which R commands are connected to SQL see the dbplyr reference sheet."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median",
    "href": "slides/2024-01-18-db-etc.html#median",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nLet’s start with an example, calculating the median altitude in the airports table.1\n\nairports &lt;- tbl(con_air, \"airports\")\n\nhead(airports)\n\n# Source:   SQL [6 x 9]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  faa   name                           lat   lon   alt    tz dst   city  country\n  &lt;chr&gt; &lt;chr&gt;                        &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  \n1 04G   Lansdowne Airport             41.1 -80.6  1044    -5 A     Youn… United…\n2 06A   Moton Field Municipal Airpo…  32.5 -85.7   264    -6 A     Tusk… United…\n3 06C   Schaumburg Regional           42.0 -88.1   801    -6 A     Scha… United…\n4 06N   Randall Airport               41.4 -74.4   523    -5 A     Midd… United…\n5 09J   Jekyll Island Airport         31.1 -81.4    11    -5 A     Jeky… United…\n6 0A9   Elizabethton Municipal Airp…  36.4 -82.2  1593    -5 A     Eliz… United…\n\n\nExample taken from: https://sebhastian.com/mysql-median/"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-1",
    "href": "slides/2024-01-18-db-etc.html#median-1",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nIt looks like show_query() is providing SQL code for calculating the median!\n\nmedian_query &lt;- airports |&gt;\n  summarize(med_alt = median(alt, na.rm = TRUE))\n\nshow_query(median_query)\n\n&lt;SQL&gt;\nSELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY `alt`) AS `med_alt`\nFROM `airports`"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-2",
    "href": "slides/2024-01-18-db-etc.html#median-2",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nBut when the SQL code is run, it doesn’t seem to work.\n\nSELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY `alt`) AS `med_alt`\nFROM `airports`;\n\nError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'GROUP (ORDER BY `alt`) AS `med_alt`\nFROM `airports`' at line 1 [1064]"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-3",
    "href": "slides/2024-01-18-db-etc.html#median-3",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nWhat happens when we computer the median on the tbl?\n\nairports |&gt;\n  summarize(med_alt = median(alt, na.rm = TRUE))\n\nError in `collect()`:\n! Failed to collect lazy table.\nCaused by error:\n! You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'GROUP (ORDER BY `alt`) AS `med_alt`\nFROM `airports`\nLIMIT 7' at line 1 [1064]"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-4",
    "href": "slides/2024-01-18-db-etc.html#median-4",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nHow can the median be calculated in SQL?\n\nSET @row_index := -1;\n\n\nSELECT AVG(subquery.alt) AS median_value\nFROM (\nSELECT @row_index:=@row_index + 1 AS row_index, alt\n  FROM airports\n  ORDER BY alt\n) AS subquery\nWHERE subquery.row_index IN (FLOOR(@row_index / 2), CEIL(@row_index / 2));\n\n\n\n\n1 records\n\n\n\n\nmedian_value\n\n\n\n\n\n\n476"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-5",
    "href": "slides/2024-01-18-db-etc.html#median-5",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nLet’s break down what the code is doing… First, set the row_index to -1 and iterate through by adding +1 for each row. Then concatenate the row_index information onto our table of interest. (Basically, create a column that gives a row value to the dataset, sorted by altitude.)\n\nSET @row_index := -1;\n\n\nSELECT @row_index:=@row_index + 1 AS row_index, alt\n  FROM airports\n  ORDER BY alt\n  LIMIT 10;\n\n\n\n\nDisplaying records 1 - 10\n\n\n\n\nrow_index\n\n\nalt\n\n\n\n\n\n\n0\n\n\n-54\n\n\n\n\n1\n\n\n-42\n\n\n\n\n2\n\n\n0\n\n\n\n\n3\n\n\n0\n\n\n\n\n4\n\n\n0\n\n\n\n\n5\n\n\n0\n\n\n\n\n6\n\n\n0\n\n\n\n\n7\n\n\n0\n\n\n\n\n8\n\n\n0\n\n\n\n\n9\n\n\n0"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-6",
    "href": "slides/2024-01-18-db-etc.html#median-6",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nNext, filter the data to include only the middle row or two rows.\n\nSET @row_index := -1;\n\n\nSELECT *\nFROM (\nSELECT @row_index:=@row_index + 1 AS row_index, alt\n  FROM airports\n  ORDER BY alt\n) AS subquery\nWHERE subquery.row_index IN (FLOOR(@row_index / 2), CEIL(@row_index / 2));\n\n\n\n\n2 records\n\n\n\n\nrow_index\n\n\nalt\n\n\n\n\n\n\n728\n\n\n474\n\n\n\n\n729\n\n\n477"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-7",
    "href": "slides/2024-01-18-db-etc.html#median-7",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nThe last step is to average the middle row(s). If only one row is pulled out in the previous query, then only one row will be averaged (which the computer does happily).\n\nSET @row_index := -1;\n\n\nSELECT AVG(subquery.alt) AS median_value\nFROM (\nSELECT @row_index:=@row_index + 1 AS row_index, alt\n  FROM airports\n  ORDER BY alt\n) AS subquery\nWHERE subquery.row_index IN (FLOOR(@row_index / 2), CEIL(@row_index / 2));\n\n\n\n\n1 records\n\n\n\n\nmedian_value\n\n\n\n\n\n\n476"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-ifelse",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-ifelse",
    "title": "SQL Extras",
    "section": "CASE WHEN and ifelse()",
    "text": "CASE WHEN and ifelse()\nConsider the various R functions that create new variables based on an original variable.\n\nairports |&gt;\n  mutate(sea = ifelse(alt &gt; 500, \"above sea\", \"near sea\")) |&gt;\n  head(5)\n\n# Source:   SQL [5 x 10]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  faa   name                     lat   lon   alt    tz dst   city  country sea  \n  &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n1 04G   Lansdowne Airport       41.1 -80.6  1044    -5 A     Youn… United… abov…\n2 06A   Moton Field Municipal…  32.5 -85.7   264    -6 A     Tusk… United… near…\n3 06C   Schaumburg Regional     42.0 -88.1   801    -6 A     Scha… United… abov…\n4 06N   Randall Airport         41.4 -74.4   523    -5 A     Midd… United… abov…\n5 09J   Jekyll Island Airport   31.1 -81.4    11    -5 A     Jeky… United… near…"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-ifelse-1",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-ifelse-1",
    "title": "SQL Extras",
    "section": "CASE WHEN and ifelse()",
    "text": "CASE WHEN and ifelse()\n\nif_query &lt;- airports |&gt;\n  mutate(sea = ifelse(alt &gt; 500, \"above sea\", \"near sea\"))\n\nshow_query(if_query)\n\n&lt;SQL&gt;\nSELECT\n  *,\n  CASE WHEN (`alt` &gt; 500.0) THEN 'above sea' WHEN NOT (`alt` &gt; 500.0) THEN 'near sea' END AS `sea`\nFROM `airports`"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-ifelse-2",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-ifelse-2",
    "title": "SQL Extras",
    "section": "CASE WHEN and ifelse()",
    "text": "CASE WHEN and ifelse()\n\nSELECT *,\nCASE WHEN (`alt` &gt; 500.0) THEN 'above sea' WHEN NOT (`alt` &gt; 500.0) THEN 'near sea' END AS `sea`\nFROM `airports` \nLIMIT 5;\n\n\n\n\n5 records\n\n\n\n\nfaa\n\n\nname\n\n\nlat\n\n\nlon\n\n\nalt\n\n\ntz\n\n\ndst\n\n\ncity\n\n\ncountry\n\n\nsea\n\n\n\n\n\n\n04G\n\n\nLansdowne Airport\n\n\n41.1\n\n\n-80.6\n\n\n1044\n\n\n-5\n\n\nA\n\n\nYoungstown\n\n\nUnited States\n\n\nabove sea\n\n\n\n\n06A\n\n\nMoton Field Municipal Airport\n\n\n32.5\n\n\n-85.7\n\n\n264\n\n\n-6\n\n\nA\n\n\nTuskegee\n\n\nUnited States\n\n\nnear sea\n\n\n\n\n06C\n\n\nSchaumburg Regional\n\n\n42.0\n\n\n-88.1\n\n\n801\n\n\n-6\n\n\nA\n\n\nSchaumburg\n\n\nUnited States\n\n\nabove sea\n\n\n\n\n06N\n\n\nRandall Airport\n\n\n41.4\n\n\n-74.4\n\n\n523\n\n\n-5\n\n\nA\n\n\nMiddletown\n\n\nUnited States\n\n\nabove sea\n\n\n\n\n09J\n\n\nJekyll Island Airport\n\n\n31.1\n\n\n-81.4\n\n\n11\n\n\n-5\n\n\nA\n\n\nJekyll Island\n\n\nUnited States\n\n\nnear sea"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#other-functions",
    "href": "slides/2024-01-18-db-etc.html#other-functions",
    "title": "SQL Extras",
    "section": "Other functions",
    "text": "Other functions\ndistinct() / head()"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-case_when",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-case_when",
    "title": "SQL Extras",
    "section": "CASE WHEN and case_when()",
    "text": "CASE WHEN and case_when()\n\nairports |&gt;\n  mutate(sea = case_when(\n    alt &lt; 500 ~ \"near sea\",\n    alt &lt; 2000 ~ \"low alt\",\n    alt &lt; 3000 ~ \"mod alt\",\n    alt &lt; 5500 ~ \"high alt\",\n    alt &gt; 5500 ~ \"extreme alt\")) |&gt;\n  head(5)\n\n# Source:   SQL [5 x 10]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  faa   name                     lat   lon   alt    tz dst   city  country sea  \n  &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n1 04G   Lansdowne Airport       41.1 -80.6  1044    -5 A     Youn… United… low …\n2 06A   Moton Field Municipal…  32.5 -85.7   264    -6 A     Tusk… United… near…\n3 06C   Schaumburg Regional     42.0 -88.1   801    -6 A     Scha… United… low …\n4 06N   Randall Airport         41.4 -74.4   523    -5 A     Midd… United… low …\n5 09J   Jekyll Island Airport   31.1 -81.4    11    -5 A     Jeky… United… near…"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-case_when-1",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-case_when-1",
    "title": "SQL Extras",
    "section": "CASE WHEN and case_when()",
    "text": "CASE WHEN and case_when()\n\ncw_query &lt;- airports |&gt;\n  mutate(sea = case_when(\n    alt &lt; 500 ~ \"near sea\",\n    alt &lt; 2000 ~ \"low alt\",\n    alt &lt; 3000 ~ \"mod alt\",\n    alt &lt; 5500 ~ \"high alt\",\n    alt &gt; 5500 ~ \"extreme alt\"))\n\nshow_query(cw_query)\n\n&lt;SQL&gt;\nSELECT\n  *,\n  CASE\nWHEN (`alt` &lt; 500.0) THEN 'near sea'\nWHEN (`alt` &lt; 2000.0) THEN 'low alt'\nWHEN (`alt` &lt; 3000.0) THEN 'mod alt'\nWHEN (`alt` &lt; 5500.0) THEN 'high alt'\nWHEN (`alt` &gt; 5500.0) THEN 'extreme alt'\nEND AS `sea`\nFROM `airports`"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-case_when-2",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-case_when-2",
    "title": "SQL Extras",
    "section": "CASE WHEN and case_when()",
    "text": "CASE WHEN and case_when()\n\nSELECT\n  *,\n  CASE\nWHEN (`alt` &lt; 500.0) THEN 'near sea'\nWHEN (`alt` &lt; 2000.0) THEN 'low alt'\nWHEN (`alt` &lt; 3000.0) THEN 'mod alt'\nWHEN (`alt` &lt; 5500.0) THEN 'high alt'\nWHEN (`alt` &gt; 5500.0) THEN 'extreme alt'\nEND AS `sea`\nFROM `airports`\nLIMIT 5;\n\n\n\n\n5 records\n\n\n\n\nfaa\n\n\nname\n\n\nlat\n\n\nlon\n\n\nalt\n\n\ntz\n\n\ndst\n\n\ncity\n\n\ncountry\n\n\nsea\n\n\n\n\n\n\n04G\n\n\nLansdowne Airport\n\n\n41.1\n\n\n-80.6\n\n\n1044\n\n\n-5\n\n\nA\n\n\nYoungstown\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n06A\n\n\nMoton Field Municipal Airport\n\n\n32.5\n\n\n-85.7\n\n\n264\n\n\n-6\n\n\nA\n\n\nTuskegee\n\n\nUnited States\n\n\nnear sea\n\n\n\n\n06C\n\n\nSchaumburg Regional\n\n\n42.0\n\n\n-88.1\n\n\n801\n\n\n-6\n\n\nA\n\n\nSchaumburg\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n06N\n\n\nRandall Airport\n\n\n41.4\n\n\n-74.4\n\n\n523\n\n\n-5\n\n\nA\n\n\nMiddletown\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n09J\n\n\nJekyll Island Airport\n\n\n31.1\n\n\n-81.4\n\n\n11\n\n\n-5\n\n\nA\n\n\nJekyll Island\n\n\nUnited States\n\n\nnear sea"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-cut",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-cut",
    "title": "SQL Extras",
    "section": "CASE WHEN and cut()",
    "text": "CASE WHEN and cut()\n\nairports |&gt;\n  mutate(sea = cut(\n    alt,\n    breaks = c(-Inf, 500, 2000, 3000, 5500, Inf),\n    labels = c(\"near sea\", \"low alt\", \"mod alt\", \"high alt\", \"extreme alt\")\n  )\n)|&gt;\n  head(5)\n\n# Source:   SQL [5 x 10]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  faa   name                     lat   lon   alt    tz dst   city  country sea  \n  &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n1 04G   Lansdowne Airport       41.1 -80.6  1044    -5 A     Youn… United… low …\n2 06A   Moton Field Municipal…  32.5 -85.7   264    -6 A     Tusk… United… near…\n3 06C   Schaumburg Regional     42.0 -88.1   801    -6 A     Scha… United… low …\n4 06N   Randall Airport         41.4 -74.4   523    -5 A     Midd… United… low …\n5 09J   Jekyll Island Airport   31.1 -81.4    11    -5 A     Jeky… United… near…"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-case_when-3",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-case_when-3",
    "title": "SQL Extras",
    "section": "CASE WHEN and case_when()",
    "text": "CASE WHEN and case_when()\n\ncw_query &lt;- airports |&gt;\n  mutate(sea = cut(\n    alt,\n    breaks = c(-Inf, 500, 2000, 3000, 5500, Inf),\n    labels = c(\"near sea\", \"low alt\", \"mod alt\", \"high alt\", \"extreme alt\")\n  )\n)\n\nshow_query(cw_query)\n\n&lt;SQL&gt;\nSELECT\n  *,\n  CASE\nWHEN (`alt` &lt;= 500.0) THEN 'near sea'\nWHEN (`alt` &lt;= 2000.0) THEN 'low alt'\nWHEN (`alt` &lt;= 3000.0) THEN 'mod alt'\nWHEN (`alt` &lt;= 5500.0) THEN 'high alt'\nWHEN (`alt` &gt; 5500.0) THEN 'extreme alt'\nEND AS `sea`\nFROM `airports`"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-case_when-4",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-case_when-4",
    "title": "SQL Extras",
    "section": "CASE WHEN and case_when()",
    "text": "CASE WHEN and case_when()\n\nSELECT\n  *,\n  CASE\nWHEN (`alt` &lt;= 500.0) THEN 'near sea'\nWHEN (`alt` &lt;= 2000.0) THEN 'low alt'\nWHEN (`alt` &lt;= 3000.0) THEN 'mod alt'\nWHEN (`alt` &lt;= 5500.0) THEN 'high alt'\nWHEN (`alt` &gt; 5500.0) THEN 'extreme alt'\nEND AS `sea`\nFROM `airports`\nLIMIT 5;\n\n\n\n\n5 records\n\n\n\n\nfaa\n\n\nname\n\n\nlat\n\n\nlon\n\n\nalt\n\n\ntz\n\n\ndst\n\n\ncity\n\n\ncountry\n\n\nsea\n\n\n\n\n\n\n04G\n\n\nLansdowne Airport\n\n\n41.1\n\n\n-80.6\n\n\n1044\n\n\n-5\n\n\nA\n\n\nYoungstown\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n06A\n\n\nMoton Field Municipal Airport\n\n\n32.5\n\n\n-85.7\n\n\n264\n\n\n-6\n\n\nA\n\n\nTuskegee\n\n\nUnited States\n\n\nnear sea\n\n\n\n\n06C\n\n\nSchaumburg Regional\n\n\n42.0\n\n\n-88.1\n\n\n801\n\n\n-6\n\n\nA\n\n\nSchaumburg\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n06N\n\n\nRandall Airport\n\n\n41.4\n\n\n-74.4\n\n\n523\n\n\n-5\n\n\nA\n\n\nMiddletown\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n09J\n\n\nJekyll Island Airport\n\n\n31.1\n\n\n-81.4\n\n\n11\n\n\n-5\n\n\nA\n\n\nJekyll Island\n\n\nUnited States\n\n\nnear sea"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#distinct",
    "href": "slides/2024-01-18-db-etc.html#distinct",
    "title": "SQL Extras",
    "section": "distinct()",
    "text": "distinct()\nHow many distinct time zones are there in the airports table?\n\nairports |&gt;\n  select(tz) |&gt;\n  distinct()\n\n# Source:   SQL [?? x 1]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n     tz\n  &lt;int&gt;\n1    -5\n2    -6\n3    -8\n4    -7\n5    -9\n6   -10\n# ℹ more rows"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#distinct-1",
    "href": "slides/2024-01-18-db-etc.html#distinct-1",
    "title": "SQL Extras",
    "section": "distinct()",
    "text": "distinct()\nHow many distinct time zones are there in the airports table?\n\ndist_query &lt;- airports |&gt;\n  select(tz) |&gt;\n  distinct()\n\nshow_query(dist_query)\n\n&lt;SQL&gt;\nSELECT DISTINCT `tz`\nFROM `airports`"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#distinct-2",
    "href": "slides/2024-01-18-db-etc.html#distinct-2",
    "title": "SQL Extras",
    "section": "distinct()",
    "text": "distinct()\nHow many distinct time zones are there in the airports table?\n\nSELECT DISTINCT `tz`\nFROM `airports`;\n\n\n\n\n7 records\n\n\n\n\ntz\n\n\n\n\n\n\n-5\n\n\n\n\n-6\n\n\n\n\n-8\n\n\n\n\n-7\n\n\n\n\n-9\n\n\n\n\n-10\n\n\n\n\n8"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#limit-as-head",
    "href": "slides/2024-01-18-db-etc.html#limit-as-head",
    "title": "SQL Extras",
    "section": "LIMIT as head()",
    "text": "LIMIT as head()\n\nairports |&gt;\n  head(5)\n\n# Source:   SQL [5 x 9]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:NA/airlines]\n  faa   name                           lat   lon   alt    tz dst   city  country\n  &lt;chr&gt; &lt;chr&gt;                        &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  \n1 04G   Lansdowne Airport             41.1 -80.6  1044    -5 A     Youn… United…\n2 06A   Moton Field Municipal Airpo…  32.5 -85.7   264    -6 A     Tusk… United…\n3 06C   Schaumburg Regional           42.0 -88.1   801    -6 A     Scha… United…\n4 06N   Randall Airport               41.4 -74.4   523    -5 A     Midd… United…\n5 09J   Jekyll Island Airport         31.1 -81.4    11    -5 A     Jeky… United…"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#limit-as-head-1",
    "href": "slides/2024-01-18-db-etc.html#limit-as-head-1",
    "title": "SQL Extras",
    "section": "LIMIT as head()",
    "text": "LIMIT as head()\n\nhead_query &lt;- airports |&gt;\n  head(5)\n\nshow_query(head_query)\n\n&lt;SQL&gt;\nSELECT *\nFROM `airports`\nLIMIT 5"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#limit-as-head-2",
    "href": "slides/2024-01-18-db-etc.html#limit-as-head-2",
    "title": "SQL Extras",
    "section": "LIMIT as head()",
    "text": "LIMIT as head()\n\nSELECT *\nFROM `airports`\nLIMIT 5;\n\n\n\n\n5 records\n\n\n\n\nfaa\n\n\nname\n\n\nlat\n\n\nlon\n\n\nalt\n\n\ntz\n\n\ndst\n\n\ncity\n\n\ncountry\n\n\n\n\n\n\n04G\n\n\nLansdowne Airport\n\n\n41.1\n\n\n-80.6\n\n\n1044\n\n\n-5\n\n\nA\n\n\nYoungstown\n\n\nUnited States\n\n\n\n\n06A\n\n\nMoton Field Municipal Airport\n\n\n32.5\n\n\n-85.7\n\n\n264\n\n\n-6\n\n\nA\n\n\nTuskegee\n\n\nUnited States\n\n\n\n\n06C\n\n\nSchaumburg Regional\n\n\n42.0\n\n\n-88.1\n\n\n801\n\n\n-6\n\n\nA\n\n\nSchaumburg\n\n\nUnited States\n\n\n\n\n06N\n\n\nRandall Airport\n\n\n41.4\n\n\n-74.4\n\n\n523\n\n\n-5\n\n\nA\n\n\nMiddletown\n\n\nUnited States\n\n\n\n\n09J\n\n\nJekyll Island Airport\n\n\n31.1\n\n\n-81.4\n\n\n11\n\n\n-5\n\n\nA\n\n\nJekyll Island\n\n\nUnited States"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#ggplot",
    "href": "slides/2024-01-18-db-etc.html#ggplot",
    "title": "SQL Extras",
    "section": "ggplot()",
    "text": "ggplot()\n\nairports |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n  geom_point()"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#ggplot-1",
    "href": "slides/2024-01-18-db-etc.html#ggplot-1",
    "title": "SQL Extras",
    "section": "ggplot()",
    "text": "ggplot()\n\nairports |&gt;\n  filter(lon &lt; 0) |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n  geom_point()"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#ggplot-2",
    "href": "slides/2024-01-18-db-etc.html#ggplot-2",
    "title": "SQL Extras",
    "section": "ggplot()",
    "text": "ggplot()\n\ngg_query &lt;- airports |&gt;\n  filter(lon &lt; 0) |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n  geom_point()\n\nshow_query(gg_query)\n\nError in UseMethod(\"show_query\"): no applicable method for 'show_query' applied to an object of class \"c('gg', 'ggplot')\""
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-cut-1",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-cut-1",
    "title": "SQL Extras",
    "section": "CASE WHEN and cut()",
    "text": "CASE WHEN and cut()\n\ncw_query &lt;- airports |&gt;\n  mutate(sea = cut(\n    alt,\n    breaks = c(-Inf, 500, 2000, 3000, 5500, Inf),\n    labels = c(\"near sea\", \"low alt\", \"mod alt\", \"high alt\", \"extreme alt\")\n  )\n)\n\nshow_query(cw_query)\n\n&lt;SQL&gt;\nSELECT\n  *,\n  CASE\nWHEN (`alt` &lt;= 500.0) THEN 'near sea'\nWHEN (`alt` &lt;= 2000.0) THEN 'low alt'\nWHEN (`alt` &lt;= 3000.0) THEN 'mod alt'\nWHEN (`alt` &lt;= 5500.0) THEN 'high alt'\nWHEN (`alt` &gt; 5500.0) THEN 'extreme alt'\nEND AS `sea`\nFROM `airports`"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#case-when-and-cut-2",
    "href": "slides/2024-01-18-db-etc.html#case-when-and-cut-2",
    "title": "SQL Extras",
    "section": "CASE WHEN and cut()",
    "text": "CASE WHEN and cut()\n\nSELECT\n  *,\n  CASE\nWHEN (`alt` &lt;= 500.0) THEN 'near sea'\nWHEN (`alt` &lt;= 2000.0) THEN 'low alt'\nWHEN (`alt` &lt;= 3000.0) THEN 'mod alt'\nWHEN (`alt` &lt;= 5500.0) THEN 'high alt'\nWHEN (`alt` &gt; 5500.0) THEN 'extreme alt'\nEND AS `sea`\nFROM `airports`\nLIMIT 5;\n\n\n\n\n5 records\n\n\n\n\nfaa\n\n\nname\n\n\nlat\n\n\nlon\n\n\nalt\n\n\ntz\n\n\ndst\n\n\ncity\n\n\ncountry\n\n\nsea\n\n\n\n\n\n\n04G\n\n\nLansdowne Airport\n\n\n41.1\n\n\n-80.6\n\n\n1044\n\n\n-5\n\n\nA\n\n\nYoungstown\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n06A\n\n\nMoton Field Municipal Airport\n\n\n32.5\n\n\n-85.7\n\n\n264\n\n\n-6\n\n\nA\n\n\nTuskegee\n\n\nUnited States\n\n\nnear sea\n\n\n\n\n06C\n\n\nSchaumburg Regional\n\n\n42.0\n\n\n-88.1\n\n\n801\n\n\n-6\n\n\nA\n\n\nSchaumburg\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n06N\n\n\nRandall Airport\n\n\n41.4\n\n\n-74.4\n\n\n523\n\n\n-5\n\n\nA\n\n\nMiddletown\n\n\nUnited States\n\n\nlow alt\n\n\n\n\n09J\n\n\nJekyll Island Airport\n\n\n31.1\n\n\n-81.4\n\n\n11\n\n\n-5\n\n\nA\n\n\nJekyll Island\n\n\nUnited States\n\n\nnear sea"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#cardinality-x-rows",
    "href": "slides/2024-01-18-db-etc.html#cardinality-x-rows",
    "title": "SQL Extras",
    "section": "Cardinality x rows",
    "text": "Cardinality x rows\nThe Cardinality from SHOW INDEXES times the rows from EXPLAIN is roughly the total number of rows in the dataframe."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#median-8",
    "href": "slides/2024-01-18-db-etc.html#median-8",
    "title": "SQL Extras",
    "section": "Median",
    "text": "Median\nTake-aways:\n\ndbplyr is not able to translate the median() function into SQL.\nThe median is actually really hard to calculate! In particular, it is hard to calculate the median in one pass through the data."
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#take-away-message",
    "href": "slides/2024-01-18-db-etc.html#take-away-message",
    "title": "SQL Extras",
    "section": "Take-away message",
    "text": "Take-away message\n\ndbplyr is awesome and can often be helpful in figuring out SQL syntax\nsometimes dbplyr will provide SQL syntax that does not work (see the median example)\nsometimes there is no SQL syntax to match the R task of interest (see ggplot)"
  },
  {
    "objectID": "slides/2024-01-18-db-etc.html#section",
    "href": "slides/2024-01-18-db-etc.html#section",
    "title": "SQL Extras",
    "section": "47",
    "text": "47\nPomona’s number is 47, and I wanted to have a 47th slide.\n\n\nFigure 1: image credit: Jo Hardin"
  }
]